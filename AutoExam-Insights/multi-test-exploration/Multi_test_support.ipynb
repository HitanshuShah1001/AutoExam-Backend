{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30294341",
   "metadata": {},
   "source": [
    "<h1>Import Libs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f591104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openai as client\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from fpdf import FPDF\n",
    "import seaborn as sns\n",
    "from xhtml2pdf import pisa\n",
    "from PyPDF2 import PdfMerger\n",
    "import re\n",
    "import csv\n",
    "from typing import List\n",
    "from utils import print_question_data\n",
    "from utils import print_first_5_students\n",
    "from utils import print_single_value_in_table\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from utils import print_single_value_in_table\n",
    "from utils import err_box_red\n",
    "from utils import pretty_print_results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdb1bf",
   "metadata": {},
   "source": [
    "<h1>Constants</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE_ORIGIN = \"./student_data.csv\"\n",
    "FILE_DESTINATION = \"./student_data_final.csv\"\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS =  [\n",
    "        (\"Test1\", [\"English\", \"Maths\"], [\"a an the,Naming words\", \"numbers upto 1000,numbers upto 500\"]),\n",
    "        (\"Test2\", [\"English\", \"Maths\"], [\"Naming words,singular nouns and plural nouns\", \"numbers upto 500,numbers\"])\n",
    "    ]\n",
    "API_URL = 'http://localhost:3000/'\n",
    "AUTH_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MywiZW1haWxJZCI6ImhpdGFuc2h1c2hhaDVAZ21haWwuY29tIiwiaWF0IjoxNzQ2NzE5OTI4LCJleHAiOjE3NDY4MDYzMjh9.oofQw4zUkKWcGXvYyJjdK0Mp1y25dlxVSsTRizGEBPE\"\n",
    "GET_QUESTIONS_FOR_TOPICS = API_URL + 'question/get-questions-for-chapters'\n",
    "SAVE_STUDENT_COST_PER_WORKSHEET = API_URL + 'student-stat-analysis/save-student-cost-per-worksheet'\n",
    "DOWNLOAD_FROM_S3_LINK =  API_URL + 'student-stat-analysis/download-worksheet-from-s3-link'\n",
    "GET_WORKSHEET_HTML = API_URL + 'analysis/getWorksheetHTML'\n",
    "TOTAL_COST = 0\n",
    "CHAPTERS = ['a, an, the', \"Naming words\", 'numbers', 'singular nouns and plural nouns', 'numbers upto 1,000', 'numbers upto 500']\n",
    "MODEL = 'o4-mini'\n",
    "ATTENDANCE_DAYS = 22\n",
    "STANDARD = 10\n",
    "MAX_SCORE = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee38fe",
   "metadata": {},
   "source": [
    "<h1> Read Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        student_data = pd.read_csv(file_path)\n",
    "        return student_data\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        student_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        return student_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052edb",
   "metadata": {},
   "source": [
    "<h1>Add topics to csv Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f0b01",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Setup for this demo:\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS = [\n",
    "    (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "    (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "]\n",
    "FILE_ORIGIN      = \"input.csv\"\n",
    "FILE_DESTINATION = \"output.csv\"\n",
    "\n",
    "# Contents of `input.csv`:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance\n",
    "# Alice,85,88,90,92,12\n",
    "# Bob,78,82,88,85,23\n",
    "# Charlie,92,94,76,78,24\n",
    "\n",
    "add_topics_to_csv()\n",
    "\n",
    "# After running, `output.csv` will include extra columns:\n",
    "#   English Topics Test1, Maths Topics Test1,\n",
    "#   English Topics Test2, Maths Topics Test2,\n",
    "#   English All Topics,    Maths All Topics\n",
    "#\n",
    "# And sample rows become:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance,English Topics Test1,Maths Topics Test1,English Topics Test2,Maths Topics Test2,English All Topics,Maths All Topics\n",
    "# Alice,85,88,90,92,12,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Bob,78,82,88,85,23,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Charlie,92,94,76,78,24,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def add_topics_to_csv():\n",
    "    \"\"\"\n",
    "    - input_csv_path, output_csv_path: file paths.\n",
    "    - tests: a list of (test_name, subjects, topic_values), e.g.:\n",
    "        [\n",
    "          (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "          (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "        ]\n",
    "    \n",
    "    This will add columns:\n",
    "      English Topics Test1, Maths Topics Test1,\n",
    "      English Topics Test2, Maths Topics Test2,\n",
    "      English All Topics,  Maths All Topics\n",
    "    \"\"\"\n",
    "    # 1) Validate\n",
    "    for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        if len(subjects) != len(chapters):\n",
    "            raise ValueError(f\"subjects vs topic_values length mismatch in {test_name}\")\n",
    "\n",
    "    # 2) Collect all unique subjects and append it to all_subjects\n",
    "    all_subjects: List[str] = []\n",
    "    for _, subjects, _ in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        for subj in subjects:\n",
    "            if subj not in all_subjects:\n",
    "                all_subjects.append(subj)\n",
    "\n",
    "    # 3) Build per-test lookup maps\n",
    "    test_topic_maps: Dict[str, Dict[str, str]] = {\n",
    "        test_name: dict(zip(subjects, chapters))\n",
    "        for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS\n",
    "    }\n",
    "\n",
    "    # 4) Open I/O\n",
    "    with open(FILE_ORIGIN, newline=\"\", encoding=\"utf-8\") as fin, \\\n",
    "         open(FILE_DESTINATION, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        # a) build the new header\n",
    "        extra_cols: List[str] = []\n",
    "        for test_name in test_topic_maps:\n",
    "            for subj in all_subjects:\n",
    "                if subj in test_topic_maps[test_name]:\n",
    "                    extra_cols.append(f\"{subj} Topics {test_name}\")\n",
    "        for subj in all_subjects:\n",
    "            extra_cols.append(f\"{subj} All Topics\")\n",
    "\n",
    "        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames + extra_cols)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 5) Process each row\n",
    "        for row in reader:\n",
    "            # per-test columns\n",
    "            for test_name, topics_map in test_topic_maps.items():\n",
    "                for subj, topics_str in topics_map.items():\n",
    "                    row[f\"{subj} Topics {test_name}\"] = topics_str\n",
    "\n",
    "            # aggregated union columns\n",
    "            for subj in all_subjects:\n",
    "                all_toks: List[str] = []\n",
    "                for topics_map in test_topic_maps.values():\n",
    "                    if subj in topics_map:\n",
    "                        # split on comma, strip whitespace\n",
    "                        all_toks.extend([tok.strip() for tok in topics_map[subj].split(\",\")])\n",
    "                # dedupe & sort (optional)\n",
    "                unique = sorted(set(tok for tok in all_toks if tok))\n",
    "                row[f\"{subj} All Topics\"] = \", \".join(unique)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc8db",
   "metadata": {},
   "source": [
    "<h1>Validate Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e7c4d",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Example setup\n",
    "import pandas as pd\n",
    "from your_module import validate_data  # adjust import as needed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': ['85', '78', '92'],\n",
    "    'English_Test2': ['88', '82', '94'],\n",
    "    'Maths_Test1': ['90', '88', '76'],\n",
    "    'Maths_Test2': ['92', '85', '78'],\n",
    "    'English Topics Test1': ['A,B', 'A,B', 'A,B'],\n",
    "    'Maths Topics Test1': ['C,D', 'C,D', 'C,D'],\n",
    "    'English Topics Test2': ['B,C', 'B,C', 'B,C'],\n",
    "    'Maths Topics Test2': ['D,F', 'D,F', 'D,F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24]\n",
    "})\n",
    "\n",
    "clean_df = validate_data(df)\n",
    "\n",
    "# Console output:\n",
    "# Number of students loaded: 3\n",
    "# \n",
    "#   Student Names  English_Test1  English_Test2  Maths_Test1  Maths_Test2  English Topics Test1  Maths Topics Test1  English Topics Test2  Maths Topics Test2  English All Topics  Maths All Topics  Attendance\n",
    "#0         Alice              85              88           90           92                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          12\n",
    "#1           Bob              78              82           88           85                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          23\n",
    "#2       Charlie              92              94           76           78                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data(df: pd.DataFrame, test_mark_cols=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates a student score DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Strips whitespace from all string columns\n",
    "    - Normalizes topic strings like \"A,B\" to \"A, B\"\n",
    "    - Detects missing names or marks\n",
    "    - Standardizes absent marks as 'AB'\n",
    "    - Converts valid marks to int/float\n",
    "    - Fills missing attendance with 0\n",
    "    - Prints a summary of absentees and preview of data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input student data.\n",
    "        test_mark_cols (list[str], optional): List of test score columns to validate. If None, inferred.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and validated dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # 0. Remove leading/trailing spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # 1. Normalize topic columns — ensure \"A, B, C\" format\n",
    "    topic_cols = [c for c in df.columns if re.search(r'topics', c, re.IGNORECASE)]\n",
    "    for col in topic_cols:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: ', '.join(p.strip() for p in x.split(',')) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # 2. Check for missing student names and report\n",
    "    if df['Student Names'].isna().any():\n",
    "        missing = df[df['Student Names'].isna()].index.tolist()\n",
    "        print(f\"Missing Student Names in rows: {missing}\")\n",
    "\n",
    "    # 3. Identify test mark columns: use passed ones or detect those matching '<Subject>_Test<N>'\n",
    "    if test_mark_cols is None:\n",
    "        test_mark_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "\n",
    "    # Ensure the specified test mark columns exist in DataFrame\n",
    "    missing_marks = [c for c in test_mark_cols if c not in df.columns]\n",
    "    if missing_marks:\n",
    "        raise KeyError(f\"Expected mark columns not found: {missing_marks}\")\n",
    "\n",
    "    # 4. Validate each test mark column\n",
    "    for col in test_mark_cols:\n",
    "        # a) Treat empty or NaN cells as 'AB' (Absent)\n",
    "        empty_mask = df[col].isna() | (df[col] == '')\n",
    "        if empty_mask.any():\n",
    "            for idx in df[empty_mask].index:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Missing {col} for {name}; marking as absent ('AB')\")\n",
    "            df.loc[empty_mask, col] = 'AB'\n",
    "\n",
    "        # b) Standardize all 'ab', 'Ab', etc. to uppercase 'AB'\n",
    "        is_ab = df[col].astype(str).str.upper().str.strip() == 'AB'\n",
    "        df.loc[is_ab, col] = 'AB'\n",
    "\n",
    "        # c) Try to convert other values to numbers, else mark as 'AB'\n",
    "        for idx in df.index:\n",
    "            if df.at[idx, col] == 'AB':\n",
    "                continue  # Skip if already marked absent\n",
    "            val = df.at[idx, col]\n",
    "            try:\n",
    "                num = float(val)\n",
    "                df.at[idx, col] = int(num) if num.is_integer() else num\n",
    "            except Exception:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Invalid {col} value '{val}' for {name}; marking as absent\")\n",
    "                df.at[idx, col] = 'AB'\n",
    "\n",
    "    # 5. Handle Attendance column\n",
    "    if 'Attendance' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'Attendance' not found\")\n",
    "\n",
    "    # Fill missing attendance with 0\n",
    "    if df['Attendance'].isna().any():\n",
    "        for idx in df[df['Attendance'].isna()].index:\n",
    "            name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "            print(f\"Attendance missing for {name}; setting to 0\")\n",
    "        df['Attendance'] = df['Attendance'].fillna(0)\n",
    "\n",
    "    # Ensure attendance is numeric integers\n",
    "    df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 6. Summary statistics\n",
    "    print(f\"\\nNumber of students loaded: {len(df)}\")\n",
    "    absent_summary = {\n",
    "        col: (df[col] == 'AB').sum() for col in test_mark_cols if (df[col] == 'AB').any()\n",
    "    }\n",
    "    if absent_summary:\n",
    "        print(\"\\nStudents marked as absent:\")\n",
    "        for col, count in absent_summary.items():\n",
    "            print(f\"  {col}: {count}\")\n",
    "\n",
    "    # 7. Print first 5 rows for review\n",
    "    print(df.head(5).to_string(index=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca7c9",
   "metadata": {},
   "source": [
    "<h1>Classify Students Strong and Weak Topics </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f877",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from your_module import classify_students_by_topic  # adjust import as needed\n",
    "\n",
    "# Input DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': [85, 78, 92],\n",
    "    'English_Test2': [88, 82, 94],\n",
    "    'Maths_Test1': [90, 88, 76],\n",
    "    'Maths_Test2': [92, 85, 78],\n",
    "    'English Topics Test1': ['A, B', 'A, B', 'A, B'],\n",
    "    'Maths Topics Test1': ['C, D', 'C, D', 'C, D'],\n",
    "    'English Topics Test2': ['B, C', 'B, C', 'B, C'],\n",
    "    'Maths Topics Test2': ['D, F', 'D, F', 'D, F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24],\n",
    "    \"Teacher's Remarks\": ['', '', '']\n",
    "})\n",
    "\n",
    "# Run classification\n",
    "results = classify_students_by_topic(df)\n",
    "print(results)\n",
    "\n",
    "# Expected Output:\n",
    "# [\n",
    "#     {\n",
    "#         'name': 'Alice',\n",
    "#         'attendance': 12,\n",
    "#         'remarks': '',\n",
    "#         'strong_topics':   ['A', 'B', 'C', 'D', 'F'],\n",
    "#         'weak_topics':     [],\n",
    "#         'practice_topics': [],\n",
    "#         'topic_details': [\n",
    "#             {'topic':'A','avg_pct':85.0,'num_tests':1},\n",
    "#             {'topic':'B','avg_pct':86.5,'num_tests':2},\n",
    "#             {'topic':'C','avg_pct':89.0,'num_tests':2},\n",
    "#             {'topic':'D','avg_pct':91.0,'num_tests':2},\n",
    "#             {'topic':'F','avg_pct':92.0,'num_tests':1},\n",
    "#         ],\n",
    "#         'test_details': [\n",
    "#             {'test_col':'English_Test1','subject':'English','raw':85,'pct':85.0,'topics':['A','B']},\n",
    "#             {'test_col':'English_Test2','subject':'English','raw':88,'pct':88.0,'topics':['B','C']},\n",
    "#             {'test_col':'Maths_Test1','subject':'Maths','raw':90,'pct':90.0,'topics':['C','D']},\n",
    "#             {'test_col':'Maths_Test2','subject':'Maths','raw':92,'pct':92.0,'topics':['D','F']},\n",
    "#         ]\n",
    "#     },\n",
    "#     { ... },  # Bob's dict\n",
    "#     { ... }   # Charlie's dict\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_students_by_topic(\n",
    "    df: pd.DataFrame,\n",
    "    strong_thresh: float = 85.0,\n",
    "    weak_thresh: float = 70.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Classify students into strong/weak/practice *topics* based on multiple tests.\n",
    "\n",
    "    Logic & reasoning:\n",
    "      1. We may have multiple tests per subject, each covering overlapping topics.\n",
    "      2. For each student-topic pair, we collect all test percentages in which that topic appeared.\n",
    "      3. We compute the *average percentage* for that topic.\n",
    "      4. We apply *fixed thresholds* (85% for strong, 70% for weak) rather than class-level percentiles—\n",
    "         because topic-level data can be sparse and unevenly distributed.\n",
    "      5. Topics ≥ strong_thresh → strong; ≤ weak_thresh → weak; otherwise → practice.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing:\n",
    "            - \"Student Names\", one or more \"<Subject>_Test<N>\" columns,\n",
    "            - corresponding \"<Subject> Topics Test<N>\" columns,\n",
    "            - \"Attendance\" and \"Teacher's Remarks\".\n",
    "        max_score: Maximum possible raw score per test.\n",
    "        strong_thresh: Percentage threshold above which a topic is 'strong'.\n",
    "        weak_thresh: Percentage threshold below which a topic is 'weak'.\n",
    "\n",
    "    Returns:\n",
    "        A list of per-student dicts with keys:\n",
    "          - name, attendance, remarks\n",
    "          - strong_topics, weak_topics, practice_topics\n",
    "          - topic_details: list of { topic, avg_pct, count_of_tests }\n",
    "          - test_details: list of { test_col, subject, raw, pct, topics }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1) Identify all test-score columns, e.g. 'English_Test1', 'Maths_Test2', etc.\n",
    "    test_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "    # 2) Identify all topic columns for tests: '<Subject> Topics Test<N>'\n",
    "    topic_cols = [c for c in df.columns if re.match(r'.+ Topics Test\\d+', c)]\n",
    "\n",
    "    # Build a mapping from each test column to its topic-column name\n",
    "    # e.g. { 'English_Test1': 'English Topics Test1', ... }\n",
    "    test_to_topics = {}\n",
    "    for tc in test_cols:\n",
    "        subj, num = tc.rsplit('_Test', 1)\n",
    "        tcol = f\"{subj} Topics Test{num}\"\n",
    "        if tcol in df.columns:\n",
    "            test_to_topics[tc] = tcol\n",
    "        else:\n",
    "            raise KeyError(f\"Missing topics column for {tc}: expected '{tcol}'\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name       = row['Student Names']\n",
    "        attendance = row.get('Attendance')\n",
    "        remarks    = row.get(\"Teacher's Remarks\", \"\")\n",
    "\n",
    "        # Will collect raw details for debugging/reporting\n",
    "        test_details  = []\n",
    "        # topic_scores accumulates all pct values per topic\n",
    "        topic_scores  = {}\n",
    "\n",
    "        # 3) Loop through each test, parse marks and topics\n",
    "        for tc, tcol in test_to_topics.items():\n",
    "            raw = row[tc]\n",
    "            # a) Handle absent\n",
    "            if isinstance(raw, str) and raw.strip().upper() == 'AB':\n",
    "                pct = np.nan\n",
    "            else:\n",
    "                raw_num = pd.to_numeric(raw, errors='coerce')\n",
    "                pct     = (raw_num * 100.0 / MAX_SCORE) if pd.notna(raw_num) else np.nan\n",
    "\n",
    "            # b) Parse topics list for this test\n",
    "            topics = []\n",
    "            tstr = row.get(tcol, \"\")\n",
    "            if isinstance(tstr, str) and tstr.strip():\n",
    "                topics = [t.strip() for t in tstr.split(',')]\n",
    "\n",
    "            # c) Record test detail\n",
    "            #    (helps trace exactly which tests contributed to each topic)\n",
    "            test_details.append({\n",
    "                'test_col': tc,\n",
    "                'subject':  tc.split('_Test')[0],\n",
    "                'raw':      raw,\n",
    "                'pct':      pct,\n",
    "                'topics':   topics\n",
    "            })\n",
    "\n",
    "            # d) Append pct to each topic's list\n",
    "            for topic in topics:\n",
    "                topic_scores.setdefault(topic, []).append(pct)\n",
    "\n",
    "        # 4) Compute average pct per topic & classify\n",
    "        strong_topics  = []\n",
    "        weak_topics    = []\n",
    "        practice_topics = []\n",
    "        topic_details   = []\n",
    "\n",
    "        for topic, pcts in topic_scores.items():\n",
    "            # ignore NaNs when averaging\n",
    "            valid = [p for p in pcts if pd.notna(p)]\n",
    "            avg_pct = float(np.nan) if not valid else sum(valid) / len(valid)\n",
    "\n",
    "            # classify based on fixed thresholds\n",
    "            if pd.notna(avg_pct):\n",
    "                if avg_pct >= strong_thresh:\n",
    "                    strong_topics.append(topic)\n",
    "                elif avg_pct <= weak_thresh:\n",
    "                    weak_topics.append(topic)\n",
    "                else:\n",
    "                    practice_topics.append(topic)\n",
    "\n",
    "            topic_details.append({\n",
    "                'topic':     topic,\n",
    "                'avg_pct':   avg_pct,\n",
    "                'num_tests': len(valid)\n",
    "            })\n",
    "\n",
    "        # 5) Assemble result for this student\n",
    "        results.append({\n",
    "            'name':             name,\n",
    "            'attendance':       attendance,\n",
    "            'remarks':          remarks,\n",
    "            'strong_topics':    strong_topics,\n",
    "            'weak_topics':      weak_topics,\n",
    "            'practice_topics':  practice_topics,\n",
    "            'topic_details':    topic_details,\n",
    "            'test_details':     test_details\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e198e49",
   "metadata": {},
   "source": [
    "<h1>Call API to get questions for all the chapters asked in the examination</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db4c9f",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from your_module import fetch_questions_for_topics  # adjust import as needed\n",
    "\n",
    "# Setup for demo:\n",
    "AUTH_TOKEN = \"Bearer your_token_here\"\n",
    "API_URL    = \"https://api.yoursite.com/getQuestionsForChapters\"\n",
    "chapters   = [\"Algebra Basics\", \"Calculus I\", \"Geometry Fundamentals\"]\n",
    "\n",
    "# Run the function\n",
    "results = fetch_questions_for_topics()\n",
    "print(results)\n",
    "\n",
    "# Expected Output (example structure):\n",
    "# [\n",
    "#   {\n",
    "#     \"Algebra Basics\": [\n",
    "#       \"What is the solution to x + 5 = 12?\",\n",
    "#       \"Describe the properties of a linear equation.\",\n",
    "#       {\"questionText\": \"Solve for y: 2y = 14\", \"options\": [{\"key\":\"A\",\"option\":\"y=6\"},{\"key\":\"B\",\"option\":\"y=7\"}, …]},\n",
    "#       … up to 10 questions total …\n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Calculus I\": [\n",
    "#       \"Explain the concept of a derivative.\",\n",
    "#       {\"questionText\": \"Find d/dx of x² + 3x\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Geometry Fundamentals\": [\n",
    "#       \"What defines a right triangle?\",\n",
    "#       {\"questionText\":\"Which angle is opposite the hypotenuse?\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc772b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions_for_topics():\n",
    "    # 4. Build headers & payload\n",
    "    headers = {\n",
    "        'Authorization': AUTH_TOKEN,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {'chapters': CHAPTERS}\n",
    "    # 5. Fire the GET (or POST if you prefer) with JSON body\n",
    "    response = requests.get(GET_QUESTIONS_FOR_TOPICS, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca4301",
   "metadata": {},
   "source": [
    "<h1>Create System Prompt and User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an advanced educational insights generator and personalized learning advisor with expertise in analyzing student academic performance across multiple tests and subjects.\n",
    "\n",
    "Your primary responsibilities include:\n",
    "\n",
    "## Performance Analysis:\n",
    "- Analyze student performance data from multiple tests across different subjects\n",
    "- Focus primarily on test_details array as it provides the most accurate representation of student performance\n",
    "- Identify performance trends across multiple tests in the same subject\n",
    "- Compare performance across different subjects to identify relative strengths and weaknesses\n",
    "- Use topic_details for supplementary insights about topic-wise average performance\n",
    "\n",
    "## Insight Generation:\n",
    "- Generate comprehensive subject-wise analysis showing performance trends\n",
    "- Identify strong topics (>75% average performance) and weak topics (<65% average performance)\n",
    "- Prioritize focus areas based on consistent poor performance across multiple tests\n",
    "- Provide specific, actionable improvement strategies for each weak area\n",
    "- Consider the number of tests taken per topic when making assessments\n",
    "\n",
    "## Question Generation Guidelines:\n",
    "- Generate 6-8 practice questions for all the topics that are asked in the tests\n",
    "- For weak topics , generate 6-8 questions each for that particular topic.\n",
    "- Each topic should have atleast one question listed , and if there is not then your job will be considered a failure.\n",
    "- And for strong and practice topics , generate 3-4 questions each.\n",
    "- Focus on topics that appear in priority_focus_areas\n",
    "- Create a balanced mix of difficulty levels: 2-3 easy, 2-3 medium, 2-3 hard questions per topic\n",
    "- For Math subjects: Generate questions similar to provided sample questions with appropriate difficulty progression\n",
    "- For English Grammar: Create questions following the style and pattern of provided samples\n",
    "- For English Literature/Stories: Use questions directly from provided samples when available\n",
    "- For Social Studies: Use questions directly from provided samples when available\n",
    "- Exclude questions that require images or visual elements\n",
    "- Ensure questions are grade-appropriate and align with curriculum standards\n",
    "- The curriculum standards are based on CBSE and GSEB.\n",
    "\n",
    "## Parent Communication:\n",
    "- Write in simple, clear English that Indian parents can easily understand\n",
    "- Address the student by name throughout for personalization\n",
    "- Use a supportive, encouraging tone while being honest about areas needing improvement\n",
    "- Provide specific, practical advice that parents can implement at home\n",
    "- Include references to attendance and teacher remarks when relevant\n",
    "- Focus on growth mindset and positive reinforcement\n",
    "- Avoid overly technical educational jargon\n",
    "\n",
    "## Key Principles:\n",
    "- Prioritize insights from test_details over other data sources\n",
    "- Be specific about which tests showed improvement or decline\n",
    "- Provide context for performance (e.g., \"improved from 65% in Test 1 to 78% in Test 2\")\n",
    "- Address the student using male/female pronouns when gender-specific language is needed and if you are unaware just use \"the student\"\n",
    "- Use the provided sample questions as a guide for generating new questions\n",
    "- Ensure all generated questions are relevant to the identified weak topics\n",
    "- Maintain a positive, constructive tone throughout the analysis\n",
    "- Focus on actionable steps parents can take to support their child's learning\n",
    "- Avoid making assumptions about the student's abilities or background\n",
    "- Maintain an encouraging, growth-focused approach throughout all content\n",
    "- Ensure all recommendations are actionable and realistic for home implementation\n",
    "\n",
    "Remember: Your goal is to help parents understand exactly where their child stands academically and provide them with clear, practical steps to support their child's improvement at home.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39d413",
   "metadata": {},
   "source": [
    "<h1>Create User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_prompt(user_data):\n",
    "    prompt = f\"\"\"\n",
    "    You are provided with comprehensive student performance data below:\n",
    "    \n",
    "    **Student Data:**\n",
    "    {user_data}\n",
    "    \n",
    "    **Your Tasks:**\n",
    "    \n",
    "    1. **Analyze Performance Trends:**\n",
    "       - Focus primarily on the 'test_details' array to understand actual test performance\n",
    "       - Look for patterns across multiple tests in the same subject\n",
    "       - Identify subjects and topics where performance is declining, improving, or consistent\n",
    "       - Use 'topic_details' for additional context on average performance per topic\n",
    "    \n",
    "    2. **Generate Comprehensive Insights:**\n",
    "       - Create subject-wise analysis showing performance trends\n",
    "       - Identify priority focus areas based on consistent poor performance\n",
    "       - Provide specific improvement strategies for weak topics\n",
    "       - Highlight strengths and areas where the student is performing well\n",
    "    \n",
    "    3. **Create Targeted Practice Questions:**\n",
    "       - Generate questions for all topics that are asked in the tests\n",
    "       - For weak topics, generate 6-8 questions each\n",
    "       - For strong and practice topics, generate 3-4 questions each\n",
    "       - Ensure a balanced mix of difficulty levels: 2-3 easy, 2-3 medium, 2-3 hard questions per topic\n",
    "       - For Math subjects, create questions similar to provided samples with appropriate difficulty progression\n",
    "       - For English Grammar, create questions following the style and pattern of provided samples\n",
    "       - For English Literature/Stories, use questions directly from provided samples when available\n",
    "       - For Social Studies, use questions directly from provided samples when available\n",
    "       - Exclude questions that require images or visual elements\n",
    "       - Ensure questions are grade-appropriate and align with curriculum standards (CBSE and GSEB)\n",
    "       - Use the sample questions provided below as reference for style and difficulty\n",
    "       - Ensure questions match the academic level and curriculum requirements\n",
    "       - Focus on topics that appear in your priority_focus_areas analysis\n",
    "    \n",
    "    **Sample Questions for Reference:**\n",
    "    {questions_for_topics_asked_in_examination}\n",
    "    \n",
    "    **Important Guidelines:**\n",
    "    - Weight your analysis heavily toward test_details as it shows actual test performance\n",
    "    - Be specific about which tests showed what performance levels\n",
    "    - Provide context for performance changes across multiple tests\n",
    "    - Generate questions only for improvement areas, not for strong topics\n",
    "    - Ensure parent recommendations are practical and implementable at home\n",
    "    \n",
    "    Please provide your response in the required JSON format with comprehensive insights and targeted practice questions.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(user_data):\n",
    "    USER_PROMPT = create_user_prompt(user_data)\n",
    "    return USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c6644",
   "metadata": {},
   "source": [
    "<h1>Get Response Format</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_format():\n",
    "    return {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"quiz_schema\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"parent_recommendations\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A comprehensive, personalized note for parents with specific recommendations for improvement, written in simple English that Indian parents can easily understand.\",\n",
    "                    },\n",
    "                    \"student_insights\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"Detailed analysis of student's academic performance across all subjects and tests.\",\n",
    "                        \"properties\": {\n",
    "                            \"overall_performance\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Overall assessment of student's academic performance across all subjects.\"\n",
    "                            },\n",
    "                            \"subject_wise_analysis\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Subject-wise detailed analysis based on test performance.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"subject\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Name of the subject (e.g., Maths, English, Physics, etc.)\"\n",
    "                                        },\n",
    "                                        \"performance_trend\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Analysis of performance trend across multiple tests in this subject\"\n",
    "                                        },\n",
    "                                        \"strong_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student performed well (>75% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"weak_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student needs improvement (<65% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"improvement_recommendations\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Specific actionable recommendations for improvement in this subject\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"subject\", \"performance_trend\", \"strong_topics\", \"weak_topics\", \"improvement_recommendations\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            },\n",
    "                            \"priority_focus_areas\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Top 3-5 priority areas that need immediate attention based on test performance\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"topic\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Name of the topic that needs focus\"\n",
    "                                        },\n",
    "                                        \"subject\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Subject this topic belongs to\"\n",
    "                                        },\n",
    "                                        \"current_performance\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Current performance level in this topic\"\n",
    "                                        },\n",
    "                                        \"why_priority\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Explanation of why this topic needs immediate attention\"\n",
    "                                        },\n",
    "                                        \"improvement_strategy\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Specific strategy to improve in this topic\"\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"topic\", \"subject\", \"current_performance\", \"why_priority\", \"improvement_strategy\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"overall_performance\", \"subject_wise_analysis\", \"priority_focus_areas\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"practice_questions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Practice questions organized by topics.For strong and practice topics, generate 3-4 questions each. For weak topics, generate 6-8 questions each.Each topic should have at least one question listed, and if there is not then your job will be considered a failure.\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"topic\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The topic for which these questions are generated\"\n",
    "                                },\n",
    "                                \"subject\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The subject this topic belongs to\"\n",
    "                                },\n",
    "                                \"questions\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Array of 6-8 practice questions for this topic\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"type\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"mcq\", \"descriptive\"],\n",
    "                                                \"description\": \"The type of the question.\"\n",
    "                                            },\n",
    "                                            \"questionId\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"Unique identifier for the question\"\n",
    "                                            },\n",
    "                                            \"question\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The question text. All math equations must be wrapped between $ and $.\"\n",
    "                                            },\n",
    "                                            \"subject\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The subject of the question.\"\n",
    "                                            },\n",
    "                                            \"chapter\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The chapter or topic this question belongs to.\"\n",
    "                                            },\n",
    "                                            \"marks\": {\n",
    "                                                \"type\": \"number\",\n",
    "                                                \"description\": \"The marks assigned for the question.\"\n",
    "                                            },\n",
    "                                            \"options\": {\n",
    "                                                \"anyOf\": [\n",
    "                                                    {\n",
    "                                                        \"type\": \"array\",\n",
    "                                                        \"description\": \"Options for multiple choice questions\",\n",
    "                                                        \"items\": {\n",
    "                                                            \"type\": \"object\",\n",
    "                                                            \"properties\": {\n",
    "                                                                \"key\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The key for the option (A, B, C, D)\"\n",
    "                                                                },\n",
    "                                                                \"option\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The option text. Math equations wrapped in $ and $.\"\n",
    "                                                                },\n",
    "                                                                \"imageUrl\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"Image URL if needed, empty string otherwise\"\n",
    "                                                                }\n",
    "                                                            },\n",
    "                                                            \"required\": [\"key\", \"option\", \"imageUrl\"],\n",
    "                                                            \"additionalProperties\": False\n",
    "                                                        }\n",
    "                                                    },\n",
    "                                                    {\n",
    "                                                        \"type\": \"null\",\n",
    "                                                        \"description\": \"Null for descriptive questions\"\n",
    "                                                    }\n",
    "                                                ]\n",
    "                                            },\n",
    "                                            \"difficulty\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "                                                \"description\": \"The difficulty level of the question.\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"required\": [\"type\", \"questionId\", \"question\", \"subject\", \"chapter\", \"marks\", \"options\", \"difficulty\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"topic\", \"subject\", \"questions\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"parent_recommendations\", \"student_insights\", \"practice_questions\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17fd82",
   "metadata": {},
   "source": [
    "<h1>Initiate OpenAI Client </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.api_key = \"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\"\n",
    "def get_questions_and_insights_for_individual_student(user_data):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "      model=MODEL,\n",
    "      messages=[\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": get_user_prompt(user_data)},\n",
    "      ],\n",
    "      response_format=get_response_format()\n",
    "    )\n",
    "    usage = completion.usage\n",
    "    completion_tokens = usage.completion_tokens\n",
    "    prompt_tokens     = usage.prompt_tokens\n",
    "    total_tokens      = usage.total_tokens\n",
    "    print_single_value_in_table(\"completion_tokens\",completion_tokens)\n",
    "    print_single_value_in_table(\"prompt tokens\", prompt_tokens)\n",
    "    print_single_value_in_table(\"total tokens\", total_tokens)\n",
    "    input_price = (prompt_tokens * 1.1)/1000000\n",
    "    output_price = (completion_tokens * 4.4)/1000000\n",
    "    final_cost = (input_price + output_price)*90\n",
    "    return [json.loads(completion.choices[0].message.content),str(round(final_cost, 2))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca81e03",
   "metadata": {},
   "source": [
    "<h1>Generate Report For Each Student (Class Comparison)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d417f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_individual_student_report(csv_path, student_name, output_folder):\n",
    "    # 1. Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 2. Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 3. Identify subjects and their test columns\n",
    "    subjects_info = _identify_subjects_and_tests(df.columns)\n",
    "    subjects = list(subjects_info.keys())\n",
    "\n",
    "    # 4. Replace 'AB' with NaN for calculations but keep original data for display\n",
    "    df_calc = df.copy()\n",
    "    for subject_data in subjects_info.values():\n",
    "        for test_col in subject_data['test_columns']:\n",
    "            df_calc[test_col] = pd.to_numeric(df_calc[test_col], errors='coerce')\n",
    "\n",
    "    # 5. Compute aggregated scores and class stats\n",
    "    aggregated_scores = _compute_aggregated_scores(df_calc, subjects_info)\n",
    "    class_stats = _compute_class_stats(aggregated_scores, subjects)\n",
    "\n",
    "    # 6. Locate the student row\n",
    "    student_df = df[df['Student Names'] == student_name]\n",
    "    if student_df.empty:\n",
    "        raise ValueError(f\"Student '{student_name}' not found\")\n",
    "    student = student_df.iloc[0]\n",
    "    \n",
    "    # 7. Compute student's aggregated scores\n",
    "    student_calc = df_calc[df_calc['Student Names'] == student_name].iloc[0]\n",
    "    student_aggregated = _compute_student_aggregated_scores(student_calc, subjects_info)\n",
    "    \n",
    "    # 8. Generate the PDF\n",
    "    output_path = _generate_student_pdf(\n",
    "        student, student_calc, student_aggregated, subjects_info, subjects, \n",
    "        class_stats, output_folder, aggregated_scores\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def _identify_subjects_and_tests(columns):\n",
    "    \"\"\"\n",
    "    Identify subjects and their corresponding test columns from dataframe columns.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject_name: {'test_columns': [col1, col2, ...], 'topic_columns': [...]}}\n",
    "    \"\"\"\n",
    "    subjects_info = {}\n",
    "    \n",
    "    # Filter out non-subject columns\n",
    "    excluded_cols = {'Student Names', 'Attendance', \"Teacher's Remarks\"}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in excluded_cols:\n",
    "            continue\n",
    "            \n",
    "        # Check if it's a topic column\n",
    "        if 'Topics' in col:\n",
    "            continue\n",
    "            \n",
    "        # Extract base subject name (remove _Test1, _Test2, etc.)\n",
    "        if '_Test' in col:\n",
    "            base_subject = col.split('_Test')[0]\n",
    "        else:\n",
    "            base_subject = col\n",
    "            \n",
    "        if base_subject not in subjects_info:\n",
    "            subjects_info[base_subject] = {\n",
    "                'test_columns': [],\n",
    "                'topic_columns': []\n",
    "            }\n",
    "        \n",
    "        # Add to test columns if it's a test column\n",
    "        if '_Test' in col or col == base_subject:\n",
    "            subjects_info[base_subject]['test_columns'].append(col)\n",
    "    \n",
    "    # Now find topic columns for each subject\n",
    "    for col in columns:\n",
    "        if 'Topics' in col:\n",
    "            # Try to match with subjects\n",
    "            for subject in subjects_info.keys():\n",
    "                if subject in col:\n",
    "                    subjects_info[subject]['topic_columns'].append(col)\n",
    "                    break\n",
    "    \n",
    "    return subjects_info\n",
    "\n",
    "\n",
    "def _compute_aggregated_scores(df_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for each student and subject.\n",
    "    Uses average of all tests for a subject, handling AB/NaN values properly.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: Student Names, Subject1_Avg, Subject2_Avg, etc.\n",
    "    \"\"\"\n",
    "    result_data = {'Student Names': df_calc['Student Names']}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            # Single test - just use that column\n",
    "            result_data[f\"{subject}_Avg\"] = df_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Multiple tests - compute average of available scores\n",
    "            test_data = df_calc[test_cols]\n",
    "            # Compute row-wise mean, ignoring NaN values\n",
    "            result_data[f\"{subject}_Avg\"] = test_data.mean(axis=1, skipna=True)\n",
    "    \n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "\n",
    "def _compute_student_aggregated_scores(student_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for a single student.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject: aggregated_score}\n",
    "    \"\"\"\n",
    "    student_scores = {}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            student_scores[subject] = student_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Compute average of available test scores\n",
    "            test_scores = [student_calc[col] for col in test_cols if pd.notna(student_calc[col])]\n",
    "            if test_scores:\n",
    "                student_scores[subject] = sum(test_scores) / len(test_scores)\n",
    "            else:\n",
    "                student_scores[subject] = float('nan')  # All tests were AB/NaN\n",
    "    \n",
    "    return student_scores\n",
    "\n",
    "\n",
    "def _compute_class_stats(aggregated_scores, subjects):\n",
    "    \"\"\"\n",
    "    Compute class statistics using aggregated scores.\n",
    "    \"\"\"\n",
    "    class_stats = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        col_name = f\"{subject}_Avg\"\n",
    "        if col_name in aggregated_scores.columns:\n",
    "            class_stats[subject] = {\n",
    "                'highest': aggregated_scores[col_name].max(),\n",
    "                'lowest': aggregated_scores[col_name].min(),\n",
    "                'average': aggregated_scores[col_name].mean()\n",
    "            }\n",
    "    \n",
    "    return class_stats\n",
    "\n",
    "\n",
    "def _generate_student_pdf(student, student_calc, student_aggregated, subjects_info, \n",
    "                         subjects, class_stats, output_folder, aggregated_scores):\n",
    "    \"\"\"\n",
    "    Internal helper to build the PDF for one student with compact layout.\n",
    "    Handles multiple tests per subject and improved strongest/weakest analysis.\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Use Times as it's closer to the \"math\" font in the template\n",
    "    pdf.set_font('Times', 'B', 14)\n",
    "\n",
    "    # Header - more compact\n",
    "    name = student['Student Names']\n",
    "    pdf.cell(0, 8, \"Student Performance Report\", ln=1, align='C')\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Attendance with less spacing (if available)\n",
    "    if 'Attendance' in student.index:\n",
    "        att = student['Attendance']\n",
    "        att_pct = (int(att) / ATTENDANCE_DAYS) * 100 if pd.notna(att) else 0\n",
    "        pdf.cell(0, 6, f\"Attendance: {att} / {ATTENDANCE_DAYS} ({att_pct:.1f}%)\", ln=1, align='C')\n",
    "    \n",
    "    # Minimal spacing before chart\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # Comparison chart - increased height\n",
    "    chart_path = create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info)\n",
    "    pdf.image(chart_path, x=20, w=170, h=75)\n",
    "    os.remove(chart_path)\n",
    "    \n",
    "    # Compact spacing\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # SECTION: Subject Analysis with underlined header\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Subject Analysis\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Format subject analysis showing individual tests and average\n",
    "    pct_map = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        info = subjects_info[subject]\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        # Get subject average score\n",
    "        avg_score = student_aggregated.get(subject)\n",
    "        \n",
    "        if pd.isna(avg_score):\n",
    "            pdf.cell(0, 6, f\"{subject}: All tests absent\", ln=1)\n",
    "        else:\n",
    "            # Show individual test scores and average\n",
    "            test_details = []\n",
    "            for col in test_cols:\n",
    "                raw_score = student[col] if col in student.index else 'AB'\n",
    "                if raw_score == 'AB' or pd.isna(raw_score):\n",
    "                    test_details.append(\"AB\")\n",
    "                else:\n",
    "                    test_details.append(f\"{raw_score}\")\n",
    "            \n",
    "            # Assuming max score is 100 for percentage calculation\n",
    "            # You may need to adjust this based on your scoring system\n",
    "            avg_pct = (avg_score / MAX_SCORE) * 100\n",
    "            pct_map[subject] = avg_pct\n",
    "            \n",
    "            if len(test_cols) == 1:\n",
    "                pdf.cell(0, 6, f\"{subject}: {test_details[0]}/{MAX_SCORE} ({avg_pct:.1f}%)\", ln=1)\n",
    "            else:\n",
    "                tests_str = \" | \".join([f\"T{i+1}: {score}\" for i, score in enumerate(test_details)])\n",
    "                pdf.cell(0, 6, f\"{subject}: {tests_str} | Avg: {avg_score:.1f}/{MAX_SCORE} ({avg_pct:.1f}%)\", ln=1)\n",
    "\n",
    "    # SECTION: Performance Highlights with improved logic\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Performance Highlights\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Only show highlights if student has taken at least one test\n",
    "    if pct_map:\n",
    "        # Improved strongest/weakest subject logic\n",
    "        performance_analysis = _analyze_student_performance(pct_map, aggregated_scores, subjects, name)\n",
    "        \n",
    "        # Display strongest subjects (top 30% performance or above 80%)\n",
    "        if performance_analysis['strong_subjects']:\n",
    "            strong_subjects_str = \", \".join([f\"{subj} ({pct:.1f}%)\" \n",
    "                                           for subj, pct in performance_analysis['strong_subjects']])\n",
    "            pdf.cell(0, 6, f\"Strong Subjects: {strong_subjects_str}\", ln=1)\n",
    "        \n",
    "        # Display subjects needing improvement\n",
    "        if performance_analysis['improvement_subjects']:\n",
    "            pdf.cell(0, 6, \"Subjects Needing Improvement:\", ln=1)\n",
    "            for subj, pct, reason in performance_analysis['improvement_subjects']:\n",
    "                pdf.cell(0, 6, f\"- {subj} ({pct:.1f}%) - {reason}\", ln=1)\n",
    "        \n",
    "        # Overall performance summary\n",
    "        pdf.cell(0, 6, f\"Overall Average: {performance_analysis['overall_avg']:.1f}%\", ln=1)\n",
    "        \n",
    "        if performance_analysis['consistency_note']:\n",
    "            pdf.cell(0, 6, performance_analysis['consistency_note'], ln=1)\n",
    "    else:\n",
    "        pdf.cell(0, 6, \"No test scores available for performance analysis\", ln=1)\n",
    "\n",
    "    # SECTION: Teacher's Remarks (if available)\n",
    "    if \"Teacher's Remarks\" in student.index:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Teacher's Remarks\", ln=1)\n",
    "        \n",
    "        has_remarks = pd.notna(student[\"Teacher's Remarks\"]) and student[\"Teacher's Remarks\"].strip() != \"\"\n",
    "        \n",
    "        if has_remarks:\n",
    "            pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.multi_cell(0, 5, student[\"Teacher's Remarks\"])\n",
    "        else:\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.cell(0, 5, \"No remarks from teacher\", ln=1)\n",
    "\n",
    "    # SECTION: Topics Covered - consolidate from all tests\n",
    "    remaining_height = 270 - pdf.get_y()\n",
    "    \n",
    "    if remaining_height > 20:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Topics Covered\", ln=1)\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(1)\n",
    "        \n",
    "        pdf.set_font('Times', '', 10)\n",
    "        for subject in subjects:\n",
    "            info = subjects_info[subject]\n",
    "            topic_cols = info['topic_columns']\n",
    "            \n",
    "            if topic_cols:\n",
    "                all_topics = set()\n",
    "                for col in topic_cols:\n",
    "                    if col in student.index and pd.notna(student[col]):\n",
    "                        # Split topics by comma and add to set to avoid duplicates\n",
    "                        topics = [t.strip() for t in str(student[col]).split(',')]\n",
    "                        all_topics.update(topics)\n",
    "                \n",
    "                if all_topics:\n",
    "                    topics_text = f\"{subject}: {', '.join(sorted(all_topics))}\"\n",
    "                    if len(topics_text) > 100:\n",
    "                        topics_text = topics_text[:97] + \"...\"\n",
    "                    pdf.multi_cell(0, 5, topics_text)\n",
    "\n",
    "    # Save\n",
    "    safe_name = name.replace(' ', '_')\n",
    "    path = os.path.join(output_folder, f\"{safe_name}_report.pdf\")\n",
    "    pdf.output(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def _analyze_student_performance(pct_map, aggregated_scores, subjects, student_name):\n",
    "    \"\"\"\n",
    "    Improved performance analysis logic that considers:\n",
    "    1. Relative performance vs class\n",
    "    2. Absolute performance thresholds\n",
    "    3. Consistency across subjects\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        'strong_subjects': [],\n",
    "        'improvement_subjects': [],\n",
    "        'overall_avg': 0,\n",
    "        'consistency_note': ''\n",
    "    }\n",
    "    \n",
    "    if not pct_map:\n",
    "        return analysis\n",
    "    \n",
    "    # Calculate overall average\n",
    "    analysis['overall_avg'] = sum(pct_map.values()) / len(pct_map)\n",
    "    \n",
    "    # Calculate class percentiles for each subject\n",
    "    subject_percentiles = {}\n",
    "    for subject in subjects:\n",
    "        if subject in pct_map:\n",
    "            col_name = f\"{subject}_Avg\"\n",
    "            if col_name in aggregated_scores.columns:\n",
    "                all_scores = aggregated_scores[col_name].dropna()\n",
    "                if not all_scores.empty:\n",
    "                    student_score = pct_map[subject] * 100 / 100  # Convert back to raw score\n",
    "                    percentile = (all_scores < student_score).sum() / len(all_scores) * 100\n",
    "                    subject_percentiles[subject] = percentile\n",
    "    \n",
    "    # Identify strong subjects (above 80% OR top 25% of class)\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        if pct >= 80 or percentile >= 75:\n",
    "            analysis['strong_subjects'].append((subject, pct))\n",
    "    \n",
    "    # Sort strong subjects by percentage\n",
    "    analysis['strong_subjects'].sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Identify subjects needing improvement\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        reasons = []\n",
    "        \n",
    "        if pct < 60:\n",
    "            reasons.append(\"below 60%\")\n",
    "        elif pct < 75 and percentile < 50:\n",
    "            reasons.append(\"below class median\")\n",
    "        elif percentile < 25:\n",
    "            reasons.append(\"bottom 25% of class\")\n",
    "        \n",
    "        if reasons:\n",
    "            analysis['improvement_subjects'].append((subject, pct, \" & \".join(reasons)))\n",
    "    \n",
    "    # Sort improvement subjects by percentage (lowest first)\n",
    "    analysis['improvement_subjects'].sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Consistency analysis\n",
    "    if len(pct_map) > 1:\n",
    "        scores = list(pct_map.values())\n",
    "        score_range = max(scores) - min(scores)\n",
    "        if score_range < 10:\n",
    "            analysis['consistency_note'] = \"Performance is very consistent across subjects\"\n",
    "        elif score_range > 30:\n",
    "            analysis['consistency_note'] = \"Performance varies significantly across subjects\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info):\n",
    "    \"\"\"\n",
    "    Build and save a matplotlib chart comparing this student's aggregated scores\n",
    "    against class high/low/average in each subject, with percentages over all bars.\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Set Times font family explicitly\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    matplotlib.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif', 'serif']\n",
    "\n",
    "    # Prepare data arrays\n",
    "    marks = []\n",
    "    absent_subjects = []\n",
    "    for s in subjects:\n",
    "        agg = student_aggregated.get(s)\n",
    "        if pd.isna(agg):\n",
    "            marks.append(0)\n",
    "            absent_subjects.append(s)\n",
    "        else:\n",
    "            marks.append(agg)\n",
    "\n",
    "    average = [class_stats[s]['average'] for s in subjects]\n",
    "    highest = [class_stats[s]['highest'] for s in subjects]\n",
    "    lowest  = [class_stats[s]['lowest']  for s in subjects]\n",
    "\n",
    "\n",
    "    # Colors\n",
    "    student_color = '#4570B7'\n",
    "    avg_color     = '#9FA7B2'\n",
    "    high_color    = '#97D077'\n",
    "    low_color     = '#F08B7E'\n",
    "    absent_color  = '#E8E8E8'\n",
    "\n",
    "    # Figure setup\n",
    "    plt.figure(figsize=(7.5, 5.0))\n",
    "    x = np.arange(len(subjects))\n",
    "    width = 0.18\n",
    "\n",
    "    # Plot bars\n",
    "    avg_bars     = plt.bar(x,           average, width, color=avg_color,    edgecolor='white', linewidth=0.5, label='Class Average', zorder=1)\n",
    "    high_bars    = plt.bar(x + width,   highest, width,  color=high_color,   edgecolor='white', linewidth=0.5, label='Class Highest', zorder=1)\n",
    "    low_bars     = plt.bar(x - width,   lowest,  width,  color=low_color,    edgecolor='white', linewidth=0.5, label='Class Lowest', zorder=1)\n",
    "    student_bars = plt.bar(\n",
    "        x + 2*width,\n",
    "        marks,\n",
    "        width,\n",
    "        color=[absent_color if s in absent_subjects else student_color for s in subjects],\n",
    "        edgecolor='white',\n",
    "        linewidth=1.0,\n",
    "        label=student['Student Names'],\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "    # Annotate every bar with a percentage or \"Absent\"\n",
    "    bar_sets = [\n",
    "        (avg_bars,     average),\n",
    "        (high_bars,    highest),\n",
    "        (low_bars,     lowest),\n",
    "        (student_bars, marks),\n",
    "    ]\n",
    "    for bars, values in bar_sets:\n",
    "        for idx, rect in enumerate(bars):\n",
    "            height = rect.get_height()\n",
    "            # For student bars where the student was absent:\n",
    "            if bars is student_bars and subjects[idx] in absent_subjects:\n",
    "                label = \"Absent\"\n",
    "            else:\n",
    "                # value is out of 100, so it's directly percentage\n",
    "                label = f\"{values[idx]:.1f}%\"\n",
    "            plt.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height + MAX_SCORE * 0.01,  # small offset above bar\n",
    "                label,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8,\n",
    "                family='Times New Roman'\n",
    "            )\n",
    "\n",
    "    # Axes & titles\n",
    "    plt.xlabel('Subjects', fontsize=10, family='Times New Roman')\n",
    "    plt.ylabel('Average Score', fontsize=10, family='Times New Roman')\n",
    "    plt.suptitle(f\"{student['Student Names']}'s Performance\",\n",
    "                 fontsize=12, family='Times New Roman', y=0.98)\n",
    "    plt.title(\"Comparison with class statistics (test averages)\",\n",
    "              fontsize=9, family='Times New Roman', pad=10)\n",
    "\n",
    "    plt.xticks(x + width/2, subjects, fontsize=10, family='Times New Roman')\n",
    "    plt.ylim(0, MAX_SCORE * 1.1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.2, zorder=0)\n",
    "\n",
    "    # Legend\n",
    "    legend_elems = [\n",
    "        Patch(facecolor=student_color, edgecolor='white', label=student['Student Names']),\n",
    "        Patch(facecolor=avg_color,     edgecolor='white', label='Class Average'),\n",
    "        Patch(facecolor=high_color,    edgecolor='white', label='Class Highest'),\n",
    "        Patch(facecolor=low_color,     edgecolor='white', label='Class Lowest'),\n",
    "    ]\n",
    "    if absent_subjects:\n",
    "        legend_elems.append(Patch(facecolor=absent_color, edgecolor='white', label='Absent'))\n",
    "    plt.legend(handles=legend_elems, loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "               fontsize=9, framealpha=0.7, edgecolor='#CCCCCC',\n",
    "               ncol=min(5, len(legend_elems)), prop={'family': 'Times New Roman'})\n",
    "\n",
    "    # Clean up\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for lbl in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        lbl.set_fontname('Times New Roman')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.97])\n",
    "\n",
    "    # Save and return\n",
    "    fname = f\"temp_chart_{student['Student Names'].replace(' ', '_')}.png\"\n",
    "    plt.savefig(fname, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51fc68",
   "metadata": {},
   "source": [
    "<h1>Convert worksheet html to pdf </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf415a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_latex_to_mathml(html_content):\n",
    "    \"\"\"\n",
    "    Convert LaTeX equations enclosed in $ signs to MathML format.\n",
    "    \n",
    "    Args:\n",
    "        html_content (str): HTML content with LaTeX equations\n",
    "        \n",
    "    Returns:\n",
    "        str: HTML content with LaTeX equations replaced by MathML\n",
    "    \"\"\"\n",
    "    # Regular expression to find LaTeX expressions enclosed in $ signs\n",
    "    # This handles both inline math ($...$) and display math ($$...$$)\n",
    "    pattern = r'\\$\\$(.*?)\\$\\$|\\$(.*?)\\$'\n",
    "    \n",
    "    def replace_math(match):\n",
    "        if match.group(1) is not None:  # Display math ($$...$$)\n",
    "            latex_expr = match.group(1)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='block')\n",
    "            return mathml\n",
    "        else:  # Inline math ($...$)\n",
    "            latex_expr = match.group(2)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='inline')\n",
    "            return mathml\n",
    "    \n",
    "    # Replace all matches with MathML\n",
    "    return re.sub(pattern, replace_math, html_content)\n",
    "\n",
    "def download_html_to_pdf(s3_url, output_pdf_path):\n",
    "    \"\"\"\n",
    "    Enhanced version with better error handling and debugging\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    print(f\"=== Python PDF Download Debug ===\")\n",
    "    print(f\"S3 URL: {s3_url}\")\n",
    "    print(f\"Output path: {output_pdf_path}\")\n",
    "    \n",
    "    output_dir = os.path.dirname(output_pdf_path)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(\"Directory created/verified\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Testing HTML accessibility...\")\n",
    "        html_response = requests.get(s3_url, timeout=30)\n",
    "        html_response.raise_for_status()\n",
    "        print(f\"HTML response status: {html_response.status_code}\")\n",
    "        print(f\"HTML content length: {len(html_response.text)}\")\n",
    "        \n",
    "        if len(html_response.text) < 100:\n",
    "            print(\"WARNING: HTML content seems too short\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERROR: Failed to fetch HTML from S3: {e}\")\n",
    "        return {\"success\": False, \"error\": f\"Cannot access HTML: {str(e)}\"}\n",
    "    \n",
    "    api_url = DOWNLOAD_FROM_S3_LINK\n",
    "    payload = {\n",
    "        \"s3Link\": s3_url,\n",
    "        \"pathToSave\": output_pdf_path,\n",
    "    }\n",
    "    \n",
    "    print(f\"API URL: {api_url}\")\n",
    "    print(f\"Payload: {payload}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Making API request...\")\n",
    "        response = requests.post(api_url, json=payload, timeout=120)\n",
    "        print(f\"API response status: {response.status_code}\")\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        print(f\"API response: {result}\")\n",
    "        return result.get(\"path\")\n",
    "    \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"ERROR: API request timed out\")\n",
    "        return {\"success\": False, \"error\": \"Request timed out\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERROR: API request failed - {e}\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Unexpected error - {e}\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f736e",
   "metadata": {},
   "source": [
    "<h1>Save Student Record in Database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16531eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_student_record(student_name, standard,worksheet_s3_link,cost,school_name='Surya International School'):\n",
    "    \"\"\"\n",
    "    Sends a POST to your Express endpoint to save a new student record.\n",
    "\n",
    "    Args:\n",
    "        student_name (str): Name of the student.\n",
    "        school_name (str): Name of the student's school.\n",
    "        standard (str): Grade or standard of the student.\n",
    "        worksheet_s3_link (str): URL to the student’s worksheet HTML in S3.\n",
    "        cost (int): Associated cost.\n",
    "        base_url (str): Base URL of your server (no trailing slash).\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed JSON response from the server, or None on error.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"studentName\": student_name,\n",
    "        \"schoolName\": school_name,\n",
    "        \"standard\": standard,\n",
    "        \"worksheet_s3_link\": worksheet_s3_link,\n",
    "        \"cost\": cost,\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(SAVE_STUDENT_COST_PER_WORKSHEET, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        err_box_red(\"[ERROR] Failed to save student record:\", err)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda05513",
   "metadata": {},
   "source": [
    "<h1>Generate worksheet and combine worksheet and report</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_worksheet_for_students_and_combine_report(data):\n",
    "    TOTAL_COST = 0\n",
    "    output_paths = []\n",
    "    for student in data:\n",
    "        print_single_value_in_table(\"Student Being Processed\",student['name'])\n",
    "        student_name = student['name']\n",
    "        # [questions_and_insights_for_student,cost] = get_questions_and_insights_for_individual_student(student)\n",
    "        [questions_and_insights_for_student,cost] = [{'parent_recommendations': 'Dear Parent,\\n\\nBob is doing well in both English and Maths. He attended 23 classes and shows good understanding of number concepts (up to 500 and up to 1000) and basic grammar. To help him improve further:\\n\\n1. English Articles & Nouns:\\n   - Encourage Bob to read short stories or picture books and ask him to point out words starting with a, an, or the.\\n   - Play a simple game at home: give him everyday objects (apple, book, umbrella) and have him say the correct article before naming them.\\n   - Ask him to pick any sentence and circle all the naming words (people, places, things) he finds.\\n\\n2. Maths Large Numbers:\\n   - Use real-life contexts: while shopping, ask Bob to read prices or count rupees and paise, reinforcing numbers up to 1000.\\n   - Challenge him with simple word problems involving addition or subtraction of numbers within 500–1000.\\n\\n3. General Tips:\\n   - Praise his correct answers to build confidence and correct mistakes gently.\\n   - Keep practice sessions short (10–15 minutes) but regular (3–4 times a week).\\n   - Review his workbook or test papers together and discuss one new concept at a time.\\n\\nWith consistent practice and your support at home, Bob will continue to improve and enjoy learning!', 'student_insights': {'overall_performance': 'Bob has a solid start: 88% in Maths and 78% in English. His number skills are strong, and he shows good basic grammar understanding. Continued focused practice will help him reach even higher.', 'subject_wise_analysis': [{'subject': 'English', 'performance_trend': 'Bob scored 78% in his first English test (English_Test1). With only one test so far, performance is good but there is room to refine article usage and noun identification.', 'strong_topics': ['a an the', 'Naming words'], 'weak_topics': [], 'improvement_recommendations': ['Practice using articles (a, an, the) in daily conversation.', 'Read short passages and circle all naming words.', 'Use flashcards of nouns and articles for quick drills.']}, {'subject': 'Maths', 'performance_trend': 'Bob scored 88% in his first Maths test (Maths_Test1), showing strong command of numbers up to 500 and 1000.', 'strong_topics': ['numbers upto 1000', 'numbers upto 500'], 'weak_topics': [], 'improvement_recommendations': ['Give Bob larger numbers in real contexts (prices, counts) to read aloud.', 'Introduce simple two-step word problems with numbers up to 1000.', 'Encourage mental math drills for faster recall.']}], 'priority_focus_areas': []}, 'practice_questions': [{'topic': 'a an the', 'subject': 'English', 'questions': [{'type': 'mcq', 'questionId': 'ENG-A1', 'question': 'Fill in the blank with the correct article: \"____ apple a day keeps the doctor away.\"', 'subject': 'English', 'chapter': 'Articles', 'marks': 1, 'options': [{'key': 'A', 'option': 'A', 'imageUrl': ''}, {'key': 'B', 'option': 'An', 'imageUrl': ''}, {'key': 'C', 'option': 'The', 'imageUrl': ''}, {'key': 'D', 'option': 'None', 'imageUrl': ''}], 'difficulty': 'easy'}, {'type': 'descriptive', 'questionId': 'ENG-A2', 'question': \"Fill in the blanks with 'a', 'an' or 'the':\\n1) She read ____ interesting story last night.\\n2) He is ____ tallest boy in his class.\", 'subject': 'English', 'chapter': 'Articles', 'marks': 4, 'options': None, 'difficulty': 'medium'}, {'type': 'mcq', 'questionId': 'ENG-A3', 'question': 'Choose the correct pair of articles: \"____ Mount Everest is ____ highest mountain in the world.\"', 'subject': 'English', 'chapter': 'Articles', 'marks': 1, 'options': [{'key': 'A', 'option': 'A, the', 'imageUrl': ''}, {'key': 'B', 'option': 'The, a', 'imageUrl': ''}, {'key': 'C', 'option': 'The, the', 'imageUrl': ''}, {'key': 'D', 'option': 'A, an', 'imageUrl': ''}], 'difficulty': 'hard'}]}, {'topic': 'Naming words', 'subject': 'English', 'questions': [{'type': 'mcq', 'questionId': 'ENG-N1', 'question': 'Identify the naming words (nouns) in the sentence: \"The cat sat on the mat.\"', 'subject': 'English', 'chapter': 'Naming words', 'marks': 1, 'options': [{'key': 'A', 'option': 'cat, sat', 'imageUrl': ''}, {'key': 'B', 'option': 'The, mat', 'imageUrl': ''}, {'key': 'C', 'option': 'cat, mat', 'imageUrl': ''}, {'key': 'D', 'option': 'sat, on', 'imageUrl': ''}], 'difficulty': 'easy'}, {'type': 'descriptive', 'questionId': 'ENG-N2', 'question': 'Circle the naming words in each sentence:\\n1) The children played in the garden.\\n2) A doctor works in a hospital.', 'subject': 'English', 'chapter': 'Naming words', 'marks': 4, 'options': None, 'difficulty': 'medium'}, {'type': 'mcq', 'questionId': 'ENG-N3', 'question': 'Which word is NOT a naming word?\\n\"run, school, apple, teacher\"', 'subject': 'English', 'chapter': 'Naming words', 'marks': 1, 'options': [{'key': 'A', 'option': 'run', 'imageUrl': ''}, {'key': 'B', 'option': 'school', 'imageUrl': ''}, {'key': 'C', 'option': 'apple', 'imageUrl': ''}, {'key': 'D', 'option': 'teacher', 'imageUrl': ''}], 'difficulty': 'hard'}]}]},100]\n",
    "        worksheet = requests.request(\n",
    "        method='POST',\n",
    "        url=GET_WORKSHEET_HTML,\n",
    "        json={'student_data':questions_and_insights_for_student}\n",
    "        )\n",
    "        print(questions_and_insights_for_student)\n",
    "        worksheet.raise_for_status()\n",
    "        student_specific_questions_and_insights = worksheet.json()\n",
    "        student_worksheet_link = student_specific_questions_and_insights['worksheet_html']\n",
    "        student_worksheet_pdf = download_html_to_pdf(student_worksheet_link,f\"./{STANDARD}/worksheets/{student_name}.pdf\")\n",
    "        print_single_value_in_table(\"student_worksheet_link\",student_worksheet_link)\n",
    "        print_single_value_in_table(\"student_worksheet_pdf_cost\",student_worksheet_pdf)\n",
    "        print_single_value_in_table(\"cost\",cost)\n",
    "        TOTAL_COST += float(cost)\n",
    "        student_comparison_report_pdf = generate_individual_student_report(FILE_DESTINATION,student_name,f\"./{STANDARD}/reports/\")\n",
    "        full_output_path = combine_pdfs(student_comparison_report_pdf,student_worksheet_pdf,f\"./{STANDARD}/final_reports\",f\"{student_name}_insights.pdf\")\n",
    "        save_student_record(student_name,standard=STANDARD,cost=cost,worksheet_s3_link=student_worksheet_link)\n",
    "        output_paths.append(full_output_path)\n",
    "    print_single_value_in_table(\"Total Cost\",TOTAL_COST)\n",
    "    return output_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f97a17",
   "metadata": {},
   "source": [
    "<h1>Merge Pdfs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pdfs(pdf_path1, pdf_path2, output_folder, output_filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    Combine two PDFs into a single PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path1 (str): Path to the first PDF file\n",
    "        pdf_path2 (str): Path to the second PDF file\n",
    "        output_folder (str): Folder where the combined PDF will be saved\n",
    "        output_filename (str): Filename for the combined PDF\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the combined PDF file\n",
    "    \"\"\"\n",
    "    final_path_for_worksheet = '../../AutoExam-QPG' + pdf_path2[1:]\n",
    "    print(\"====PDF Paths======\")\n",
    "    print(pdf_path1, pdf_path2, output_folder, output_filename,final_path_for_worksheet)\n",
    "    print(\"====PDF Paths End====\")\n",
    "    try:\n",
    "        # Create a PDF merger object\n",
    "        merger = PdfMerger()\n",
    "        \n",
    "        # Append the PDFs to the merger\n",
    "        merger.append(pdf_path1)\n",
    "        merger.append(final_path_for_worksheet)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        full_output_path = os.path.join(output_folder, output_filename)        \n",
    "        # Write the combined PDF to the output path\n",
    "        merger.write(full_output_path)\n",
    "        merger.close()\n",
    "        print_single_value_in_table(\"Successfully combined PDFs and saved to\",full_output_path)\n",
    "        return full_output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        err_box_red(\"Error combining pdfs\",e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_topics_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = read_data(FILE_DESTINATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_validated = validate_data(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_students_data = classify_students_by_topic(student_data_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_topics_asked_in_examination = fetch_questions_for_topics()\n",
    "print_question_data(questions_for_topics_asked_in_examination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_worksheet_for_students_and_combine_report(classified_students_data)\n",
    "print_single_value_in_table(\"Total cost\",TOTAL_COST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec426a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
