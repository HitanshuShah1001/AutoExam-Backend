{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30294341",
   "metadata": {},
   "source": [
    "<h1>Import Libs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f591104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openai as client\n",
    "import json\n",
    "from fpdf import FPDF\n",
    "from PyPDF2 import PdfMerger\n",
    "import re\n",
    "from utils import print_question_data\n",
    "from utils import print_single_value_in_table\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import numpy as np\n",
    "from utils import print_single_value_in_table\n",
    "from utils import err_box_red\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdb1bf",
   "metadata": {},
   "source": [
    "<h1>Constants</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE_ORIGIN = \"./student_data.csv\"\n",
    "FILE_DESTINATION = \"./student_data_final.csv\"\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS =  [\n",
    "        (\"Test1\", [\"Physics\", \"Maths\"], [\"electromagnetic waves,Nucleus\", \"Three Dimensional Geometry,Integrations\"]),\n",
    "        (\"Test2\", [\"Physics\", \"Maths\"], [\"Capacitance,Nucleus\", \"Exponential Functions,Conic Sections\"])\n",
    "    ]\n",
    "\n",
    "API_URL = 'http://localhost:3000/'\n",
    "AUTH_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MywiZW1haWxJZCI6ImhpdGFuc2h1c2hhaDVAZ21haWwuY29tIiwiaWF0IjoxNzQ2NzE5OTI4LCJleHAiOjE3NDY4MDYzMjh9.oofQw4zUkKWcGXvYyJjdK0Mp1y25dlxVSsTRizGEBPE\"\n",
    "GET_QUESTIONS_FOR_TOPICS = API_URL + 'question/get-questions-for-chapters'\n",
    "SAVE_STUDENT_COST_PER_WORKSHEET = API_URL + 'student-stat-analysis/save-student-cost-per-worksheet'\n",
    "DOWNLOAD_FROM_S3_LINK =  API_URL + 'student-stat-analysis/download-worksheet-from-s3-link'\n",
    "GET_WORKSHEET_HTML = API_URL + 'analysis/getWorksheetHTML'\n",
    "TOTAL_COST = 0\n",
    "CHAPTERS = [\"electromagnetic waves\",\"Nuclues\",\"Three Dimensional Geometry\",\"Exponential Functions\"]\n",
    "MODEL = 'o4-mini'\n",
    "ATTENDANCE_DAYS = 22\n",
    "STANDARD = 10\n",
    "MAX_SCORE = 100\n",
    "STRONG_THRESHOLD = 80\n",
    "WEAK_THRESHOLD = 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee38fe",
   "metadata": {},
   "source": [
    "<h1> Read Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        student_data = pd.read_csv(file_path)\n",
    "        return student_data\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        student_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        return student_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052edb",
   "metadata": {},
   "source": [
    "<h1>Add topics to csv Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f0b01",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Setup for this demo:\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS = [\n",
    "    (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "    (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "]\n",
    "FILE_ORIGIN      = \"input.csv\"\n",
    "FILE_DESTINATION = \"output.csv\"\n",
    "\n",
    "# Contents of `input.csv`:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance\n",
    "# Alice,85,88,90,92,12\n",
    "# Bob,78,82,88,85,23\n",
    "# Charlie,92,94,76,78,24\n",
    "\n",
    "add_topics_to_csv()\n",
    "\n",
    "# After running, `output.csv` will include extra columns:\n",
    "#   English Topics Test1, Maths Topics Test1,\n",
    "#   English Topics Test2, Maths Topics Test2,\n",
    "#   English All Topics,    Maths All Topics\n",
    "#\n",
    "# And sample rows become:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance,English Topics Test1,Maths Topics Test1,English Topics Test2,Maths Topics Test2,English All Topics,Maths All Topics\n",
    "# Alice,85,88,90,92,12,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Bob,78,82,88,85,23,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Charlie,92,94,76,78,24,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def add_topics_to_csv():\n",
    "    \"\"\"\n",
    "    - input_csv_path, output_csv_path: file paths.\n",
    "    - tests: a list of (test_name, subjects, topic_values), e.g.:\n",
    "        [\n",
    "          (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "          (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "        ]\n",
    "    \n",
    "    This will add columns:\n",
    "      English Topics Test1, Maths Topics Test1,\n",
    "      English Topics Test2, Maths Topics Test2,\n",
    "      English All Topics,  Maths All Topics\n",
    "    \"\"\"\n",
    "    # 1) Validate\n",
    "    for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        if len(subjects) != len(chapters):\n",
    "            raise ValueError(f\"subjects vs topic_values length mismatch in {test_name}\")\n",
    "\n",
    "    # 2) Collect all unique subjects and append it to all_subjects\n",
    "    all_subjects: List[str] = []\n",
    "    for _, subjects, _ in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        for subj in subjects:\n",
    "            if subj not in all_subjects:\n",
    "                all_subjects.append(subj)\n",
    "\n",
    "    # 3) Build per-test lookup maps\n",
    "    test_topic_maps: Dict[str, Dict[str, str]] = {\n",
    "        test_name: dict(zip(subjects, chapters))\n",
    "        for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS\n",
    "    }\n",
    "    \n",
    "    # {'Test1': {'English': 'a an the,Naming words', \n",
    "    #            'Maths': 'numbers upto 1000,numbers upto 500'}, \n",
    "    # 'Test2': {'English': 'Naming words,singular nouns and plural nouns', \n",
    "    #           'Maths': 'numbers upto 500,numbers'}\n",
    "    # }\n",
    "\n",
    "    # 4) Open I/O\n",
    "    with open(FILE_ORIGIN, newline=\"\", encoding=\"utf-8\") as fin, \\\n",
    "         open(FILE_DESTINATION, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        # a) build the new header\n",
    "        extra_cols: List[str] = []\n",
    "        for test_name in test_topic_maps:\n",
    "            for subj in all_subjects:\n",
    "                if subj in test_topic_maps[test_name]:\n",
    "                    extra_cols.append(f\"{subj} Topics {test_name}\")\n",
    "        for subj in all_subjects:\n",
    "            extra_cols.append(f\"{subj} All Topics\")\n",
    "\n",
    "        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames + extra_cols)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 5) Process each row\n",
    "        for row in reader:\n",
    "            # per-test columns\n",
    "            for test_name, topics_map in test_topic_maps.items():\n",
    "                for subj, topics_str in topics_map.items():\n",
    "                    row[f\"{subj} Topics {test_name}\"] = topics_str\n",
    "\n",
    "            # aggregated union columns\n",
    "            for subj in all_subjects:\n",
    "                all_toks: List[str] = []\n",
    "                for topics_map in test_topic_maps.values():\n",
    "                    if subj in topics_map:\n",
    "                        # split on comma, strip whitespace\n",
    "                        all_toks.extend([tok.strip() for tok in topics_map[subj].split(\",\")])\n",
    "                # dedupe & sort (optional)\n",
    "                unique = sorted(set(tok for tok in all_toks if tok))\n",
    "                row[f\"{subj} All Topics\"] = \", \".join(unique)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc8db",
   "metadata": {},
   "source": [
    "<h1>Validate Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e7c4d",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Example setup\n",
    "import pandas as pd\n",
    "from your_module import validate_data  # adjust import as needed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': ['85', '78', '92'],\n",
    "    'English_Test2': ['88', '82', '94'],\n",
    "    'Maths_Test1': ['90', '88', '76'],\n",
    "    'Maths_Test2': ['92', '85', '78'],\n",
    "    'English Topics Test1': ['A,B', 'A,B', 'A,B'],\n",
    "    'Maths Topics Test1': ['C,D', 'C,D', 'C,D'],\n",
    "    'English Topics Test2': ['B,C', 'B,C', 'B,C'],\n",
    "    'Maths Topics Test2': ['D,F', 'D,F', 'D,F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24]\n",
    "})\n",
    "\n",
    "clean_df = validate_data(df)\n",
    "\n",
    "# Console output:\n",
    "# Number of students loaded: 3\n",
    "# \n",
    "#   Student Names  English_Test1  English_Test2  Maths_Test1  Maths_Test2  English Topics Test1  Maths Topics Test1  English Topics Test2  Maths Topics Test2  English All Topics  Maths All Topics  Attendance\n",
    "#0         Alice              85              88           90           92                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          12\n",
    "#1           Bob              78              82           88           85                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          23\n",
    "#2       Charlie              92              94           76           78                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data(df: pd.DataFrame, test_mark_cols=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates a student score DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Strips whitespace from all string columns\n",
    "    - Normalizes topic strings like \"A,B\" to \"A, B\"\n",
    "    - Detects missing names or marks\n",
    "    - Standardizes absent marks as 'AB'\n",
    "    - Converts valid marks to int/float\n",
    "    - Fills missing attendance with 0\n",
    "    - Prints a summary of absentees and preview of data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input student data.\n",
    "        test_mark_cols (list[str], optional): List of test score columns to validate. If None, inferred.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and validated dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # 0. Remove leading/trailing spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # 1. Normalize topic columns — ensure \"A, B, C\" format\n",
    "    topic_cols = [c for c in df.columns if re.search(r'topics', c, re.IGNORECASE)]\n",
    "    for col in topic_cols:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: ', '.join(p.strip() for p in x.split(',')) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # 2. Check for missing student names and report\n",
    "    if df['Student Names'].isna().any():\n",
    "        missing = df[df['Student Names'].isna()].index.tolist()\n",
    "        print(f\"Missing Student Names in rows: {missing}\")\n",
    "\n",
    "    # 3. Identify test mark columns: use passed ones or detect those matching '<Subject>_Test<N>'\n",
    "    if test_mark_cols is None:\n",
    "        test_mark_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "\n",
    "    # Ensure the specified test mark columns exist in DataFrame\n",
    "    missing_marks = [c for c in test_mark_cols if c not in df.columns]\n",
    "    if missing_marks:\n",
    "        raise KeyError(f\"Expected mark columns not found: {missing_marks}\")\n",
    "\n",
    "    # 4. Validate each test mark column\n",
    "    for col in test_mark_cols:\n",
    "        # a) Treat empty or NaN cells as 'AB' (Absent)\n",
    "        empty_mask = df[col].isna() | (df[col] == '')\n",
    "        if empty_mask.any():\n",
    "            for idx in df[empty_mask].index:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Missing {col} for {name}; marking as absent ('AB')\")\n",
    "            df.loc[empty_mask, col] = 'AB'\n",
    "\n",
    "        # b) Standardize all 'ab', 'Ab', etc. to uppercase 'AB'\n",
    "        is_ab = df[col].astype(str).str.upper().str.strip() == 'AB'\n",
    "        df.loc[is_ab, col] = 'AB'\n",
    "\n",
    "        # c) Try to convert other values to numbers, else mark as 'AB'\n",
    "        for idx in df.index:\n",
    "            if df.at[idx, col] == 'AB':\n",
    "                continue  # Skip if already marked absent\n",
    "            val = df.at[idx, col]\n",
    "            try:\n",
    "                num = float(val)\n",
    "                df.at[idx, col] = int(num) if num.is_integer() else num\n",
    "            except Exception:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Invalid {col} value '{val}' for {name}; marking as absent\")\n",
    "                df.at[idx, col] = 'AB'\n",
    "\n",
    "    # 5. Handle Attendance column\n",
    "    if 'Attendance' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'Attendance' not found\")\n",
    "\n",
    "    # Fill missing attendance with 0\n",
    "    if df['Attendance'].isna().any():\n",
    "        for idx in df[df['Attendance'].isna()].index:\n",
    "            name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "            print(f\"Attendance missing for {name}; setting to 0\")\n",
    "        df['Attendance'] = df['Attendance'].fillna(0)\n",
    "\n",
    "    # Ensure attendance is numeric integers\n",
    "    df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 6. Summary statistics\n",
    "    print(f\"\\nNumber of students loaded: {len(df)}\")\n",
    "    absent_summary = {\n",
    "        col: (df[col] == 'AB').sum() for col in test_mark_cols if (df[col] == 'AB').any()\n",
    "    }\n",
    "    if absent_summary:\n",
    "        print(\"\\nStudents marked as absent:\")\n",
    "        for col, count in absent_summary.items():\n",
    "            print(f\"  {col}: {count}\")\n",
    "\n",
    "    # 7. Print first 5 rows for review\n",
    "    print(df.head(5).to_string(index=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca7c9",
   "metadata": {},
   "source": [
    "<h1>Classify Students Strong and Weak Topics </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f877",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from your_module import classify_students_by_topic  # adjust import as needed\n",
    "\n",
    "# Input DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': [85, 78, 92],\n",
    "    'English_Test2': [88, 82, 94],\n",
    "    'Maths_Test1': [90, 88, 76],\n",
    "    'Maths_Test2': [92, 85, 78],\n",
    "    'English Topics Test1': ['A, B', 'A, B', 'A, B'],\n",
    "    'Maths Topics Test1': ['C, D', 'C, D', 'C, D'],\n",
    "    'English Topics Test2': ['B, C', 'B, C', 'B, C'],\n",
    "    'Maths Topics Test2': ['D, F', 'D, F', 'D, F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24],\n",
    "    \"Teacher's Remarks\": ['', '', '']\n",
    "})\n",
    "\n",
    "# Run classification\n",
    "results = classify_students_by_topic(df)\n",
    "print(results)\n",
    "\n",
    "# Expected Output:\n",
    "# [\n",
    "#     {\n",
    "#         'name': 'Alice',\n",
    "#         'attendance': 12,\n",
    "#         'remarks': '',\n",
    "#         'strong_topics':   ['A', 'B', 'C', 'D', 'F'],\n",
    "#         'weak_topics':     [],\n",
    "#         'practice_topics': [],\n",
    "#         'topic_details': [\n",
    "#             {'topic':'A','avg_pct':85.0,'num_tests':1},\n",
    "#             {'topic':'B','avg_pct':86.5,'num_tests':2},\n",
    "#             {'topic':'C','avg_pct':89.0,'num_tests':2},\n",
    "#             {'topic':'D','avg_pct':91.0,'num_tests':2},\n",
    "#             {'topic':'F','avg_pct':92.0,'num_tests':1},\n",
    "#         ],\n",
    "#         'test_details': [\n",
    "#             {'test_col':'English_Test1','subject':'English','raw':85,'pct':85.0,'topics':['A','B']},\n",
    "#             {'test_col':'English_Test2','subject':'English','raw':88,'pct':88.0,'topics':['B','C']},\n",
    "#             {'test_col':'Maths_Test1','subject':'Maths','raw':90,'pct':90.0,'topics':['C','D']},\n",
    "#             {'test_col':'Maths_Test2','subject':'Maths','raw':92,'pct':92.0,'topics':['D','F']},\n",
    "#         ]\n",
    "#     },\n",
    "#     { ... },  # Bob's dict\n",
    "#     { ... }   # Charlie's dict\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_students_by_topic(\n",
    "    df: pd.DataFrame,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Classify students into strong/weak/practice *topics* based on multiple tests.\n",
    "\n",
    "    Logic & reasoning:\n",
    "      1. We may have multiple tests per subject, each covering overlapping topics.\n",
    "      2. For each student-topic pair, we collect all test percentages in which that topic appeared.\n",
    "      3. We compute the *average percentage* for that topic.\n",
    "      4. We apply *fixed thresholds* (85% for strong, 70% for weak) rather than class-level percentiles—\n",
    "         because topic-level data can be sparse and unevenly distributed.\n",
    "      5. Topics ≥ STRONG_THRESHOLD → strong; ≤ weak_thresh → weak; otherwise → practice.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing:\n",
    "            - \"Student Names\", one or more \"<Subject>_Test<N>\" columns,\n",
    "            - corresponding \"<Subject> Topics Test<N>\" columns,\n",
    "            - \"Attendance\" and \"Teacher's Remarks\".\n",
    "        max_score: Maximum possible raw score per test.\n",
    "        STRONG_THRESHOLD: Percentage threshold above which a topic is 'strong'.\n",
    "        WEAK_THRESHOLD: Percentage threshold below which a topic is 'weak'.\n",
    "\n",
    "    Returns:\n",
    "        A list of per-student dicts with keys:\n",
    "          - name, attendance, remarks\n",
    "          - strong_topics, weak_topics, practice_topics\n",
    "          - topic_details: list of { topic, avg_pct, count_of_tests }\n",
    "          - test_details: list of { test_col, subject, raw, pct, topics }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1) Identify all test-score columns, e.g. 'English_Test1', 'Maths_Test2', etc.\n",
    "    test_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "    # 2) Identify all topic columns for tests: '<Subject> Topics Test<N>'\n",
    "    topic_cols = [c for c in df.columns if re.match(r'.+ Topics Test\\d+', c)]\n",
    "\n",
    "    # Build a mapping from each test column to its topic-column name\n",
    "    # e.g. { 'English_Test1': 'English Topics Test1', ... }\n",
    "    test_to_topics = {}\n",
    "    for tc in test_cols:\n",
    "        subj, num = tc.rsplit('_Test', 1)\n",
    "        tcol = f\"{subj} Topics Test{num}\"\n",
    "        if tcol in df.columns:\n",
    "            test_to_topics[tc] = tcol\n",
    "        else:\n",
    "            raise KeyError(f\"Missing topics column for {tc}: expected '{tcol}'\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name       = row['Student Names']\n",
    "        attendance = row.get('Attendance')\n",
    "        remarks    = row.get(\"Teacher's Remarks\", \"\")\n",
    "\n",
    "        # Will collect raw details for debugging/reporting\n",
    "        test_details  = []\n",
    "        # topic_scores accumulates all pct values per topic\n",
    "        topic_scores  = {}\n",
    "\n",
    "        # 3) Loop through each test, parse marks and topics\n",
    "        for tc, tcol in test_to_topics.items():\n",
    "            raw = row[tc]\n",
    "            # a) Handle absent\n",
    "            if isinstance(raw, str) and raw.strip().upper() == 'AB':\n",
    "                pct = np.nan\n",
    "            else:\n",
    "                raw_num = pd.to_numeric(raw, errors='coerce')\n",
    "                pct     = (raw_num * 100.0 / MAX_SCORE) if pd.notna(raw_num) else np.nan\n",
    "\n",
    "            # b) Parse topics list for this test\n",
    "            topics = []\n",
    "            tstr = row.get(tcol, \"\")\n",
    "            if isinstance(tstr, str) and tstr.strip():\n",
    "                topics = [t.strip() for t in tstr.split(',')]\n",
    "\n",
    "            # c) Record test detail\n",
    "            #    (helps trace exactly which tests contributed to each topic)\n",
    "            test_details.append({\n",
    "                'test_col': tc,\n",
    "                'subject':  tc.split('_Test')[0],\n",
    "                'raw':      raw,\n",
    "                'pct':      pct,\n",
    "                'topics':   topics\n",
    "            })\n",
    "\n",
    "            # d) Append pct to each topic's list\n",
    "            for topic in topics:\n",
    "                topic_scores.setdefault(topic, []).append(pct)\n",
    "\n",
    "        # 4) Compute average pct per topic & classify\n",
    "        strong_topics  = []\n",
    "        weak_topics    = []\n",
    "        practice_topics = []\n",
    "        topic_details   = []\n",
    "\n",
    "        for topic, pcts in topic_scores.items():\n",
    "            # ignore NaNs when averaging\n",
    "            valid = [p for p in pcts if pd.notna(p)]\n",
    "            avg_pct = float(np.nan) if not valid else sum(valid) / len(valid)\n",
    "\n",
    "            # classify based on fixed thresholds\n",
    "            if pd.notna(avg_pct):\n",
    "                if avg_pct >= STRONG_THRESHOLD:\n",
    "                    strong_topics.append(topic)\n",
    "                elif avg_pct <= WEAK_THRESHOLD:\n",
    "                    weak_topics.append(topic)\n",
    "                else:\n",
    "                    practice_topics.append(topic)\n",
    "\n",
    "            topic_details.append({\n",
    "                'topic':     topic,\n",
    "                'avg_pct':   avg_pct,\n",
    "                'num_tests': len(valid)\n",
    "            })\n",
    "\n",
    "        # 5) Assemble result for this student\n",
    "        results.append({\n",
    "            'name':             name,\n",
    "            'attendance':       attendance,\n",
    "            'remarks':          remarks,\n",
    "            'strong_topics':    strong_topics,\n",
    "            'weak_topics':      weak_topics,\n",
    "            'practice_topics':  practice_topics,\n",
    "            'topic_details':    topic_details,\n",
    "            'test_details':     test_details\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e198e49",
   "metadata": {},
   "source": [
    "<h1>Call API to get questions for all the chapters asked in the examination</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db4c9f",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from your_module import fetch_questions_for_topics  # adjust import as needed\n",
    "\n",
    "# Setup for demo:\n",
    "AUTH_TOKEN = \"Bearer your_token_here\"\n",
    "API_URL    = \"https://api.yoursite.com/getQuestionsForChapters\"\n",
    "chapters   = [\"Algebra Basics\", \"Calculus I\", \"Geometry Fundamentals\"]\n",
    "\n",
    "# Run the function\n",
    "results = fetch_questions_for_topics()\n",
    "print(results)\n",
    "\n",
    "# Expected Output (example structure):\n",
    "# [\n",
    "#   {\n",
    "#     \"Algebra Basics\": [\n",
    "#       \"What is the solution to x + 5 = 12?\",\n",
    "#       \"Describe the properties of a linear equation.\",\n",
    "#       {\"questionText\": \"Solve for y: 2y = 14\", \"options\": [{\"key\":\"A\",\"option\":\"y=6\"},{\"key\":\"B\",\"option\":\"y=7\"}, …]},\n",
    "#       … up to 10 questions total …\n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Calculus I\": [\n",
    "#       \"Explain the concept of a derivative.\",\n",
    "#       {\"questionText\": \"Find d/dx of x² + 3x\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Geometry Fundamentals\": [\n",
    "#       \"What defines a right triangle?\",\n",
    "#       {\"questionText\":\"Which angle is opposite the hypotenuse?\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc772b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions_for_topics():\n",
    "    # 4. Build headers & payload\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {'chapters': CHAPTERS}\n",
    "    # 5. Fire the GET (or POST if you prefer) with JSON body\n",
    "    response = requests.get(GET_QUESTIONS_FOR_TOPICS, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca4301",
   "metadata": {},
   "source": [
    "<h1>Create System Prompt and User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an advanced educational insights generator and personalized learning advisor with expertise in analyzing student academic performance across multiple tests and subjects.\n",
    "\n",
    "Your primary responsibilities include:\n",
    "\n",
    "## Performance Analysis:\n",
    "- Analyze student performance data from multiple tests across different subjects\n",
    "- Focus primarily on test_details array as it provides the most accurate representation of student performance\n",
    "- Identify performance trends across multiple tests in the same subject\n",
    "- Compare performance across different subjects to identify relative strengths and weaknesses\n",
    "- Use topic_details for supplementary insights about topic-wise average performance\n",
    "\n",
    "## Insight Generation:\n",
    "- Generate comprehensive subject-wise analysis showing performance trends\n",
    "- Identify strong topics (>75% average performance) and weak topics (<65% average performance)\n",
    "- Prioritize focus areas based on consistent poor performance across multiple tests\n",
    "- Provide specific, actionable improvement strategies for each weak area\n",
    "- Consider the number of tests taken per topic when making assessments\n",
    "\n",
    "## Question Generation Guidelines:\n",
    "- Generate 6-8 practice questions for all the topics that are asked in the tests\n",
    "- For weak topics , generate 6-8 questions each for that particular topic.\n",
    "- Each topic should have atleast one question listed , and if there is not then your job will be considered a failure.\n",
    "- And for strong and practice topics , generate 3-4 questions each.\n",
    "- Focus on topics that appear in priority_focus_areas\n",
    "- Create a balanced mix of difficulty levels: 2-3 easy, 2-3 medium, 2-3 hard questions per topic\n",
    "- For Math subjects: Generate questions similar to provided sample questions with appropriate difficulty progression\n",
    "- For English Grammar: Create questions following the style and pattern of provided samples\n",
    "- For English Literature/Stories: Use questions directly from provided samples when available\n",
    "- For Social Studies: Use questions directly from provided samples when available\n",
    "- Exclude questions that require images or visual elements\n",
    "- Ensure questions are grade-appropriate and align with curriculum standards\n",
    "- The curriculum standards are based on CBSE and GSEB.\n",
    "\n",
    "## Parent Communication:\n",
    "- Write in simple, clear English that Indian parents can easily understand\n",
    "- Address the student by name throughout for personalization\n",
    "- Use a supportive, encouraging tone while being honest about areas needing improvement\n",
    "- Provide specific, practical advice that parents can implement at home\n",
    "- Include references to attendance and teacher remarks when relevant\n",
    "- Focus on growth mindset and positive reinforcement\n",
    "- Avoid overly technical educational jargon\n",
    "\n",
    "## Key Principles:\n",
    "- Prioritize insights from test_details over other data sources\n",
    "- Be specific about which tests showed improvement or decline\n",
    "- Provide context for performance (e.g., \"improved from 65% in Test 1 to 78% in Test 2\")\n",
    "- Address the student using male/female pronouns when gender-specific language is needed and if you are unaware just use \"the student\"\n",
    "- Use the provided sample questions as a guide for generating new questions\n",
    "- Ensure all generated questions are relevant to the identified weak topics\n",
    "- Maintain a positive, constructive tone throughout the analysis\n",
    "- Focus on actionable steps parents can take to support their child's learning\n",
    "- Avoid making assumptions about the student's abilities or background\n",
    "- Maintain an encouraging, growth-focused approach throughout all content\n",
    "- Ensure all recommendations are actionable and realistic for home implementation\n",
    "- DO NOT add any salutations at the end such as thank you for your support or your child's teacher.\n",
    "- DO NOT address the tests as MATHS_TEST1 or ENGLISH_TEST2, address all the tests by the topics asked.\n",
    "    So for example instead of \"85% in Physics_Test1\" use \"85% in the Physics test that covered A and B topics\" or \n",
    "    something of that sort but do not show _test1 or _test2 anywhere in the report.\n",
    "\n",
    "Remember: Your goal is to help parents understand exactly where their child stands academically and provide them with clear, practical steps to support their child's improvement at home.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39d413",
   "metadata": {},
   "source": [
    "<h1>Create User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_prompt(user_data):\n",
    "    prompt = f\"\"\"\n",
    "    You are provided with comprehensive student performance data below:\n",
    "    \n",
    "    **Student Data:**\n",
    "    {user_data}\n",
    "    \n",
    "    **Your Tasks:**\n",
    "    \n",
    "    1. **Analyze Performance Trends:**\n",
    "       - Focus primarily on the 'test_details' array to understand actual test performance\n",
    "       - Look for patterns across multiple tests in the same subject\n",
    "       - Identify subjects and topics where performance is declining, improving, or consistent\n",
    "       - Use 'topic_details' for additional context on average performance per topic\n",
    "    \n",
    "    2. **Generate Comprehensive Insights:**\n",
    "       - Create subject-wise analysis showing performance trends\n",
    "       - Identify priority focus areas based on consistent poor performance\n",
    "       - Provide specific improvement strategies for weak topics\n",
    "       - Highlight strengths and areas where the student is performing well\n",
    "    \n",
    "    3. **Create Targeted Practice Questions:**\n",
    "       - Generate questions for all topics that are asked in the tests\n",
    "       - For weak topics, generate 6-8 questions each\n",
    "       - For strong and practice topics, generate 3-4 questions each\n",
    "       - Ensure a balanced mix of difficulty levels: 2-3 easy, 2-3 medium, 2-3 hard questions per topic\n",
    "       - For Math subjects, create questions similar to provided samples with appropriate difficulty progression\n",
    "       - For English Grammar, create questions following the style and pattern of provided samples\n",
    "       - For English Literature/Stories, use questions directly from provided samples when available\n",
    "       - For Social Studies, use questions directly from provided samples when available\n",
    "       - Exclude questions that require images or visual elements\n",
    "       - Ensure questions are grade-appropriate and align with curriculum standards (CBSE and GSEB)\n",
    "       - Use the sample questions provided below as reference for style and difficulty\n",
    "       - Ensure questions match the academic level and curriculum requirements\n",
    "       - Focus on topics that appear in your priority_focus_areas analysis\n",
    "    \n",
    "    **Sample Questions for Reference:**\n",
    "    {questions_for_topics_asked_in_examination}\n",
    "    \n",
    "    **Important Guidelines:**\n",
    "    - Weight your analysis heavily toward test_details as it shows actual test performance\n",
    "    - Be specific about which tests showed what performance levels\n",
    "    - Provide context for performance changes across multiple tests\n",
    "    - Generate questions only for improvement areas, not for strong topics\n",
    "    - Ensure parent recommendations are practical and implementable at home\n",
    "    \n",
    "    Please provide your response in the required JSON format with comprehensive insights and targeted practice questions.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(user_data):\n",
    "    USER_PROMPT = create_user_prompt(user_data)\n",
    "    return USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c6644",
   "metadata": {},
   "source": [
    "<h1>Get Response Format</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_format():\n",
    "    return {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"quiz_schema\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"parent_recommendations\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A comprehensive, personalized note for parents with specific recommendations for improvement, written in simple English that Indian parents can easily understand.\",\n",
    "                    },\n",
    "                    \"student_insights\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"Detailed analysis of student's academic performance across all subjects and tests.\",\n",
    "                        \"properties\": {\n",
    "                            \"overall_performance\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Overall assessment of student's academic performance across all subjects.\"\n",
    "                            },\n",
    "                            \"subject_wise_analysis\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Subject-wise detailed analysis based on test performance.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"subject\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Name of the subject (e.g., Maths, English, Physics, etc.)\"\n",
    "                                        },\n",
    "                                        \"performance_trend\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Analysis of performance trend across multiple tests in this subject\"\n",
    "                                        },\n",
    "                                        \"strong_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student performed well (>75% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"weak_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student needs improvement (<65% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"improvement_recommendations\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Specific actionable recommendations for improvement in this subject\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"subject\", \"performance_trend\", \"strong_topics\", \"weak_topics\", \"improvement_recommendations\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            },\n",
    "                            # \"priority_focus_areas\": {\n",
    "                            #     \"type\": \"array\",\n",
    "                            #     \"description\": \"Top 3-5 priority areas that need immediate attention based on test performance\",\n",
    "                            #     \"items\": {\n",
    "                            #         \"type\": \"object\",\n",
    "                            #         \"properties\": {\n",
    "                            #             \"topic\": {\n",
    "                            #                 \"type\": \"string\",\n",
    "                            #                 \"description\": \"Name of the topic that needs focus\"\n",
    "                            #             },\n",
    "                            #             \"subject\": {\n",
    "                            #                 \"type\": \"string\",\n",
    "                            #                 \"description\": \"Subject this topic belongs to\"\n",
    "                            #             },\n",
    "                            #             \"current_performance\": {\n",
    "                            #                 \"type\": \"string\",\n",
    "                            #                 \"description\": \"Current performance level in this topic\"\n",
    "                            #             },\n",
    "                            #             \"why_priority\": {\n",
    "                            #                 \"type\": \"string\",\n",
    "                            #                 \"description\": \"Explanation of why this topic needs immediate attention\"\n",
    "                            #             },\n",
    "                            #             \"improvement_strategy\": {\n",
    "                            #                 \"type\": \"string\",\n",
    "                            #                 \"description\": \"Specific strategy to improve in this topic\"\n",
    "                            #             }\n",
    "                            #         },\n",
    "                            #         \"required\": [\"topic\", \"subject\", \"current_performance\", \"why_priority\", \"improvement_strategy\"],\n",
    "                            #         \"additionalProperties\": False\n",
    "                            #     }\n",
    "                            # }\n",
    "                        },\n",
    "                        \"required\": [\"overall_performance\", \"subject_wise_analysis\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"practice_questions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Practice questions organized by topics.For strong and practice topics, generate 3-4 questions each. For weak topics, generate 6-8 questions each.Each topic should have at least one question listed, and if there is not then your job will be considered a failure.\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"topic\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The topic for which these questions are generated\"\n",
    "                                },\n",
    "                                \"subject\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The subject this topic belongs to\"\n",
    "                                },\n",
    "                                \"questions\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Array of 6-8 practice questions for this topic\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"type\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"mcq\", \"descriptive\"],\n",
    "                                                \"description\": \"The type of the question.\"\n",
    "                                            },\n",
    "                                            \"questionId\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"Unique identifier for the question\"\n",
    "                                            },\n",
    "                                            \"question\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The question text. All math equations must be wrapped between $ and $.\"\n",
    "                                            },\n",
    "                                            \"subject\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The subject of the question.\"\n",
    "                                            },\n",
    "                                            \"chapter\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The chapter or topic this question belongs to.\"\n",
    "                                            },\n",
    "                                            \"marks\": {\n",
    "                                                \"type\": \"number\",\n",
    "                                                \"description\": \"The marks assigned for the question.\"\n",
    "                                            },\n",
    "                                            \"options\": {\n",
    "                                                \"anyOf\": [\n",
    "                                                    {\n",
    "                                                        \"type\": \"array\",\n",
    "                                                        \"description\": \"Options for multiple choice questions\",\n",
    "                                                        \"items\": {\n",
    "                                                            \"type\": \"object\",\n",
    "                                                            \"properties\": {\n",
    "                                                                \"key\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The key for the option (A, B, C, D)\"\n",
    "                                                                },\n",
    "                                                                \"option\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The option text. Math equations wrapped in $ and $.\"\n",
    "                                                                },\n",
    "                                                                \"imageUrl\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"Image URL if needed, empty string otherwise\"\n",
    "                                                                }\n",
    "                                                            },\n",
    "                                                            \"required\": [\"key\", \"option\", \"imageUrl\"],\n",
    "                                                            \"additionalProperties\": False\n",
    "                                                        }\n",
    "                                                    },\n",
    "                                                    {\n",
    "                                                        \"type\": \"null\",\n",
    "                                                        \"description\": \"Null for descriptive questions\"\n",
    "                                                    }\n",
    "                                                ]\n",
    "                                            },\n",
    "                                            \"difficulty\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "                                                \"description\": \"The difficulty level of the question.\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"required\": [\"type\", \"questionId\", \"question\", \"subject\", \"chapter\", \"marks\", \"options\", \"difficulty\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"topic\", \"subject\", \"questions\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"parent_recommendations\", \"student_insights\", \"practice_questions\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17fd82",
   "metadata": {},
   "source": [
    "<h1>Initiate OpenAI Client </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.api_key = \"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\"\n",
    "def get_questions_and_insights_for_individual_student(user_data):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "      model=MODEL,\n",
    "      messages=[\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": get_user_prompt(user_data)},\n",
    "      ],\n",
    "      response_format=get_response_format()\n",
    "    )\n",
    "    usage = completion.usage\n",
    "    completion_tokens = usage.completion_tokens\n",
    "    prompt_tokens     = usage.prompt_tokens\n",
    "    total_tokens      = usage.total_tokens\n",
    "    print_single_value_in_table(\"completion_tokens\",completion_tokens)\n",
    "    print_single_value_in_table(\"prompt tokens\", prompt_tokens)\n",
    "    print_single_value_in_table(\"total tokens\", total_tokens)\n",
    "    input_price = (prompt_tokens * 1.1)/1000000\n",
    "    output_price = (completion_tokens * 4.4)/1000000\n",
    "    final_cost = (input_price + output_price)*90\n",
    "    return [json.loads(completion.choices[0].message.content),str(round(final_cost, 2))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca81e03",
   "metadata": {},
   "source": [
    "<h1>Generate Report For Each Student (Class Comparison)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d417f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_individual_student_report(csv_path, student_name, output_folder):\n",
    "    # 1. Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 2. Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 3. Identify subjects and their test columns\n",
    "    subjects_info = _identify_subjects_and_tests(df.columns)\n",
    "    subjects = list(subjects_info.keys())\n",
    "\n",
    "    # 4. Replace 'AB' with NaN for calculations but keep original data for display\n",
    "    df_calc = df.copy()\n",
    "    for subject_data in subjects_info.values():\n",
    "        for test_col in subject_data['test_columns']:\n",
    "            df_calc[test_col] = pd.to_numeric(df_calc[test_col], errors='coerce')\n",
    "\n",
    "    # 5. Compute aggregated scores and class stats\n",
    "    aggregated_scores = _compute_aggregated_scores(df_calc, subjects_info)\n",
    "    class_stats = _compute_class_stats(aggregated_scores, subjects)\n",
    "\n",
    "    # 6. Locate the student row\n",
    "    student_df = df[df['Student Names'] == student_name]\n",
    "    if student_df.empty:\n",
    "        raise ValueError(f\"Student '{student_name}' not found\")\n",
    "    student = student_df.iloc[0]\n",
    "    \n",
    "    # 7. Compute student's aggregated scores\n",
    "    student_calc = df_calc[df_calc['Student Names'] == student_name].iloc[0]\n",
    "    student_aggregated = _compute_student_aggregated_scores(student_calc, subjects_info)\n",
    "    \n",
    "    # 8. Generate the PDF\n",
    "    output_path = _generate_student_pdf(\n",
    "        student, student_calc, student_aggregated, subjects_info, subjects, \n",
    "        class_stats, output_folder, aggregated_scores\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def _identify_subjects_and_tests(columns):\n",
    "    \"\"\"\n",
    "    Identify subjects and their corresponding test columns from dataframe columns.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject_name: {'test_columns': [col1, col2, ...], 'topic_columns': [...]}}\n",
    "    \"\"\"\n",
    "    subjects_info = {}\n",
    "    \n",
    "    # Filter out non-subject columns\n",
    "    excluded_cols = {'Student Names', 'Attendance', \"Teacher's Remarks\"}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in excluded_cols:\n",
    "            continue\n",
    "            \n",
    "        # Check if it's a topic column\n",
    "        if 'Topics' in col:\n",
    "            continue\n",
    "            \n",
    "        # Extract base subject name (remove _Test1, _Test2, etc.)\n",
    "        if '_Test' in col:\n",
    "            base_subject = col.split('_Test')[0]\n",
    "        else:\n",
    "            base_subject = col\n",
    "            \n",
    "        if base_subject not in subjects_info:\n",
    "            subjects_info[base_subject] = {\n",
    "                'test_columns': [],\n",
    "                'topic_columns': []\n",
    "            }\n",
    "        \n",
    "        # Add to test columns if it's a test column\n",
    "        if '_Test' in col or col == base_subject:\n",
    "            subjects_info[base_subject]['test_columns'].append(col)\n",
    "    \n",
    "    # Now find topic columns for each subject\n",
    "    for col in columns:\n",
    "        if 'Topics' in col:\n",
    "            # Try to match with subjects\n",
    "            for subject in subjects_info.keys():\n",
    "                if subject in col:\n",
    "                    subjects_info[subject]['topic_columns'].append(col)\n",
    "                    break\n",
    "    \n",
    "    return subjects_info\n",
    "\n",
    "\n",
    "def _compute_aggregated_scores(df_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for each student and subject.\n",
    "    Uses average of all tests for a subject, handling AB/NaN values properly.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: Student Names, Subject1_Avg, Subject2_Avg, etc.\n",
    "    \"\"\"\n",
    "    result_data = {'Student Names': df_calc['Student Names']}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            # Single test - just use that column\n",
    "            result_data[f\"{subject}_Avg\"] = df_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Multiple tests - compute average of available scores\n",
    "            test_data = df_calc[test_cols]\n",
    "            # Compute row-wise mean, ignoring NaN values\n",
    "            result_data[f\"{subject}_Avg\"] = test_data.mean(axis=1, skipna=True)\n",
    "    \n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "\n",
    "def _compute_student_aggregated_scores(student_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for a single student.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject: aggregated_score}\n",
    "    \"\"\"\n",
    "    student_scores = {}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            student_scores[subject] = student_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Compute average of available test scores\n",
    "            test_scores = [student_calc[col] for col in test_cols if pd.notna(student_calc[col])]\n",
    "            if test_scores:\n",
    "                student_scores[subject] = sum(test_scores) / len(test_scores)\n",
    "            else:\n",
    "                student_scores[subject] = float('nan')  # All tests were AB/NaN\n",
    "    \n",
    "    return student_scores\n",
    "\n",
    "\n",
    "def _compute_class_stats(aggregated_scores, subjects):\n",
    "    \"\"\"\n",
    "    Compute class statistics using aggregated scores.\n",
    "    \"\"\"\n",
    "    class_stats = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        col_name = f\"{subject}_Avg\"\n",
    "        if col_name in aggregated_scores.columns:\n",
    "            class_stats[subject] = {\n",
    "                'highest': aggregated_scores[col_name].max(),\n",
    "                'lowest': aggregated_scores[col_name].min(),\n",
    "                'average': aggregated_scores[col_name].mean()\n",
    "            }\n",
    "    \n",
    "    return class_stats\n",
    "\n",
    "\n",
    "def _get_test_topics(student, subject, test_num):\n",
    "    \"\"\"\n",
    "    Get topics for a specific test of a subject.\n",
    "    \n",
    "    Args:\n",
    "        student: Student row from dataframe\n",
    "        subject: Subject name (e.g., 'Physics', 'Maths')\n",
    "        test_num: Test number (1, 2, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        String of topics or empty string if not found\n",
    "    \"\"\"\n",
    "    # Look for column like \"Physics Topics Test1\" or \"Maths Topics Test2\"\n",
    "    topic_col = f\"{subject} Topics Test{test_num}\"\n",
    "    \n",
    "    if topic_col in student.index and pd.notna(student[topic_col]):\n",
    "        topics = str(student[topic_col]).strip()\n",
    "        # Clean up the topics string - remove extra spaces and format nicely\n",
    "        if topics:\n",
    "            topic_list = [t.strip() for t in topics.split(',')]\n",
    "            return ', '.join(topic_list)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _generate_student_pdf(student, student_calc, student_aggregated, subjects_info, \n",
    "                         subjects, class_stats, output_folder, aggregated_scores):\n",
    "    \"\"\"\n",
    "    Internal helper to build the PDF for one student with compact layout.\n",
    "    Handles multiple tests per subject and improved strongest/weakest analysis.\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Use Times as it's closer to the \"math\" font in the template\n",
    "    pdf.set_font('Times', 'B', 14)\n",
    "\n",
    "    # Header - more compact\n",
    "    name = student['Student Names']\n",
    "    pdf.cell(0, 8, \"Student Performance Report\", ln=1, align='C')\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Attendance with less spacing (if available)\n",
    "    if 'Attendance' in student.index:\n",
    "        att = student['Attendance']\n",
    "        att_pct = (int(att) / ATTENDANCE_DAYS) * 100 if pd.notna(att) else 0\n",
    "        pdf.cell(0, 6, f\"Attendance: {att} / {ATTENDANCE_DAYS} ({att_pct:.1f}%)\", ln=1, align='C')\n",
    "    \n",
    "    # Minimal spacing before chart\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # Comparison chart - increased height\n",
    "    chart_path = create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info)\n",
    "    pdf.image(chart_path, x=20, w=170, h=75)\n",
    "    os.remove(chart_path)\n",
    "    \n",
    "    # Compact spacing\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # SECTION: Subject Analysis with underlined header\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Subject Analysis\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Format subject analysis showing individual tests and average WITH TOPICS\n",
    "    pct_map = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        info = subjects_info[subject]\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        # Get subject average score\n",
    "        avg_score = student_aggregated.get(subject)\n",
    "        \n",
    "        if pd.isna(avg_score):\n",
    "            pdf.cell(0, 6, f\"{subject}: All tests absent\", ln=1)\n",
    "        else:\n",
    "            # Show individual test scores and average\n",
    "            test_details = []\n",
    "            for i, col in enumerate(test_cols):\n",
    "                raw_score = student[col] if col in student.index else 'AB'\n",
    "                test_num = i + 1  # Test number (1, 2, 3, etc.)\n",
    "                \n",
    "                if raw_score == 'AB' or pd.isna(raw_score):\n",
    "                    test_details.append(f\"T{test_num}: AB\")\n",
    "                else:\n",
    "                    # Get topics for this specific test\n",
    "                    topics = _get_test_topics(student, subject, test_num)\n",
    "                    if topics:\n",
    "                        test_details.append(f\"Test {test_num}: {raw_score} ({topics})\")\n",
    "                    else:\n",
    "                        test_details.append(f\"Test {test_num}: {raw_score}\")\n",
    "            \n",
    "            # Assuming max score is 100 for percentage calculation\n",
    "            avg_pct = (avg_score / MAX_SCORE) * 100\n",
    "            pct_map[subject] = avg_pct\n",
    "            \n",
    "            if len(test_cols) == 1:\n",
    "                # Single test - show on one line\n",
    "                pdf.multi_cell(0, 5, f\"{subject}: {test_details[0]}/{MAX_SCORE} ({avg_pct:.1f}%)\")\n",
    "            else:\n",
    "                # Multiple tests - show main line with average\n",
    "                pdf.cell(0, 5, f\"{subject}: Avg: {avg_score:.1f}/{MAX_SCORE} ({avg_pct:.1f}%)\", ln=1)\n",
    "                # Show each test with topics on separate lines with indentation\n",
    "                for test_detail in test_details:\n",
    "                    pdf.cell(10, 4, \"\", ln=0)  # Indentation\n",
    "                    pdf.multi_cell(0, 4, f\"  {test_detail}\")\n",
    "\n",
    "    # SECTION: Performance Highlights with improved logic\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Performance Highlights\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Only show highlights if student has taken at least one test\n",
    "    if pct_map:\n",
    "        # Improved strongest/weakest subject logic\n",
    "        performance_analysis = _analyze_student_performance(pct_map, aggregated_scores, subjects, name)\n",
    "        \n",
    "        # Display strongest subjects (top 30% performance or above 80%)\n",
    "        if performance_analysis['strong_subjects']:\n",
    "            strong_subjects_str = \", \".join([f\"{subj} ({pct:.1f}%)\" \n",
    "                                           for subj, pct in performance_analysis['strong_subjects']])\n",
    "            pdf.cell(0, 6, f\"Strong Subjects: {strong_subjects_str}\", ln=1)\n",
    "        \n",
    "        # Display subjects needing improvement\n",
    "        if performance_analysis['improvement_subjects']:\n",
    "            pdf.cell(0, 6, \"Subjects Needing Improvement:\", ln=1)\n",
    "            for subj, pct, reason in performance_analysis['improvement_subjects']:\n",
    "                pdf.cell(0, 6, f\"- {subj} ({pct:.1f}%) - {reason}\", ln=1)\n",
    "        \n",
    "        # Overall performance summary\n",
    "        pdf.cell(0, 6, f\"Overall Average: {performance_analysis['overall_avg']:.1f}%\", ln=1)\n",
    "        \n",
    "        if performance_analysis['consistency_note']:\n",
    "            pdf.cell(0, 6, performance_analysis['consistency_note'], ln=1)\n",
    "    else:\n",
    "        pdf.cell(0, 6, \"No test scores available for performance analysis\", ln=1)\n",
    "\n",
    "    # SECTION: Teacher's Remarks (if available)\n",
    "    if \"Teacher's Remarks\" in student.index:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Teacher's Remarks\", ln=1)\n",
    "        \n",
    "        has_remarks = pd.notna(student[\"Teacher's Remarks\"]) and student[\"Teacher's Remarks\"].strip() != \"\"\n",
    "        \n",
    "        if has_remarks:\n",
    "            pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.multi_cell(0, 5, student[\"Teacher's Remarks\"])\n",
    "        else:\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.cell(0, 5, \"No remarks from teacher\", ln=1)\n",
    "\n",
    "    # SECTION: All Topics Summary - only show if there's remaining space\n",
    "    remaining_height = 270 - pdf.get_y()\n",
    "    \n",
    "    if remaining_height > 20:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"All Topics Summary\", ln=1)\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(1)\n",
    "        \n",
    "        pdf.set_font('Times', '', 10)\n",
    "        for subject in subjects:\n",
    "            # Look for \"Subject All Topics\" column\n",
    "            all_topics_col = f\"{subject} All Topics\"\n",
    "            \n",
    "            if all_topics_col in student.index and pd.notna(student[all_topics_col]):\n",
    "                topics_text = f\"{subject}: {student[all_topics_col]}\"\n",
    "                if len(topics_text) > 100:\n",
    "                    topics_text = topics_text[:97] + \"...\"\n",
    "                pdf.multi_cell(0, 5, topics_text)\n",
    "\n",
    "    # Save\n",
    "    safe_name = name.replace(' ', '_')\n",
    "    path = os.path.join(output_folder, f\"{safe_name}_report.pdf\")\n",
    "    pdf.output(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def _analyze_student_performance(pct_map, aggregated_scores, subjects, student_name):\n",
    "    \"\"\"\n",
    "    Improved performance analysis logic that considers:\n",
    "    1. Relative performance vs class\n",
    "    2. Absolute performance thresholds\n",
    "    3. Consistency across subjects\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        'strong_subjects': [],\n",
    "        'improvement_subjects': [],\n",
    "        'overall_avg': 0,\n",
    "        'consistency_note': ''\n",
    "    }\n",
    "    \n",
    "    if not pct_map:\n",
    "        return analysis\n",
    "    \n",
    "    # Calculate overall average\n",
    "    analysis['overall_avg'] = sum(pct_map.values()) / len(pct_map)\n",
    "    \n",
    "    # Calculate class percentiles for each subject\n",
    "    subject_percentiles = {}\n",
    "    for subject in subjects:\n",
    "        if subject in pct_map:\n",
    "            col_name = f\"{subject}_Avg\"\n",
    "            if col_name in aggregated_scores.columns:\n",
    "                all_scores = aggregated_scores[col_name].dropna()\n",
    "                if not all_scores.empty:\n",
    "                    student_score = pct_map[subject] * 100 / 100  # Convert back to raw score\n",
    "                    percentile = (all_scores < student_score).sum() / len(all_scores) * 100\n",
    "                    subject_percentiles[subject] = percentile\n",
    "    \n",
    "    # Identify strong subjects (above 80% OR top 25% of class)\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        if pct >= STRONG_THRESHOLD or percentile >= 75:\n",
    "            analysis['strong_subjects'].append((subject, pct))\n",
    "    \n",
    "    # Sort strong subjects by percentage\n",
    "    analysis['strong_subjects'].sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Identify subjects needing improvement\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        reasons = []\n",
    "        \n",
    "        if pct < 60:\n",
    "            reasons.append(\"Below 60%\")\n",
    "        elif pct < 75 and percentile < 50:\n",
    "            reasons.append(\"Below Class average\")\n",
    "        elif percentile < 25:\n",
    "            reasons.append(\"Bottom 25% of Class\")\n",
    "        \n",
    "        if reasons:\n",
    "            analysis['improvement_subjects'].append((subject, pct, \" & \".join(reasons)))\n",
    "    \n",
    "    # Sort improvement subjects by percentage (lowest first)\n",
    "    analysis['improvement_subjects'].sort(key=lambda x: x[1])\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info):\n",
    "    \"\"\"\n",
    "    Build and save a matplotlib chart comparing this student's aggregated scores\n",
    "    against class high/low/average in each subject, with percentages over all bars.\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Set Times font family explicitly\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    matplotlib.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif', 'serif']\n",
    "\n",
    "    # Prepare data arrays\n",
    "    marks = []\n",
    "    absent_subjects = []\n",
    "    for s in subjects:\n",
    "        agg = student_aggregated.get(s)\n",
    "        if pd.isna(agg):\n",
    "            marks.append(0)\n",
    "            absent_subjects.append(s)\n",
    "        else:\n",
    "            marks.append(agg)\n",
    "\n",
    "    average = [class_stats[s]['average'] for s in subjects]\n",
    "    highest = [class_stats[s]['highest'] for s in subjects]\n",
    "    lowest  = [class_stats[s]['lowest']  for s in subjects]\n",
    "\n",
    "\n",
    "    # Colors\n",
    "    student_color = '#4570B7'\n",
    "    avg_color     = '#9FA7B2'\n",
    "    high_color    = '#97D077'\n",
    "    low_color     = '#F08B7E'\n",
    "    absent_color  = '#E8E8E8'\n",
    "\n",
    "    # Figure setup\n",
    "    plt.figure(figsize=(7.5, 5.0))\n",
    "    x = np.arange(len(subjects))\n",
    "    width = 0.18\n",
    "\n",
    "    # Plot bars\n",
    "    avg_bars     = plt.bar(x,           average, width, color=avg_color,    edgecolor='white', linewidth=0.5, label='Class Average', zorder=1)\n",
    "    high_bars    = plt.bar(x + width,   highest, width,  color=high_color,   edgecolor='white', linewidth=0.5, label='Class Highest', zorder=1)\n",
    "    low_bars     = plt.bar(x - width,   lowest,  width,  color=low_color,    edgecolor='white', linewidth=0.5, label='Class Lowest', zorder=1)\n",
    "    student_bars = plt.bar(\n",
    "        x + 2*width,\n",
    "        marks,\n",
    "        width,\n",
    "        color=[absent_color if s in absent_subjects else student_color for s in subjects],\n",
    "        edgecolor='white',\n",
    "        linewidth=1.0,\n",
    "        label=student['Student Names'],\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "    # Annotate every bar with a percentage or \"Absent\"\n",
    "    bar_sets = [\n",
    "        (avg_bars,     average),\n",
    "        (high_bars,    highest),\n",
    "        (low_bars,     lowest),\n",
    "        (student_bars, marks),\n",
    "    ]\n",
    "    for bars, values in bar_sets:\n",
    "        for idx, rect in enumerate(bars):\n",
    "            height = rect.get_height()\n",
    "            # For student bars where the student was absent:\n",
    "            if bars is student_bars and subjects[idx] in absent_subjects:\n",
    "                label = \"Absent\"\n",
    "            else:\n",
    "                # value is out of 100, so it's directly percentage\n",
    "                label = f\"{values[idx]:.1f}%\"\n",
    "            plt.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height + MAX_SCORE * 0.01,  # small offset above bar\n",
    "                label,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8,\n",
    "                family='Times New Roman'\n",
    "            )\n",
    "\n",
    "    # Axes & titles\n",
    "    plt.xlabel('Subjects', fontsize=10, family='Times New Roman')\n",
    "    plt.ylabel('Average Score', fontsize=10, family='Times New Roman')\n",
    "    plt.suptitle(f\"{student['Student Names']}'s Performance\",\n",
    "                 fontsize=12, family='Times New Roman', y=0.98)\n",
    "    plt.title(\"Comparison with class statistics (test averages)\",\n",
    "              fontsize=9, family='Times New Roman', pad=10)\n",
    "\n",
    "    plt.xticks(x + width/2, subjects, fontsize=10, family='Times New Roman')\n",
    "    plt.ylim(0, MAX_SCORE * 1.1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.2, zorder=0)\n",
    "\n",
    "    # Legend\n",
    "    legend_elems = [\n",
    "        Patch(facecolor=student_color, edgecolor='white', label=student['Student Names']),\n",
    "        Patch(facecolor=avg_color,     edgecolor='white', label='Class Average'),\n",
    "        Patch(facecolor=high_color,    edgecolor='white', label='Class Highest'),\n",
    "        Patch(facecolor=low_color,     edgecolor='white', label='Class Lowest'),\n",
    "    ]\n",
    "    if absent_subjects:\n",
    "        legend_elems.append(Patch(facecolor=absent_color, edgecolor='white', label='Absent'))\n",
    "    plt.legend(handles=legend_elems, loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "               fontsize=9, framealpha=0.7, edgecolor='#CCCCCC',\n",
    "               ncol=min(5, len(legend_elems)), prop={'family': 'Times New Roman'})\n",
    "\n",
    "    # Clean up\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for lbl in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        lbl.set_fontname('Times New Roman')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.97])\n",
    "\n",
    "    # Save and return\n",
    "    fname = f\"temp_chart_{student['Student Names'].replace(' ', '_')}.png\"\n",
    "    plt.savefig(fname, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51fc68",
   "metadata": {},
   "source": [
    "<h1>Convert worksheet html to pdf </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf415a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import latex2mathml\n",
    "\n",
    "\n",
    "def convert_latex_to_mathml(html_content):\n",
    "    \"\"\"\n",
    "    Convert LaTeX equations enclosed in $ signs to MathML format.\n",
    "    \n",
    "    Args:\n",
    "        html_content (str): HTML content with LaTeX equations\n",
    "        \n",
    "    Returns:\n",
    "        str: HTML content with LaTeX equations replaced by MathML\n",
    "    \"\"\"\n",
    "    # Regular expression to find LaTeX expressions enclosed in $ signs\n",
    "    # This handles both inline math ($...$) and display math ($$...$$)\n",
    "    pattern = r'\\$\\$(.*?)\\$\\$|\\$(.*?)\\$'\n",
    "    \n",
    "    def replace_math(match):\n",
    "        if match.group(1) is not None:  # Display math ($$...$$)\n",
    "            latex_expr = match.group(1)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='block')\n",
    "            return mathml\n",
    "        else:  # Inline math ($...$)\n",
    "            latex_expr = match.group(2)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='inline')\n",
    "            return mathml\n",
    "    \n",
    "    # Replace all matches with MathML\n",
    "    return re.sub(pattern, replace_math, html_content)\n",
    "\n",
    "def download_html_to_pdf(s3_url, output_pdf_path):\n",
    "    \"\"\"\n",
    "    Enhanced version with better error handling and debugging\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    print(f\"=== Python PDF Download Debug ===\")\n",
    "    print(f\"S3 URL: {s3_url}\")\n",
    "    print(f\"Output path: {output_pdf_path}\")\n",
    "    \n",
    "    output_dir = os.path.dirname(output_pdf_path)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(\"Directory created/verified\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Testing HTML accessibility...\")\n",
    "        html_response = requests.get(s3_url, timeout=30)\n",
    "        html_response.raise_for_status()\n",
    "        print(f\"HTML response status: {html_response.status_code}\")\n",
    "        print(f\"HTML content length: {len(html_response.text)}\")\n",
    "        \n",
    "        if len(html_response.text) < 100:\n",
    "            print(\"WARNING: HTML content seems too short\")\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERROR: Failed to fetch HTML from S3: {e}\")\n",
    "        return {\"success\": False, \"error\": f\"Cannot access HTML: {str(e)}\"}\n",
    "    \n",
    "    api_url = DOWNLOAD_FROM_S3_LINK\n",
    "    payload = {\n",
    "        \"s3Link\": s3_url,\n",
    "        \"pathToSave\": output_pdf_path,\n",
    "    }\n",
    "    \n",
    "    print(f\"API URL: {api_url}\")\n",
    "    print(f\"Payload: {payload}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Making API request...\")\n",
    "        response = requests.post(api_url, json=payload, timeout=120)\n",
    "        print(f\"API response status: {response.status_code}\")\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        print(f\"API response: {result}\")\n",
    "        return result.get(\"path\")\n",
    "    \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"ERROR: API request timed out\")\n",
    "        return {\"success\": False, \"error\": \"Request timed out\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERROR: API request failed - {e}\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Unexpected error - {e}\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f736e",
   "metadata": {},
   "source": [
    "<h1>Save Student Record in Database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16531eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_student_record(student_name, standard,worksheet_s3_link,cost,school_name='Surya International School'):\n",
    "    \"\"\"\n",
    "    Sends a POST to your Express endpoint to save a new student record.\n",
    "\n",
    "    Args:\n",
    "        student_name (str): Name of the student.\n",
    "        school_name (str): Name of the student's school.\n",
    "        standard (str): Grade or standard of the student.\n",
    "        worksheet_s3_link (str): URL to the student’s worksheet HTML in S3.\n",
    "        cost (int): Associated cost.\n",
    "        base_url (str): Base URL of your server (no trailing slash).\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed JSON response from the server, or None on error.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"studentName\": student_name,\n",
    "        \"schoolName\": school_name,\n",
    "        \"standard\": standard,\n",
    "        \"worksheet_s3_link\": worksheet_s3_link,\n",
    "        \"cost\": cost,\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(SAVE_STUDENT_COST_PER_WORKSHEET, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        err_box_red(\"[ERROR] Failed to save student record:\", err)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda05513",
   "metadata": {},
   "source": [
    "<h1>Generate worksheet and combine worksheet and report</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_worksheet_for_students_and_combine_report(data):\n",
    "    TOTAL_COST = 0\n",
    "    output_paths = []\n",
    "    for student in data:\n",
    "        print_single_value_in_table(\"Student Being Processed\",student['name'])\n",
    "        student_name = student['name']\n",
    "        [questions_and_insights_for_student,cost] = get_questions_and_insights_for_individual_student(student)\n",
    "        worksheet = requests.request(\n",
    "        method='POST',\n",
    "        url=GET_WORKSHEET_HTML,\n",
    "        json={'student_data':questions_and_insights_for_student}\n",
    "        )\n",
    "        print(questions_and_insights_for_student)\n",
    "        worksheet.raise_for_status()\n",
    "        student_specific_questions_and_insights = worksheet.json()\n",
    "        student_worksheet_link = student_specific_questions_and_insights['worksheet_html']\n",
    "        student_worksheet_pdf = download_html_to_pdf(student_worksheet_link,f\"./{STANDARD}/worksheets/{student_name}.pdf\")\n",
    "        print_single_value_in_table(\"student_worksheet_link\",student_worksheet_link)\n",
    "        print_single_value_in_table(\"student_worksheet_pdf_cost\",student_worksheet_pdf)\n",
    "        print_single_value_in_table(\"cost\",cost)\n",
    "        TOTAL_COST += float(cost)\n",
    "        student_comparison_report_pdf = generate_individual_student_report(FILE_DESTINATION,student_name,f\"./{STANDARD}/reports/\")\n",
    "        full_output_path = combine_pdfs(student_comparison_report_pdf,student_worksheet_pdf,f\"./{STANDARD}/final_reports\",f\"{student_name}_insights.pdf\")\n",
    "        save_student_record(student_name,standard=STANDARD,cost=cost,worksheet_s3_link=student_worksheet_link)\n",
    "        output_paths.append(full_output_path)\n",
    "    print_single_value_in_table(\"Total Cost\",TOTAL_COST)\n",
    "    return output_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f97a17",
   "metadata": {},
   "source": [
    "<h1>Merge Pdfs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pdfs(pdf_path1, pdf_path2, output_folder, output_filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    Combine two PDFs into a single PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path1 (str): Path to the first PDF file\n",
    "        pdf_path2 (str): Path to the second PDF file\n",
    "        output_folder (str): Folder where the combined PDF will be saved\n",
    "        output_filename (str): Filename for the combined PDF\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the combined PDF file\n",
    "    \"\"\"\n",
    "    final_path_for_worksheet = '../../AutoExam-QPG' + pdf_path2[1:]\n",
    "    print(\"====PDF Paths======\")\n",
    "    print(pdf_path1, pdf_path2, output_folder, output_filename,final_path_for_worksheet)\n",
    "    print(\"====PDF Paths End====\")\n",
    "    try:\n",
    "        # Create a PDF merger object\n",
    "        merger = PdfMerger()\n",
    "        \n",
    "        # Append the PDFs to the merger\n",
    "        merger.append(pdf_path1)\n",
    "        merger.append(final_path_for_worksheet)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        full_output_path = os.path.join(output_folder, output_filename)        \n",
    "        # Write the combined PDF to the output path\n",
    "        merger.write(full_output_path)\n",
    "        merger.close()\n",
    "        print_single_value_in_table(\"Successfully combined PDFs and saved to\",full_output_path)\n",
    "        return full_output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        err_box_red(\"Error combining pdfs\",e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_topics_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = read_data(FILE_DESTINATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_validated = validate_data(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_students_data = classify_students_by_topic(student_data_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_topics_asked_in_examination = fetch_questions_for_topics()\n",
    "print_question_data(questions_for_topics_asked_in_examination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcd5ad2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_worksheet_for_students_and_combine_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassified_students_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m print_single_value_in_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal cost\u001b[39m\u001b[38;5;124m\"\u001b[39m,TOTAL_COST)\n",
      "Cell \u001b[0;32mIn[39], line 7\u001b[0m, in \u001b[0;36mgenerate_worksheet_for_students_and_combine_report\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m print_single_value_in_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent Being Processed\u001b[39m\u001b[38;5;124m\"\u001b[39m,student[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m student_name \u001b[38;5;241m=\u001b[39m student[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m [questions_and_insights_for_student,cost] \u001b[38;5;241m=\u001b[39m \u001b[43mget_questions_and_insights_for_individual_student\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m worksheet \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m      9\u001b[0m method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m url\u001b[38;5;241m=\u001b[39mGET_WORKSHEET_HTML,\n\u001b[1;32m     11\u001b[0m json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_data\u001b[39m\u001b[38;5;124m'\u001b[39m:questions_and_insights_for_student}\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(questions_and_insights_for_student)\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mget_questions_and_insights_for_individual_student\u001b[0;34m(user_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_questions_and_insights_for_individual_student\u001b[39m(user_data):\n\u001b[0;32m----> 3\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSYSTEM_PROMPT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_user_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     usage \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39musage\n\u001b[1;32m     12\u001b[0m     completion_tokens \u001b[38;5;241m=\u001b[39m usage\u001b[38;5;241m.\u001b[39mcompletion_tokens\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/openai/resources/beta/chat/completions.py:161\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    156\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    157\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    158\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    159\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/openai/_base_client.py:1003\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1000\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1009\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_worksheet_for_students_and_combine_report(classified_students_data)\n",
    "print_single_value_in_table(\"Total cost\",TOTAL_COST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
