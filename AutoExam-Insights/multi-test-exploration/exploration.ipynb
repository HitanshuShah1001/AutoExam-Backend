{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30294341",
   "metadata": {},
   "source": [
    "<h1>Import Libs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f591104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdb1bf",
   "metadata": {},
   "source": [
    "<h1>Constants</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE_ORIGIN = \"./student_data.csv\"\n",
    "FILE_DESTINATION = \"./student_data_final.csv\"\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS =  [\n",
    "        (\"Test1\", [\"English\", \"Maths\"], [\"A,B\", \"C,D\"]),\n",
    "        (\"Test2\", [\"English\", \"Maths\"], [\"B,C\", \"D,F\"])\n",
    "    ]\n",
    "API_URL = 'http://localhost:3000/'\n",
    "AUTH_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MywiZW1haWxJZCI6ImhpdGFuc2h1c2hhaDVAZ21haWwuY29tIiwiaWF0IjoxNzQ2NzE5OTI4LCJleHAiOjE3NDY4MDYzMjh9.oofQw4zUkKWcGXvYyJjdK0Mp1y25dlxVSsTRizGEBPE\"\n",
    "GET_QUESTIONS_FOR_TOPICS = API_URL + 'question/get-questions-for-chapters'\n",
    "SAVE_STUDENT_COST_PER_WORKSHEET = API_URL + '/student-stat-analysis/save-student-cost-per-worksheet'\n",
    "DOWNLOAD_FROM_S3_LINK =  API_URL + '/student-stat-analysis/download-worksheet-from-s3-link'\n",
    "GET_WORKSHEET_HTML = API_URL + '/analysis/getWorksheetHTML'\n",
    "TOTAL_COST = 0\n",
    "CHAPTERS = ['A', 'B', 'C', 'D', 'E', 'F']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee38fe",
   "metadata": {},
   "source": [
    "<h1> Read Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        student_data = pd.read_csv(file_path)\n",
    "        return student_data\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        student_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        return student_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052edb",
   "metadata": {},
   "source": [
    "<h1>Add topics to csv Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f0b01",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Setup for this demo:\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS = [\n",
    "    (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "    (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "]\n",
    "FILE_ORIGIN      = \"input.csv\"\n",
    "FILE_DESTINATION = \"output.csv\"\n",
    "\n",
    "# Contents of `input.csv`:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance\n",
    "# Alice,85,88,90,92,12\n",
    "# Bob,78,82,88,85,23\n",
    "# Charlie,92,94,76,78,24\n",
    "\n",
    "add_topics_to_csv()\n",
    "\n",
    "# After running, `output.csv` will include extra columns:\n",
    "#   English Topics Test1, Maths Topics Test1,\n",
    "#   English Topics Test2, Maths Topics Test2,\n",
    "#   English All Topics,    Maths All Topics\n",
    "#\n",
    "# And sample rows become:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance,English Topics Test1,Maths Topics Test1,English Topics Test2,Maths Topics Test2,English All Topics,Maths All Topics\n",
    "# Alice,85,88,90,92,12,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Bob,78,82,88,85,23,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Charlie,92,94,76,78,24,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def add_topics_to_csv():\n",
    "    \"\"\"\n",
    "    - input_csv_path, output_csv_path: file paths.\n",
    "    - tests: a list of (test_name, subjects, topic_values), e.g.:\n",
    "        [\n",
    "          (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "          (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "        ]\n",
    "    \n",
    "    This will add columns:\n",
    "      English Topics Test1, Maths Topics Test1,\n",
    "      English Topics Test2, Maths Topics Test2,\n",
    "      English All Topics,  Maths All Topics\n",
    "    \"\"\"\n",
    "    # 1) Validate\n",
    "    for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        if len(subjects) != len(chapters):\n",
    "            raise ValueError(f\"subjects vs topic_values length mismatch in {test_name}\")\n",
    "\n",
    "    # 2) Collect all unique subjects and append it to all_subjects\n",
    "    all_subjects: List[str] = []\n",
    "    for _, subjects, _ in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        for subj in subjects:\n",
    "            if subj not in all_subjects:\n",
    "                all_subjects.append(subj)\n",
    "\n",
    "    # 3) Build per-test lookup maps\n",
    "    test_topic_maps: Dict[str, Dict[str, str]] = {\n",
    "        test_name: dict(zip(subjects, chapters))\n",
    "        for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS\n",
    "    }\n",
    "\n",
    "    # 4) Open I/O\n",
    "    with open(FILE_ORIGIN, newline=\"\", encoding=\"utf-8\") as fin, \\\n",
    "         open(FILE_DESTINATION, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        # a) build the new header\n",
    "        extra_cols: List[str] = []\n",
    "        for test_name in test_topic_maps:\n",
    "            for subj in all_subjects:\n",
    "                if subj in test_topic_maps[test_name]:\n",
    "                    extra_cols.append(f\"{subj} Topics {test_name}\")\n",
    "        for subj in all_subjects:\n",
    "            extra_cols.append(f\"{subj} All Topics\")\n",
    "\n",
    "        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames + extra_cols)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 5) Process each row\n",
    "        for row in reader:\n",
    "            # per-test columns\n",
    "            for test_name, topics_map in test_topic_maps.items():\n",
    "                for subj, topics_str in topics_map.items():\n",
    "                    row[f\"{subj} Topics {test_name}\"] = topics_str\n",
    "\n",
    "            # aggregated union columns\n",
    "            for subj in all_subjects:\n",
    "                all_toks: List[str] = []\n",
    "                for topics_map in test_topic_maps.values():\n",
    "                    if subj in topics_map:\n",
    "                        # split on comma, strip whitespace\n",
    "                        all_toks.extend([tok.strip() for tok in topics_map[subj].split(\",\")])\n",
    "                # dedupe & sort (optional)\n",
    "                unique = sorted(set(tok for tok in all_toks if tok))\n",
    "                row[f\"{subj} All Topics\"] = \", \".join(unique)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc8db",
   "metadata": {},
   "source": [
    "<h1>Validate Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e7c4d",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Example setup\n",
    "import pandas as pd\n",
    "from your_module import validate_data  # adjust import as needed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': ['85', '78', '92'],\n",
    "    'English_Test2': ['88', '82', '94'],\n",
    "    'Maths_Test1': ['90', '88', '76'],\n",
    "    'Maths_Test2': ['92', '85', '78'],\n",
    "    'English Topics Test1': ['A,B', 'A,B', 'A,B'],\n",
    "    'Maths Topics Test1': ['C,D', 'C,D', 'C,D'],\n",
    "    'English Topics Test2': ['B,C', 'B,C', 'B,C'],\n",
    "    'Maths Topics Test2': ['D,F', 'D,F', 'D,F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24]\n",
    "})\n",
    "\n",
    "clean_df = validate_data(df)\n",
    "\n",
    "# Console output:\n",
    "# Number of students loaded: 3\n",
    "# \n",
    "#   Student Names  English_Test1  English_Test2  Maths_Test1  Maths_Test2  English Topics Test1  Maths Topics Test1  English Topics Test2  Maths Topics Test2  English All Topics  Maths All Topics  Attendance\n",
    "#0         Alice              85              88           90           92                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          12\n",
    "#1           Bob              78              82           88           85                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          23\n",
    "#2       Charlie              92              94           76           78                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data(df: pd.DataFrame, test_mark_cols=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates a student score DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Strips whitespace from all string columns\n",
    "    - Normalizes topic strings like \"A,B\" to \"A, B\"\n",
    "    - Detects missing names or marks\n",
    "    - Standardizes absent marks as 'AB'\n",
    "    - Converts valid marks to int/float\n",
    "    - Fills missing attendance with 0\n",
    "    - Prints a summary of absentees and preview of data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input student data.\n",
    "        test_mark_cols (list[str], optional): List of test score columns to validate. If None, inferred.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and validated dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # 0. Remove leading/trailing spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # 1. Normalize topic columns — ensure \"A, B, C\" format\n",
    "    topic_cols = [c for c in df.columns if re.search(r'topics', c, re.IGNORECASE)]\n",
    "    for col in topic_cols:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: ', '.join(p.strip() for p in x.split(',')) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # 2. Check for missing student names and report\n",
    "    if df['Student Names'].isna().any():\n",
    "        missing = df[df['Student Names'].isna()].index.tolist()\n",
    "        print(f\"Missing Student Names in rows: {missing}\")\n",
    "\n",
    "    # 3. Identify test mark columns: use passed ones or detect those matching '<Subject>_Test<N>'\n",
    "    if test_mark_cols is None:\n",
    "        test_mark_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "\n",
    "    # Ensure the specified test mark columns exist in DataFrame\n",
    "    missing_marks = [c for c in test_mark_cols if c not in df.columns]\n",
    "    if missing_marks:\n",
    "        raise KeyError(f\"Expected mark columns not found: {missing_marks}\")\n",
    "\n",
    "    # 4. Validate each test mark column\n",
    "    for col in test_mark_cols:\n",
    "        # a) Treat empty or NaN cells as 'AB' (Absent)\n",
    "        empty_mask = df[col].isna() | (df[col] == '')\n",
    "        if empty_mask.any():\n",
    "            for idx in df[empty_mask].index:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Missing {col} for {name}; marking as absent ('AB')\")\n",
    "            df.loc[empty_mask, col] = 'AB'\n",
    "\n",
    "        # b) Standardize all 'ab', 'Ab', etc. to uppercase 'AB'\n",
    "        is_ab = df[col].astype(str).str.upper().str.strip() == 'AB'\n",
    "        df.loc[is_ab, col] = 'AB'\n",
    "\n",
    "        # c) Try to convert other values to numbers, else mark as 'AB'\n",
    "        for idx in df.index:\n",
    "            if df.at[idx, col] == 'AB':\n",
    "                continue  # Skip if already marked absent\n",
    "            val = df.at[idx, col]\n",
    "            try:\n",
    "                num = float(val)\n",
    "                df.at[idx, col] = int(num) if num.is_integer() else num\n",
    "            except Exception:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Invalid {col} value '{val}' for {name}; marking as absent\")\n",
    "                df.at[idx, col] = 'AB'\n",
    "\n",
    "    # 5. Handle Attendance column\n",
    "    if 'Attendance' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'Attendance' not found\")\n",
    "\n",
    "    # Fill missing attendance with 0\n",
    "    if df['Attendance'].isna().any():\n",
    "        for idx in df[df['Attendance'].isna()].index:\n",
    "            name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "            print(f\"Attendance missing for {name}; setting to 0\")\n",
    "        df['Attendance'] = df['Attendance'].fillna(0)\n",
    "\n",
    "    # Ensure attendance is numeric integers\n",
    "    df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 6. Summary statistics\n",
    "    print(f\"\\nNumber of students loaded: {len(df)}\")\n",
    "    absent_summary = {\n",
    "        col: (df[col] == 'AB').sum() for col in test_mark_cols if (df[col] == 'AB').any()\n",
    "    }\n",
    "    if absent_summary:\n",
    "        print(\"\\nStudents marked as absent:\")\n",
    "        for col, count in absent_summary.items():\n",
    "            print(f\"  {col}: {count}\")\n",
    "\n",
    "    # 7. Print first 5 rows for review\n",
    "    print(df.head(5).to_string(index=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca7c9",
   "metadata": {},
   "source": [
    "<h1>Classify Students Strong and Weak Topics </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f877",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from your_module import classify_students_by_topic  # adjust import as needed\n",
    "\n",
    "# Input DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': [85, 78, 92],\n",
    "    'English_Test2': [88, 82, 94],\n",
    "    'Maths_Test1': [90, 88, 76],\n",
    "    'Maths_Test2': [92, 85, 78],\n",
    "    'English Topics Test1': ['A, B', 'A, B', 'A, B'],\n",
    "    'Maths Topics Test1': ['C, D', 'C, D', 'C, D'],\n",
    "    'English Topics Test2': ['B, C', 'B, C', 'B, C'],\n",
    "    'Maths Topics Test2': ['D, F', 'D, F', 'D, F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24],\n",
    "    \"Teacher's Remarks\": ['', '', '']\n",
    "})\n",
    "\n",
    "# Run classification\n",
    "results = classify_students_by_topic(df)\n",
    "print(results)\n",
    "\n",
    "# Expected Output:\n",
    "# [\n",
    "#     {\n",
    "#         'name': 'Alice',\n",
    "#         'attendance': 12,\n",
    "#         'remarks': '',\n",
    "#         'strong_topics':   ['A', 'B', 'C', 'D', 'F'],\n",
    "#         'weak_topics':     [],\n",
    "#         'practice_topics': [],\n",
    "#         'topic_details': [\n",
    "#             {'topic':'A','avg_pct':85.0,'num_tests':1},\n",
    "#             {'topic':'B','avg_pct':86.5,'num_tests':2},\n",
    "#             {'topic':'C','avg_pct':89.0,'num_tests':2},\n",
    "#             {'topic':'D','avg_pct':91.0,'num_tests':2},\n",
    "#             {'topic':'F','avg_pct':92.0,'num_tests':1},\n",
    "#         ],\n",
    "#         'test_details': [\n",
    "#             {'test_col':'English_Test1','subject':'English','raw':85,'pct':85.0,'topics':['A','B']},\n",
    "#             {'test_col':'English_Test2','subject':'English','raw':88,'pct':88.0,'topics':['B','C']},\n",
    "#             {'test_col':'Maths_Test1','subject':'Maths','raw':90,'pct':90.0,'topics':['C','D']},\n",
    "#             {'test_col':'Maths_Test2','subject':'Maths','raw':92,'pct':92.0,'topics':['D','F']},\n",
    "#         ]\n",
    "#     },\n",
    "#     { ... },  # Bob's dict\n",
    "#     { ... }   # Charlie's dict\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_students_by_topic(\n",
    "    df: pd.DataFrame,\n",
    "    max_score: float = 100.0,\n",
    "    strong_thresh: float = 85.0,\n",
    "    weak_thresh: float = 70.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Classify students into strong/weak/practice *topics* based on multiple tests.\n",
    "\n",
    "    Logic & reasoning:\n",
    "      1. We may have multiple tests per subject, each covering overlapping topics.\n",
    "      2. For each student-topic pair, we collect all test percentages in which that topic appeared.\n",
    "      3. We compute the *average percentage* for that topic.\n",
    "      4. We apply *fixed thresholds* (85% for strong, 70% for weak) rather than class-level percentiles—\n",
    "         because topic-level data can be sparse and unevenly distributed.\n",
    "      5. Topics ≥ strong_thresh → strong; ≤ weak_thresh → weak; otherwise → practice.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing:\n",
    "            - \"Student Names\", one or more \"<Subject>_Test<N>\" columns,\n",
    "            - corresponding \"<Subject> Topics Test<N>\" columns,\n",
    "            - \"Attendance\" and \"Teacher's Remarks\".\n",
    "        max_score: Maximum possible raw score per test.\n",
    "        strong_thresh: Percentage threshold above which a topic is 'strong'.\n",
    "        weak_thresh: Percentage threshold below which a topic is 'weak'.\n",
    "\n",
    "    Returns:\n",
    "        A list of per-student dicts with keys:\n",
    "          - name, attendance, remarks\n",
    "          - strong_topics, weak_topics, practice_topics\n",
    "          - topic_details: list of { topic, avg_pct, count_of_tests }\n",
    "          - test_details: list of { test_col, subject, raw, pct, topics }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1) Identify all test-score columns, e.g. 'English_Test1', 'Maths_Test2', etc.\n",
    "    test_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "    # 2) Identify all topic columns for tests: '<Subject> Topics Test<N>'\n",
    "    topic_cols = [c for c in df.columns if re.match(r'.+ Topics Test\\d+', c)]\n",
    "\n",
    "    # Build a mapping from each test column to its topic-column name\n",
    "    # e.g. { 'English_Test1': 'English Topics Test1', ... }\n",
    "    test_to_topics = {}\n",
    "    for tc in test_cols:\n",
    "        subj, num = tc.rsplit('_Test', 1)\n",
    "        tcol = f\"{subj} Topics Test{num}\"\n",
    "        if tcol in df.columns:\n",
    "            test_to_topics[tc] = tcol\n",
    "        else:\n",
    "            raise KeyError(f\"Missing topics column for {tc}: expected '{tcol}'\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name       = row['Student Names']\n",
    "        attendance = row.get('Attendance')\n",
    "        remarks    = row.get(\"Teacher's Remarks\", \"\")\n",
    "\n",
    "        # Will collect raw details for debugging/reporting\n",
    "        test_details  = []\n",
    "        # topic_scores accumulates all pct values per topic\n",
    "        topic_scores  = {}\n",
    "\n",
    "        # 3) Loop through each test, parse marks and topics\n",
    "        for tc, tcol in test_to_topics.items():\n",
    "            raw = row[tc]\n",
    "            # a) Handle absent\n",
    "            if isinstance(raw, str) and raw.strip().upper() == 'AB':\n",
    "                pct = np.nan\n",
    "            else:\n",
    "                raw_num = pd.to_numeric(raw, errors='coerce')\n",
    "                pct     = (raw_num * 100.0 / max_score) if pd.notna(raw_num) else np.nan\n",
    "\n",
    "            # b) Parse topics list for this test\n",
    "            topics = []\n",
    "            tstr = row.get(tcol, \"\")\n",
    "            if isinstance(tstr, str) and tstr.strip():\n",
    "                topics = [t.strip() for t in tstr.split(',')]\n",
    "\n",
    "            # c) Record test detail\n",
    "            #    (helps trace exactly which tests contributed to each topic)\n",
    "            test_details.append({\n",
    "                'test_col': tc,\n",
    "                'subject':  tc.split('_Test')[0],\n",
    "                'raw':      raw,\n",
    "                'pct':      pct,\n",
    "                'topics':   topics\n",
    "            })\n",
    "\n",
    "            # d) Append pct to each topic's list\n",
    "            for topic in topics:\n",
    "                topic_scores.setdefault(topic, []).append(pct)\n",
    "\n",
    "        # 4) Compute average pct per topic & classify\n",
    "        strong_topics  = []\n",
    "        weak_topics    = []\n",
    "        practice_topics = []\n",
    "        topic_details   = []\n",
    "\n",
    "        for topic, pcts in topic_scores.items():\n",
    "            # ignore NaNs when averaging\n",
    "            valid = [p for p in pcts if pd.notna(p)]\n",
    "            avg_pct = float(np.nan) if not valid else sum(valid) / len(valid)\n",
    "\n",
    "            # classify based on fixed thresholds\n",
    "            if pd.notna(avg_pct):\n",
    "                if avg_pct >= strong_thresh:\n",
    "                    strong_topics.append(topic)\n",
    "                elif avg_pct <= weak_thresh:\n",
    "                    weak_topics.append(topic)\n",
    "                else:\n",
    "                    practice_topics.append(topic)\n",
    "\n",
    "            topic_details.append({\n",
    "                'topic':     topic,\n",
    "                'avg_pct':   avg_pct,\n",
    "                'num_tests': len(valid)\n",
    "            })\n",
    "\n",
    "        # 5) Assemble result for this student\n",
    "        results.append({\n",
    "            'name':             name,\n",
    "            'attendance':       attendance,\n",
    "            'remarks':          remarks,\n",
    "            'strong_topics':    strong_topics,\n",
    "            'weak_topics':      weak_topics,\n",
    "            'practice_topics':  practice_topics,\n",
    "            'topic_details':    topic_details,\n",
    "            'test_details':     test_details\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e198e49",
   "metadata": {},
   "source": [
    "<h1>Call API to get questions for all the chapters asked in the examination</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db4c9f",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from your_module import fetch_questions_for_topics  # adjust import as needed\n",
    "\n",
    "# Setup for demo:\n",
    "AUTH_TOKEN = \"Bearer your_token_here\"\n",
    "API_URL    = \"https://api.yoursite.com/getQuestionsForChapters\"\n",
    "chapters   = [\"Algebra Basics\", \"Calculus I\", \"Geometry Fundamentals\"]\n",
    "\n",
    "# Run the function\n",
    "results = fetch_questions_for_topics()\n",
    "print(results)\n",
    "\n",
    "# Expected Output (example structure):\n",
    "# [\n",
    "#   {\n",
    "#     \"Algebra Basics\": [\n",
    "#       \"What is the solution to x + 5 = 12?\",\n",
    "#       \"Describe the properties of a linear equation.\",\n",
    "#       {\"questionText\": \"Solve for y: 2y = 14\", \"options\": [{\"key\":\"A\",\"option\":\"y=6\"},{\"key\":\"B\",\"option\":\"y=7\"}, …]},\n",
    "#       … up to 10 questions total …\n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Calculus I\": [\n",
    "#       \"Explain the concept of a derivative.\",\n",
    "#       {\"questionText\": \"Find d/dx of x² + 3x\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Geometry Fundamentals\": [\n",
    "#       \"What defines a right triangle?\",\n",
    "#       {\"questionText\":\"Which angle is opposite the hypotenuse?\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc772b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions_for_topics():\n",
    "    chapters = sorted(chapters)\n",
    "    # 4. Build headers & payload\n",
    "    headers = {\n",
    "        'Authorization': AUTH_TOKEN,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {'chapters': chapters}\n",
    "    # 5. Fire the GET (or POST if you prefer) with JSON body\n",
    "    response = requests.get(API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_topics_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = read_data(FILE_DESTINATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_validated = validate_data(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_students_data = classify_students_by_topic(student_data_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_topics_asked_in_examination = fetch_questions_for_topics(GET_QUESTIONS_FOR_TOPICS, AUTH_TOKEN,CHAPTERS)\n",
    "print_question_data(questions_for_topics_asked_in_examination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
