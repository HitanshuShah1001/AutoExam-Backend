{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30294341",
   "metadata": {},
   "source": [
    "<h1>Import Libs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f591104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from utils import print_question_data\n",
    "from utils import print_first_5_students\n",
    "from utils import print_single_value_in_table\n",
    "import openai as client\n",
    "from utils import print_single_value_in_table\n",
    "from utils import err_box_red\n",
    "from utils import pretty_print_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdb1bf",
   "metadata": {},
   "source": [
    "<h1>Constants</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE_ORIGIN = \"./student_data.csv\"\n",
    "FILE_DESTINATION = \"./student_data_final.csv\"\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS =  [\n",
    "        (\"Test1\", [\"English\", \"Maths\"], [\"A,B\", \"C,D\"]),\n",
    "        (\"Test2\", [\"English\", \"Maths\"], [\"B,C\", \"D,F\"])\n",
    "    ]\n",
    "API_URL = 'http://localhost:3000/'\n",
    "AUTH_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MywiZW1haWxJZCI6ImhpdGFuc2h1c2hhaDVAZ21haWwuY29tIiwiaWF0IjoxNzQ2NzE5OTI4LCJleHAiOjE3NDY4MDYzMjh9.oofQw4zUkKWcGXvYyJjdK0Mp1y25dlxVSsTRizGEBPE\"\n",
    "GET_QUESTIONS_FOR_TOPICS = API_URL + 'question/get-questions-for-chapters'\n",
    "SAVE_STUDENT_COST_PER_WORKSHEET = API_URL + '/student-stat-analysis/save-student-cost-per-worksheet'\n",
    "DOWNLOAD_FROM_S3_LINK =  API_URL + '/student-stat-analysis/download-worksheet-from-s3-link'\n",
    "GET_WORKSHEET_HTML = API_URL + '/analysis/getWorksheetHTML'\n",
    "TOTAL_COST = 0\n",
    "CHAPTERS = ['A', 'B', 'C', 'D', 'E', 'F']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee38fe",
   "metadata": {},
   "source": [
    "<h1> Read Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        student_data = pd.read_csv(file_path)\n",
    "        return student_data\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        student_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        return student_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052edb",
   "metadata": {},
   "source": [
    "<h1>Add topics to csv Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f0b01",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Setup for this demo:\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS = [\n",
    "    (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "    (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "]\n",
    "FILE_ORIGIN      = \"input.csv\"\n",
    "FILE_DESTINATION = \"output.csv\"\n",
    "\n",
    "# Contents of `input.csv`:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance\n",
    "# Alice,85,88,90,92,12\n",
    "# Bob,78,82,88,85,23\n",
    "# Charlie,92,94,76,78,24\n",
    "\n",
    "add_topics_to_csv()\n",
    "\n",
    "# After running, `output.csv` will include extra columns:\n",
    "#   English Topics Test1, Maths Topics Test1,\n",
    "#   English Topics Test2, Maths Topics Test2,\n",
    "#   English All Topics,    Maths All Topics\n",
    "#\n",
    "# And sample rows become:\n",
    "# Student Names,English_Test1,English_Test2,Maths_Test1,Maths_Test2,Attendance,English Topics Test1,Maths Topics Test1,English Topics Test2,Maths Topics Test2,English All Topics,Maths All Topics\n",
    "# Alice,85,88,90,92,12,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Bob,78,82,88,85,23,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n",
    "# Charlie,92,94,76,78,24,\"A,B\",\"C,D\",\"B,C\",\"E,F\",\"A, B, C\",\"C, D, E, F\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def add_topics_to_csv():\n",
    "    \"\"\"\n",
    "    - input_csv_path, output_csv_path: file paths.\n",
    "    - tests: a list of (test_name, subjects, topic_values), e.g.:\n",
    "        [\n",
    "          (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "          (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "        ]\n",
    "    \n",
    "    This will add columns:\n",
    "      English Topics Test1, Maths Topics Test1,\n",
    "      English Topics Test2, Maths Topics Test2,\n",
    "      English All Topics,  Maths All Topics\n",
    "    \"\"\"\n",
    "    # 1) Validate\n",
    "    for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        if len(subjects) != len(chapters):\n",
    "            raise ValueError(f\"subjects vs topic_values length mismatch in {test_name}\")\n",
    "\n",
    "    # 2) Collect all unique subjects and append it to all_subjects\n",
    "    all_subjects: List[str] = []\n",
    "    for _, subjects, _ in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        for subj in subjects:\n",
    "            if subj not in all_subjects:\n",
    "                all_subjects.append(subj)\n",
    "\n",
    "    # 3) Build per-test lookup maps\n",
    "    test_topic_maps: Dict[str, Dict[str, str]] = {\n",
    "        test_name: dict(zip(subjects, chapters))\n",
    "        for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS\n",
    "    }\n",
    "\n",
    "    # 4) Open I/O\n",
    "    with open(FILE_ORIGIN, newline=\"\", encoding=\"utf-8\") as fin, \\\n",
    "         open(FILE_DESTINATION, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        # a) build the new header\n",
    "        extra_cols: List[str] = []\n",
    "        for test_name in test_topic_maps:\n",
    "            for subj in all_subjects:\n",
    "                if subj in test_topic_maps[test_name]:\n",
    "                    extra_cols.append(f\"{subj} Topics {test_name}\")\n",
    "        for subj in all_subjects:\n",
    "            extra_cols.append(f\"{subj} All Topics\")\n",
    "\n",
    "        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames + extra_cols)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 5) Process each row\n",
    "        for row in reader:\n",
    "            # per-test columns\n",
    "            for test_name, topics_map in test_topic_maps.items():\n",
    "                for subj, topics_str in topics_map.items():\n",
    "                    row[f\"{subj} Topics {test_name}\"] = topics_str\n",
    "\n",
    "            # aggregated union columns\n",
    "            for subj in all_subjects:\n",
    "                all_toks: List[str] = []\n",
    "                for topics_map in test_topic_maps.values():\n",
    "                    if subj in topics_map:\n",
    "                        # split on comma, strip whitespace\n",
    "                        all_toks.extend([tok.strip() for tok in topics_map[subj].split(\",\")])\n",
    "                # dedupe & sort (optional)\n",
    "                unique = sorted(set(tok for tok in all_toks if tok))\n",
    "                row[f\"{subj} All Topics\"] = \", \".join(unique)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc8db",
   "metadata": {},
   "source": [
    "<h1>Validate Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e7c4d",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "# Example setup\n",
    "import pandas as pd\n",
    "from your_module import validate_data  # adjust import as needed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': ['85', '78', '92'],\n",
    "    'English_Test2': ['88', '82', '94'],\n",
    "    'Maths_Test1': ['90', '88', '76'],\n",
    "    'Maths_Test2': ['92', '85', '78'],\n",
    "    'English Topics Test1': ['A,B', 'A,B', 'A,B'],\n",
    "    'Maths Topics Test1': ['C,D', 'C,D', 'C,D'],\n",
    "    'English Topics Test2': ['B,C', 'B,C', 'B,C'],\n",
    "    'Maths Topics Test2': ['D,F', 'D,F', 'D,F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24]\n",
    "})\n",
    "\n",
    "clean_df = validate_data(df)\n",
    "\n",
    "# Console output:\n",
    "# Number of students loaded: 3\n",
    "# \n",
    "#   Student Names  English_Test1  English_Test2  Maths_Test1  Maths_Test2  English Topics Test1  Maths Topics Test1  English Topics Test2  Maths Topics Test2  English All Topics  Maths All Topics  Attendance\n",
    "#0         Alice              85              88           90           92                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          12\n",
    "#1           Bob              78              82           88           85                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          23\n",
    "#2       Charlie              92              94           76           78                 A, B                C, D                 B, C                D, F            A, B, C          C, D, F          24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data(df: pd.DataFrame, test_mark_cols=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates a student score DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Strips whitespace from all string columns\n",
    "    - Normalizes topic strings like \"A,B\" to \"A, B\"\n",
    "    - Detects missing names or marks\n",
    "    - Standardizes absent marks as 'AB'\n",
    "    - Converts valid marks to int/float\n",
    "    - Fills missing attendance with 0\n",
    "    - Prints a summary of absentees and preview of data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input student data.\n",
    "        test_mark_cols (list[str], optional): List of test score columns to validate. If None, inferred.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and validated dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # 0. Remove leading/trailing spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # 1. Normalize topic columns — ensure \"A, B, C\" format\n",
    "    topic_cols = [c for c in df.columns if re.search(r'topics', c, re.IGNORECASE)]\n",
    "    for col in topic_cols:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: ', '.join(p.strip() for p in x.split(',')) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # 2. Check for missing student names and report\n",
    "    if df['Student Names'].isna().any():\n",
    "        missing = df[df['Student Names'].isna()].index.tolist()\n",
    "        print(f\"Missing Student Names in rows: {missing}\")\n",
    "\n",
    "    # 3. Identify test mark columns: use passed ones or detect those matching '<Subject>_Test<N>'\n",
    "    if test_mark_cols is None:\n",
    "        test_mark_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "\n",
    "    # Ensure the specified test mark columns exist in DataFrame\n",
    "    missing_marks = [c for c in test_mark_cols if c not in df.columns]\n",
    "    if missing_marks:\n",
    "        raise KeyError(f\"Expected mark columns not found: {missing_marks}\")\n",
    "\n",
    "    # 4. Validate each test mark column\n",
    "    for col in test_mark_cols:\n",
    "        # a) Treat empty or NaN cells as 'AB' (Absent)\n",
    "        empty_mask = df[col].isna() | (df[col] == '')\n",
    "        if empty_mask.any():\n",
    "            for idx in df[empty_mask].index:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Missing {col} for {name}; marking as absent ('AB')\")\n",
    "            df.loc[empty_mask, col] = 'AB'\n",
    "\n",
    "        # b) Standardize all 'ab', 'Ab', etc. to uppercase 'AB'\n",
    "        is_ab = df[col].astype(str).str.upper().str.strip() == 'AB'\n",
    "        df.loc[is_ab, col] = 'AB'\n",
    "\n",
    "        # c) Try to convert other values to numbers, else mark as 'AB'\n",
    "        for idx in df.index:\n",
    "            if df.at[idx, col] == 'AB':\n",
    "                continue  # Skip if already marked absent\n",
    "            val = df.at[idx, col]\n",
    "            try:\n",
    "                num = float(val)\n",
    "                df.at[idx, col] = int(num) if num.is_integer() else num\n",
    "            except Exception:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Invalid {col} value '{val}' for {name}; marking as absent\")\n",
    "                df.at[idx, col] = 'AB'\n",
    "\n",
    "    # 5. Handle Attendance column\n",
    "    if 'Attendance' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'Attendance' not found\")\n",
    "\n",
    "    # Fill missing attendance with 0\n",
    "    if df['Attendance'].isna().any():\n",
    "        for idx in df[df['Attendance'].isna()].index:\n",
    "            name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "            print(f\"Attendance missing for {name}; setting to 0\")\n",
    "        df['Attendance'] = df['Attendance'].fillna(0)\n",
    "\n",
    "    # Ensure attendance is numeric integers\n",
    "    df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 6. Summary statistics\n",
    "    print(f\"\\nNumber of students loaded: {len(df)}\")\n",
    "    absent_summary = {\n",
    "        col: (df[col] == 'AB').sum() for col in test_mark_cols if (df[col] == 'AB').any()\n",
    "    }\n",
    "    if absent_summary:\n",
    "        print(\"\\nStudents marked as absent:\")\n",
    "        for col, count in absent_summary.items():\n",
    "            print(f\"  {col}: {count}\")\n",
    "\n",
    "    # 7. Print first 5 rows for review\n",
    "    print(df.head(5).to_string(index=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca7c9",
   "metadata": {},
   "source": [
    "<h1>Classify Students Strong and Weak Topics </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f877",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from your_module import classify_students_by_topic  # adjust import as needed\n",
    "\n",
    "# Input DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Student Names': ['Alice', 'Bob', 'Charlie'],\n",
    "    'English_Test1': [85, 78, 92],\n",
    "    'English_Test2': [88, 82, 94],\n",
    "    'Maths_Test1': [90, 88, 76],\n",
    "    'Maths_Test2': [92, 85, 78],\n",
    "    'English Topics Test1': ['A, B', 'A, B', 'A, B'],\n",
    "    'Maths Topics Test1': ['C, D', 'C, D', 'C, D'],\n",
    "    'English Topics Test2': ['B, C', 'B, C', 'B, C'],\n",
    "    'Maths Topics Test2': ['D, F', 'D, F', 'D, F'],\n",
    "    'English All Topics': ['A, B, C', 'A, B, C', 'A, B, C'],\n",
    "    'Maths All Topics': ['C, D, F', 'C, D, F', 'C, D, F'],\n",
    "    'Attendance': [12, 23, 24],\n",
    "    \"Teacher's Remarks\": ['', '', '']\n",
    "})\n",
    "\n",
    "# Run classification\n",
    "results = classify_students_by_topic(df)\n",
    "print(results)\n",
    "\n",
    "# Expected Output:\n",
    "# [\n",
    "#     {\n",
    "#         'name': 'Alice',\n",
    "#         'attendance': 12,\n",
    "#         'remarks': '',\n",
    "#         'strong_topics':   ['A', 'B', 'C', 'D', 'F'],\n",
    "#         'weak_topics':     [],\n",
    "#         'practice_topics': [],\n",
    "#         'topic_details': [\n",
    "#             {'topic':'A','avg_pct':85.0,'num_tests':1},\n",
    "#             {'topic':'B','avg_pct':86.5,'num_tests':2},\n",
    "#             {'topic':'C','avg_pct':89.0,'num_tests':2},\n",
    "#             {'topic':'D','avg_pct':91.0,'num_tests':2},\n",
    "#             {'topic':'F','avg_pct':92.0,'num_tests':1},\n",
    "#         ],\n",
    "#         'test_details': [\n",
    "#             {'test_col':'English_Test1','subject':'English','raw':85,'pct':85.0,'topics':['A','B']},\n",
    "#             {'test_col':'English_Test2','subject':'English','raw':88,'pct':88.0,'topics':['B','C']},\n",
    "#             {'test_col':'Maths_Test1','subject':'Maths','raw':90,'pct':90.0,'topics':['C','D']},\n",
    "#             {'test_col':'Maths_Test2','subject':'Maths','raw':92,'pct':92.0,'topics':['D','F']},\n",
    "#         ]\n",
    "#     },\n",
    "#     { ... },  # Bob's dict\n",
    "#     { ... }   # Charlie's dict\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_students_by_topic(\n",
    "    df: pd.DataFrame,\n",
    "    max_score: float = 100.0,\n",
    "    strong_thresh: float = 85.0,\n",
    "    weak_thresh: float = 70.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Classify students into strong/weak/practice *topics* based on multiple tests.\n",
    "\n",
    "    Logic & reasoning:\n",
    "      1. We may have multiple tests per subject, each covering overlapping topics.\n",
    "      2. For each student-topic pair, we collect all test percentages in which that topic appeared.\n",
    "      3. We compute the *average percentage* for that topic.\n",
    "      4. We apply *fixed thresholds* (85% for strong, 70% for weak) rather than class-level percentiles—\n",
    "         because topic-level data can be sparse and unevenly distributed.\n",
    "      5. Topics ≥ strong_thresh → strong; ≤ weak_thresh → weak; otherwise → practice.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing:\n",
    "            - \"Student Names\", one or more \"<Subject>_Test<N>\" columns,\n",
    "            - corresponding \"<Subject> Topics Test<N>\" columns,\n",
    "            - \"Attendance\" and \"Teacher's Remarks\".\n",
    "        max_score: Maximum possible raw score per test.\n",
    "        strong_thresh: Percentage threshold above which a topic is 'strong'.\n",
    "        weak_thresh: Percentage threshold below which a topic is 'weak'.\n",
    "\n",
    "    Returns:\n",
    "        A list of per-student dicts with keys:\n",
    "          - name, attendance, remarks\n",
    "          - strong_topics, weak_topics, practice_topics\n",
    "          - topic_details: list of { topic, avg_pct, count_of_tests }\n",
    "          - test_details: list of { test_col, subject, raw, pct, topics }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1) Identify all test-score columns, e.g. 'English_Test1', 'Maths_Test2', etc.\n",
    "    test_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "    # 2) Identify all topic columns for tests: '<Subject> Topics Test<N>'\n",
    "    topic_cols = [c for c in df.columns if re.match(r'.+ Topics Test\\d+', c)]\n",
    "\n",
    "    # Build a mapping from each test column to its topic-column name\n",
    "    # e.g. { 'English_Test1': 'English Topics Test1', ... }\n",
    "    test_to_topics = {}\n",
    "    for tc in test_cols:\n",
    "        subj, num = tc.rsplit('_Test', 1)\n",
    "        tcol = f\"{subj} Topics Test{num}\"\n",
    "        if tcol in df.columns:\n",
    "            test_to_topics[tc] = tcol\n",
    "        else:\n",
    "            raise KeyError(f\"Missing topics column for {tc}: expected '{tcol}'\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name       = row['Student Names']\n",
    "        attendance = row.get('Attendance')\n",
    "        remarks    = row.get(\"Teacher's Remarks\", \"\")\n",
    "\n",
    "        # Will collect raw details for debugging/reporting\n",
    "        test_details  = []\n",
    "        # topic_scores accumulates all pct values per topic\n",
    "        topic_scores  = {}\n",
    "\n",
    "        # 3) Loop through each test, parse marks and topics\n",
    "        for tc, tcol in test_to_topics.items():\n",
    "            raw = row[tc]\n",
    "            # a) Handle absent\n",
    "            if isinstance(raw, str) and raw.strip().upper() == 'AB':\n",
    "                pct = np.nan\n",
    "            else:\n",
    "                raw_num = pd.to_numeric(raw, errors='coerce')\n",
    "                pct     = (raw_num * 100.0 / max_score) if pd.notna(raw_num) else np.nan\n",
    "\n",
    "            # b) Parse topics list for this test\n",
    "            topics = []\n",
    "            tstr = row.get(tcol, \"\")\n",
    "            if isinstance(tstr, str) and tstr.strip():\n",
    "                topics = [t.strip() for t in tstr.split(',')]\n",
    "\n",
    "            # c) Record test detail\n",
    "            #    (helps trace exactly which tests contributed to each topic)\n",
    "            test_details.append({\n",
    "                'test_col': tc,\n",
    "                'subject':  tc.split('_Test')[0],\n",
    "                'raw':      raw,\n",
    "                'pct':      pct,\n",
    "                'topics':   topics\n",
    "            })\n",
    "\n",
    "            # d) Append pct to each topic's list\n",
    "            for topic in topics:\n",
    "                topic_scores.setdefault(topic, []).append(pct)\n",
    "\n",
    "        # 4) Compute average pct per topic & classify\n",
    "        strong_topics  = []\n",
    "        weak_topics    = []\n",
    "        practice_topics = []\n",
    "        topic_details   = []\n",
    "\n",
    "        for topic, pcts in topic_scores.items():\n",
    "            # ignore NaNs when averaging\n",
    "            valid = [p for p in pcts if pd.notna(p)]\n",
    "            avg_pct = float(np.nan) if not valid else sum(valid) / len(valid)\n",
    "\n",
    "            # classify based on fixed thresholds\n",
    "            if pd.notna(avg_pct):\n",
    "                if avg_pct >= strong_thresh:\n",
    "                    strong_topics.append(topic)\n",
    "                elif avg_pct <= weak_thresh:\n",
    "                    weak_topics.append(topic)\n",
    "                else:\n",
    "                    practice_topics.append(topic)\n",
    "\n",
    "            topic_details.append({\n",
    "                'topic':     topic,\n",
    "                'avg_pct':   avg_pct,\n",
    "                'num_tests': len(valid)\n",
    "            })\n",
    "\n",
    "        # 5) Assemble result for this student\n",
    "        results.append({\n",
    "            'name':             name,\n",
    "            'attendance':       attendance,\n",
    "            'remarks':          remarks,\n",
    "            'strong_topics':    strong_topics,\n",
    "            'weak_topics':      weak_topics,\n",
    "            'practice_topics':  practice_topics,\n",
    "            'topic_details':    topic_details,\n",
    "            'test_details':     test_details\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e198e49",
   "metadata": {},
   "source": [
    "<h1>Call API to get questions for all the chapters asked in the examination</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db4c9f",
   "metadata": {},
   "source": [
    "### Demo Input → Expected Output\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from your_module import fetch_questions_for_topics  # adjust import as needed\n",
    "\n",
    "# Setup for demo:\n",
    "AUTH_TOKEN = \"Bearer your_token_here\"\n",
    "API_URL    = \"https://api.yoursite.com/getQuestionsForChapters\"\n",
    "chapters   = [\"Algebra Basics\", \"Calculus I\", \"Geometry Fundamentals\"]\n",
    "\n",
    "# Run the function\n",
    "results = fetch_questions_for_topics()\n",
    "print(results)\n",
    "\n",
    "# Expected Output (example structure):\n",
    "# [\n",
    "#   {\n",
    "#     \"Algebra Basics\": [\n",
    "#       \"What is the solution to x + 5 = 12?\",\n",
    "#       \"Describe the properties of a linear equation.\",\n",
    "#       {\"questionText\": \"Solve for y: 2y = 14\", \"options\": [{\"key\":\"A\",\"option\":\"y=6\"},{\"key\":\"B\",\"option\":\"y=7\"}, …]},\n",
    "#       … up to 10 questions total …\n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Calculus I\": [\n",
    "#       \"Explain the concept of a derivative.\",\n",
    "#       {\"questionText\": \"Find d/dx of x² + 3x\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   },\n",
    "#   {\n",
    "#     \"Geometry Fundamentals\": [\n",
    "#       \"What defines a right triangle?\",\n",
    "#       {\"questionText\":\"Which angle is opposite the hypotenuse?\", \"options\":[…]},\n",
    "#       … \n",
    "#     ]\n",
    "#   }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc772b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions_for_topics():\n",
    "    chapters = sorted(chapters)\n",
    "    # 4. Build headers & payload\n",
    "    headers = {\n",
    "        'Authorization': AUTH_TOKEN,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {'chapters': chapters}\n",
    "    # 5. Fire the GET (or POST if you prefer) with JSON body\n",
    "    response = requests.get(API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca4301",
   "metadata": {},
   "source": [
    "<h1>Create System Prompt and User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an advanced educational insights generator and personalized learning advisor with expertise in analyzing student academic performance across multiple tests and subjects.\n",
    "\n",
    "Your primary responsibilities include:\n",
    "\n",
    "## Performance Analysis:\n",
    "- Analyze student performance data from multiple tests across different subjects\n",
    "- Focus primarily on test_details array as it provides the most accurate representation of student performance\n",
    "- Identify performance trends across multiple tests in the same subject\n",
    "- Compare performance across different subjects to identify relative strengths and weaknesses\n",
    "- Use topic_details for supplementary insights about topic-wise average performance\n",
    "\n",
    "## Insight Generation:\n",
    "- Generate comprehensive subject-wise analysis showing performance trends\n",
    "- Identify strong topics (>75% average performance) and weak topics (<65% average performance)\n",
    "- Prioritize focus areas based on consistent poor performance across multiple tests\n",
    "- Provide specific, actionable improvement strategies for each weak area\n",
    "- Consider the number of tests taken per topic when making assessments\n",
    "\n",
    "## Question Generation Guidelines:\n",
    "- Generate 6-8 practice questions ONLY for topics identified as weak or needing improvement\n",
    "- Focus on topics that appear in priority_focus_areas\n",
    "- Create a balanced mix of difficulty levels: 2-3 easy, 2-3 medium, 2-3 hard questions per topic\n",
    "- For Math subjects: Generate questions similar to provided sample questions with appropriate difficulty progression\n",
    "- For English Grammar: Create questions following the style and pattern of provided samples\n",
    "- For English Literature/Stories: Use questions directly from provided samples when available\n",
    "- For Social Studies: Use questions directly from provided samples when available\n",
    "- Exclude questions that require images or visual elements\n",
    "- Ensure questions are grade-appropriate and align with curriculum standards\n",
    "\n",
    "## Parent Communication:\n",
    "- Write in simple, clear English that Indian parents can easily understand\n",
    "- Address the student by name throughout for personalization\n",
    "- Use a supportive, encouraging tone while being honest about areas needing improvement\n",
    "- Provide specific, practical advice that parents can implement at home\n",
    "- Include references to attendance and teacher remarks when relevant\n",
    "- Focus on growth mindset and positive reinforcement\n",
    "- Avoid overly technical educational jargon\n",
    "\n",
    "## Key Principles:\n",
    "- Prioritize insights from test_details over other data sources\n",
    "- Be specific about which tests showed improvement or decline\n",
    "- Provide context for performance (e.g., \"improved from 65% in Test 1 to 78% in Test 2\")\n",
    "- Address the student using male/female pronouns when gender-specific language is needed and if you are unaware just use \"the student\"\n",
    "- Use the provided sample questions as a guide for generating new questions\n",
    "- Ensure all generated questions are relevant to the identified weak topics\n",
    "- Maintain a positive, constructive tone throughout the analysis\n",
    "- Focus on actionable steps parents can take to support their child's learning\n",
    "- Avoid making assumptions about the student's abilities or background\n",
    "- Maintain an encouraging, growth-focused approach throughout all content\n",
    "- Ensure all recommendations are actionable and realistic for home implementation\n",
    "\n",
    "Remember: Your goal is to help parents understand exactly where their child stands academically and provide them with clear, practical steps to support their child's improvement at home.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39d413",
   "metadata": {},
   "source": [
    "<h1>Create User Prompt</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_prompt(user_data):\n",
    "    prompt = f\"\"\"\n",
    "    You are provided with comprehensive student performance data below:\n",
    "    \n",
    "    **Student Data:**\n",
    "    {user_data}\n",
    "    \n",
    "    **Your Tasks:**\n",
    "    \n",
    "    1. **Analyze Performance Trends:**\n",
    "       - Focus primarily on the 'test_details' array to understand actual test performance\n",
    "       - Look for patterns across multiple tests in the same subject\n",
    "       - Identify subjects and topics where performance is declining, improving, or consistent\n",
    "       - Use 'topic_details' for additional context on average performance per topic\n",
    "    \n",
    "    2. **Generate Comprehensive Insights:**\n",
    "       - Create subject-wise analysis showing performance trends\n",
    "       - Identify priority focus areas based on consistent poor performance\n",
    "       - Provide specific improvement strategies for weak topics\n",
    "       - Highlight strengths and areas where the student is performing well\n",
    "    \n",
    "    3. **Create Targeted Practice Questions:**\n",
    "       - Generate questions ONLY for topics identified as weak or needing improvement\n",
    "       - Use the sample questions provided below as reference for style and difficulty\n",
    "       - Ensure questions match the academic level and curriculum requirements\n",
    "       - Focus on topics that appear in your priority_focus_areas analysis\n",
    "    \n",
    "    **Sample Questions for Reference:**\n",
    "    {questions_for_topics_asked_in_examination}\n",
    "    \n",
    "    **Important Guidelines:**\n",
    "    - Weight your analysis heavily toward test_details as it shows actual test performance\n",
    "    - Be specific about which tests showed what performance levels\n",
    "    - Provide context for performance changes across multiple tests\n",
    "    - Generate questions only for improvement areas, not for strong topics\n",
    "    - Ensure parent recommendations are practical and implementable at home\n",
    "    \n",
    "    Please provide your response in the required JSON format with comprehensive insights and targeted practice questions.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(user_data):\n",
    "    USER_PROMPT = create_user_prompt(user_data)\n",
    "    return USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c6644",
   "metadata": {},
   "source": [
    "<h1>Get Response Format</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_format():\n",
    "    return {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"quiz_schema\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"parent_recommendations\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A comprehensive, personalized note for parents with specific recommendations for improvement, written in simple English that Indian parents can easily understand.\",\n",
    "                    },\n",
    "                    \"student_insights\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": \"Detailed analysis of student's academic performance across all subjects and tests.\",\n",
    "                        \"properties\": {\n",
    "                            \"overall_performance\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Overall assessment of student's academic performance across all subjects.\"\n",
    "                            },\n",
    "                            \"subject_wise_analysis\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Subject-wise detailed analysis based on test performance.\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"subject\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Name of the subject (e.g., Maths, English, Physics, etc.)\"\n",
    "                                        },\n",
    "                                        \"performance_trend\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Analysis of performance trend across multiple tests in this subject\"\n",
    "                                        },\n",
    "                                        \"strong_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student performed well (>75% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"weak_topics\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Topics where student needs improvement (<65% average)\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"improvement_recommendations\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"description\": \"Specific actionable recommendations for improvement in this subject\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"subject\", \"performance_trend\", \"strong_topics\", \"weak_topics\", \"improvement_recommendations\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            },\n",
    "                            \"priority_focus_areas\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"Top 3-5 priority areas that need immediate attention based on test performance\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"topic\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Name of the topic that needs focus\"\n",
    "                                        },\n",
    "                                        \"subject\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Subject this topic belongs to\"\n",
    "                                        },\n",
    "                                        \"current_performance\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Current performance level in this topic\"\n",
    "                                        },\n",
    "                                        \"why_priority\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Explanation of why this topic needs immediate attention\"\n",
    "                                        },\n",
    "                                        \"improvement_strategy\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Specific strategy to improve in this topic\"\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"topic\", \"subject\", \"current_performance\", \"why_priority\", \"improvement_strategy\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"overall_performance\", \"subject_wise_analysis\", \"priority_focus_areas\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"practice_questions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Practice questions organized by priority topics that need improvement\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"topic\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The topic for which these questions are generated\"\n",
    "                                },\n",
    "                                \"subject\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The subject this topic belongs to\"\n",
    "                                },\n",
    "                                \"questions\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"description\": \"Array of 6-8 practice questions for this topic\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"type\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"mcq\", \"descriptive\"],\n",
    "                                                \"description\": \"The type of the question.\"\n",
    "                                            },\n",
    "                                            \"questionId\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"Unique identifier for the question\"\n",
    "                                            },\n",
    "                                            \"question\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The question text. All math equations must be wrapped between $ and $.\"\n",
    "                                            },\n",
    "                                            \"subject\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The subject of the question.\"\n",
    "                                            },\n",
    "                                            \"chapter\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"description\": \"The chapter or topic this question belongs to.\"\n",
    "                                            },\n",
    "                                            \"marks\": {\n",
    "                                                \"type\": \"number\",\n",
    "                                                \"description\": \"The marks assigned for the question.\"\n",
    "                                            },\n",
    "                                            \"options\": {\n",
    "                                                \"anyOf\": [\n",
    "                                                    {\n",
    "                                                        \"type\": \"array\",\n",
    "                                                        \"description\": \"Options for multiple choice questions\",\n",
    "                                                        \"items\": {\n",
    "                                                            \"type\": \"object\",\n",
    "                                                            \"properties\": {\n",
    "                                                                \"key\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The key for the option (A, B, C, D)\"\n",
    "                                                                },\n",
    "                                                                \"option\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"The option text. Math equations wrapped in $ and $.\"\n",
    "                                                                },\n",
    "                                                                \"imageUrl\": {\n",
    "                                                                    \"type\": \"string\",\n",
    "                                                                    \"description\": \"Image URL if needed, empty string otherwise\"\n",
    "                                                                }\n",
    "                                                            },\n",
    "                                                            \"required\": [\"key\", \"option\", \"imageUrl\"],\n",
    "                                                            \"additionalProperties\": False\n",
    "                                                        }\n",
    "                                                    },\n",
    "                                                    {\n",
    "                                                        \"type\": \"null\",\n",
    "                                                        \"description\": \"Null for descriptive questions\"\n",
    "                                                    }\n",
    "                                                ]\n",
    "                                            },\n",
    "                                            \"difficulty\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [\"easy\", \"medium\", \"hard\"],\n",
    "                                                \"description\": \"The difficulty level of the question.\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"required\": [\"type\", \"questionId\", \"question\", \"subject\", \"chapter\", \"marks\", \"options\", \"difficulty\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"topic\", \"subject\", \"questions\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"parent_recommendations\", \"student_insights\", \"practice_questions\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17fd82",
   "metadata": {},
   "source": [
    "<h1>Initiate OpenAI Client </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client.api_key = \"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\"\n",
    "def get_questions_and_insights_for_individual_student(user_data):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "      model=\"o4-mini\",\n",
    "      messages=[\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": get_user_prompt(user_data)},\n",
    "      ],\n",
    "      response_format=get_response_format()\n",
    "    )\n",
    "    usage = completion.usage\n",
    "    completion_tokens = usage.completion_tokens\n",
    "    prompt_tokens     = usage.prompt_tokens\n",
    "    total_tokens      = usage.total_tokens\n",
    "    print_single_value_in_table(\"completion_tokens\",completion_tokens)\n",
    "    print_single_value_in_table(\"prompt tokens\", prompt_tokens)\n",
    "    print_single_value_in_table(\"total tokens\", total_tokens)\n",
    "    input_price = (prompt_tokens * 1.1)/1000000\n",
    "    output_price = (completion_tokens * 4.4)/1000000\n",
    "    final_cost = (input_price + output_price)*90\n",
    "    return [json.loads(completion.choices[0].message.content),str(round(final_cost, 2))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca81e03",
   "metadata": {},
   "source": [
    "<h1>Generate Report For Each Student (Class Comparison)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d417f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_individual_student_report(csv_path, student_name, output_folder):\n",
    "    # 1. Ensure output folder exists\n",
    "    \n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 2. Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 3. Define subjects (excluding non-subject columns)\n",
    "    subjects = [col for col in df.columns if col not in [\n",
    "        'Student Names', 'Attendance', \"Teacher's Remarks\"\n",
    "    ] and not col.endswith(' Topics')]\n",
    "\n",
    "    # 4. Replace 'AB' with NaN for calculations but keep original data for display\n",
    "    df_calc = df.copy()\n",
    "    for subj in subjects:\n",
    "        df_calc[subj] = pd.to_numeric(df_calc[subj], errors='coerce')  # Convert to numeric, 'AB' becomes NaN\n",
    "\n",
    "    # 5. Compute class stats (only using numeric values)\n",
    "    class_stats = {\n",
    "        subj: {\n",
    "            'highest':   df_calc[subj].max(),\n",
    "            'lowest':    df_calc[subj].min(),\n",
    "            'average':   df_calc[subj].mean()\n",
    "        }\n",
    "        for subj in subjects\n",
    "    }\n",
    "\n",
    "    # 6. Locate the student row\n",
    "    student_df = df[df['Student Names'] == student_name]\n",
    "    if student_df.empty:\n",
    "        raise ValueError(f\"Student '{student_name}' not found\")\n",
    "    student = student_df.iloc[0]\n",
    "    \n",
    "    # 7. Also create a numeric version of student data for calculations\n",
    "    student_calc = df_calc[df_calc['Student Names'] == student_name].iloc[0]\n",
    "    print(\"df calc>>>>>\",df_calc)\n",
    "    # 8. Generate the PDF\n",
    "    output_path = _generate_student_pdf(\n",
    "        student, student_calc, subjects, class_stats, output_folder,df_calc\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def _generate_student_pdf(student, student_calc, subjects, class_stats, output_folder, df_calc=None):\n",
    "    \"\"\"\n",
    "    Internal helper to build the PDF for one student with compact layout.\n",
    "    Handles 'AB' (absent) values in student data.\n",
    "    \n",
    "    Args:\n",
    "        student: Student's row from the original dataframe\n",
    "        student_calc: Student's row from the df_calc dataframe (with numeric values)\n",
    "        subjects: List of subject columns\n",
    "        class_stats: Dictionary with class statistics\n",
    "        output_folder: Where to save the PDF\n",
    "        df_calc: The full numeric dataframe for percentile calculations\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Use Times as it's closer to the \"math\" font in the template\n",
    "    pdf.set_font('Times', 'B', 14)\n",
    "\n",
    "    # Header - more compact\n",
    "    name = student['Student Names']\n",
    "    pdf.cell(0, 8, \"Student Performance Report\", ln=1, align='C')\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    print(subjects)\n",
    "    # Attendance with less spacing\n",
    "    att = student['Attendance']\n",
    "\n",
    "    att_pct = (int(att) / ATTENDANCE_DAYS) * 100 if pd.notna(att) else 0\n",
    "    pdf.cell(0, 6, f\"Attendance: {att} / {ATTENDANCE_DAYS} ({att_pct:.1f}%)\", ln=1, align='C')\n",
    "    \n",
    "    # Minimal spacing before chart\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # Comparison chart - increased height\n",
    "    chart_path = create_comparison_chart(student, student_calc, subjects, class_stats)\n",
    "    pdf.image(chart_path, x=20, w=170, h=75)  # Increased height from 60 to 75\n",
    "    os.remove(chart_path)\n",
    "    \n",
    "    # Compact spacing\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # SECTION: Subject Analysis with underlined header\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Subject Analysis\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Format subject analysis as a table to save space\n",
    "    col_width = 60\n",
    "    row_height = 6\n",
    "    \n",
    "    # Create columns for subjects - 3 per row\n",
    "    pct_map = {}\n",
    "    rows = (len(subjects) + 2) // 3  # Ceiling division\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(3):\n",
    "            idx = i * 3 + j\n",
    "            if idx < len(subjects):\n",
    "                subj = subjects[idx]\n",
    "                raw = student[subj]\n",
    "                # Check if student was absent\n",
    "                if raw == 'AB' or raw == '🆎' or raw == '' or pd.isna(raw):\n",
    "                    # Display \"Absent\" instead of percentage\n",
    "                    display_text = f\"{subj}: Absent\"\n",
    "                    # We don't add to pct_map when absent\n",
    "                else:\n",
    "                    # Normal case with score\n",
    "                    raw_num = float(raw)\n",
    "                    pct = (raw_num / 30) * 100\n",
    "                    pct_map[subj] = pct\n",
    "                    display_text = f\"{subj}: {raw}/30 ({pct:.1f}%)\"\n",
    "                \n",
    "                pdf.cell(col_width, row_height, \n",
    "                      display_text, \n",
    "                      ln=0 if j < 2 and (i*3+j+1) < len(subjects) else 1)\n",
    "    print(pct_map,\"pct\")\n",
    "    # SECTION: Performance Highlights\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Performance Highlights\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Only show highlights if student has taken at least one test\n",
    "    if pct_map:\n",
    "        # Calculate 80th percentile for each subject that the student has taken\n",
    "        subject_percentiles = {}\n",
    "        needs_improvement_subjects = []\n",
    "        # Only proceed if df_calc is provided\n",
    "        if df_calc is not None:\n",
    "            for subj in pct_map:\n",
    "\n",
    "                # Get all non-NaN scores for this subject to calculate percentile\n",
    "                all_scores = df_calc[subj].dropna()\n",
    "                \n",
    "                if not all_scores.empty:\n",
    "                    # Calculate 80th percentile\n",
    "                    percentile_80 = np.percentile(all_scores, 80)\n",
    "                    subject_percentiles[subj] = percentile_80\n",
    "                    # Check if student score is less than 75% or below 80th percentile\n",
    "                    if pct_map[subj] < 75 or student_calc[subj] < percentile_80:\n",
    "                        needs_improvement_subjects.append((subj, pct_map[subj]))\n",
    "        \n",
    "        # Find strongest subject (highest percentage)\n",
    "        best_subj = max(pct_map, key=pct_map.get)\n",
    "        best_pct = pct_map[best_subj]\n",
    "        \n",
    "        # Display strongest subject\n",
    "        pdf.cell(95, 6, f\"Strongest Subject: {best_subj} ({best_pct:.1f}%)\", ln=0)\n",
    "        \n",
    "        # Display subject that needs improvement (if any)\n",
    "        \n",
    "        if needs_improvement_subjects:\n",
    "            # Sort by percentage ascending (lowest first)\n",
    "            needs_improvement_subjects.sort(key=lambda x: x[1])\n",
    "            pdf.cell(0, 6, \"Subjects Needing Improvement:\", ln=1)\n",
    "            for subj, pct in needs_improvement_subjects:\n",
    "                pdf.cell(0, 6, f\"- {subj} ({pct:.1f}%)\", ln=1)\n",
    "        else:\n",
    "            pdf.cell(95, 6, \"All subjects meet expectations\", ln=1)\n",
    "    else:\n",
    "        pdf.cell(0, 6, \"No test scores available for performance analysis\", ln=1)\n",
    "\n",
    "    # SECTION: Teacher's Remarks\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Teacher's Remarks\", ln=1)\n",
    "    \n",
    "    # Check if there are any teacher's remarks\n",
    "    has_remarks = pd.notna(student[\"Teacher's Remarks\"]) and student[\"Teacher's Remarks\"].strip() != \"\"\n",
    "    \n",
    "    # Only draw the line if there are remarks\n",
    "    if has_remarks:\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(1)\n",
    "        pdf.set_font('Times', '', 10)\n",
    "        # Use multi_cell with smaller height to make text more compact\n",
    "        pdf.multi_cell(0, 5, student[\"Teacher's Remarks\"])\n",
    "    else:\n",
    "        # No remarks - display message\n",
    "        pdf.ln(1)\n",
    "        pdf.set_font('Times', '', 10)\n",
    "        pdf.cell(0, 5, \"No remarks from teacher\", ln=1)\n",
    "\n",
    "    # SECTION: Topics Covered - only if we have space\n",
    "    remaining_height = 270 - pdf.get_y()  # Approx A4 usable height\n",
    "    \n",
    "    if remaining_height > 20:  # Only show if we have room\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Topics Covered\", ln=1)\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(1)\n",
    "        \n",
    "        pdf.set_font('Times', '', 10)\n",
    "        for subj in subjects:\n",
    "            tcol = f\"{subj} Topics\"\n",
    "            if tcol in student.index and pd.notna(student[tcol]):\n",
    "                # Limited space, so keep it brief\n",
    "                if(subj ==\"Maths\"):\n",
    "                    topic_text = f\"{subj}: {student[tcol]}\"\n",
    "                elif(subj == \"Biology\"):\n",
    "                    topic_text = f\"{subj}: {student[tcol]} , Human reproduction\"\n",
    "                else:\n",
    "                    topic_text = f\"{subj}: {student[tcol]}\"\n",
    "                if len(topic_text) > 100:\n",
    "                    topic_text = topic_text[:97] + \"...\"\n",
    "                pdf.multi_cell(0, 5, topic_text)\n",
    "\n",
    "    # Save\n",
    "    safe_name = name.replace(' ', '_')\n",
    "    path = os.path.join(output_folder, f\"{safe_name}_report.pdf\")\n",
    "    pdf.output(path)\n",
    "    return path\n",
    "\n",
    "def create_comparison_chart(student, student_calc, subjects, class_stats):\n",
    "    \"\"\"\n",
    "    Build and save a matplotlib chart comparing this student\n",
    "    against class high/low/average in each subject, with a \n",
    "    parent-friendly, aesthetic design.\n",
    "    \n",
    "    Uses Times font to match the rest of the report.\n",
    "    Handles 'AB' (absent) values in student data.\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    import matplotlib.font_manager as fm\n",
    "    \n",
    "    # Set Times font family explicitly - this ensures consistency with the PDF\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    # For systems that might not have Times New Roman, fall back to serif\n",
    "    matplotlib.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif', 'serif']\n",
    "    \n",
    "    # Data preparation - check for absent tests\n",
    "    marks = []\n",
    "    percentages = []\n",
    "    absent_subjects = []\n",
    "    \n",
    "    for s in subjects:\n",
    "        if student[s] == 'AB':\n",
    "            # Track which subjects student was absent for\n",
    "            marks.append(0)  # Use 0 for absent in chart\n",
    "            percentages.append(None)  # No percentage for absent\n",
    "            absent_subjects.append(s)\n",
    "        else:\n",
    "            # Normal case with score\n",
    "            marks.append(student_calc[s])\n",
    "            percentages.append((student_calc[s]/30)*100 if pd.notna(student_calc[s]) else None)\n",
    "    \n",
    "    highest  = [class_stats[s]['highest'] for s in subjects]\n",
    "    lowest   = [class_stats[s]['lowest'] for s in subjects]\n",
    "    average  = [class_stats[s]['average'] for s in subjects]\n",
    "    \n",
    "    # Set a modern, professional color palette\n",
    "    student_color = '#4570B7'  # Vibrant blue for student\n",
    "    avg_color = '#9FA7B2'      # Muted gray for average\n",
    "    high_color = '#97D077'     # Soft green for highest\n",
    "    low_color = '#F08B7E'      # Soft red for lowest\n",
    "    absent_color = '#E8E8E8'   # Light gray for absent\n",
    "    \n",
    "    # Create figure with increased height \n",
    "    plt.figure(figsize=(7.5, 5.0))  # Increased height from 4.5 to 5.0\n",
    "    \n",
    "    # Define positions and width\n",
    "    x = np.arange(len(subjects))\n",
    "    width = 0.18  # Slightly thinner bars with more spacing\n",
    "    \n",
    "    # Plot bars with softer colors and borders\n",
    "    avg_bars = plt.bar(x, average, width, color=avg_color, edgecolor='white', \n",
    "                    linewidth=0.5, label='Class Average', zorder=1)\n",
    "    high_bars = plt.bar(x + width, highest, width, color=high_color, edgecolor='white',\n",
    "                     linewidth=0.5, label='Class Highest', zorder=1)\n",
    "    low_bars = plt.bar(x - width, lowest, width, color=low_color, edgecolor='white',\n",
    "                    linewidth=0.5, label='Class Lowest', zorder=1)\n",
    "    \n",
    "    # Make student bars stand out more\n",
    "    student_bars = plt.bar(x + 2*width, marks, width, \n",
    "                          color=[absent_color if s in absent_subjects else student_color for s in subjects], \n",
    "                          edgecolor='white', linewidth=1.0, \n",
    "                          label=f\"{student['Student Names']}\", zorder=2)\n",
    "    \n",
    "    # Add student score percentages above their bars (except for absent)\n",
    "    for i, (p, m, s) in enumerate(zip(percentages, marks, subjects)):\n",
    "        if s in absent_subjects:\n",
    "            plt.annotate(\"Absent\", \n",
    "                       xy=(x[i] + 2*width, 2),  # Position just above the x-axis\n",
    "                       ha='center', va='bottom',\n",
    "                       fontsize=8, fontweight='normal', color='#000',\n",
    "                       family='Times New Roman')  # Explicitly set font family\n",
    "        elif p is not None:\n",
    "            plt.annotate(f\"{int(p)}%\", \n",
    "                       xy=(x[i] + 2*width, m + 0.5), \n",
    "                       ha='center', va='bottom',\n",
    "                       fontsize=9, fontweight='normal', color=student_color,\n",
    "                       family='Times New Roman')  # Explicitly set font family\n",
    "    \n",
    "    # Set axis labels with consistent Times font\n",
    "    plt.xlabel('Subjects', fontsize=10, fontweight='normal', family='Times New Roman')\n",
    "    plt.ylabel('Marks (out of 30)', fontsize=10, fontweight='normal', family='Times New Roman')\n",
    "    \n",
    "    # Set title and add subtitle as a single title with newline for better spacing\n",
    "    plt.suptitle(f\"{student['Student Names']}'s Performance\", \n",
    "            fontsize=12, fontweight='normal', family='Times New Roman', y=0.98)\n",
    "    \n",
    "    # Add explanatory subtitle closer to title\n",
    "    plt.title(\"This chart compares the student's performance with the class statistics\", \n",
    "            fontsize=10, fontstyle='normal', family='Times New Roman', pad=10)\n",
    "    \n",
    "    # Improve x-axis readability with Times font\n",
    "    plt.xticks(x + width/2, subjects, fontsize=10, fontweight='normal', family='Times New Roman')\n",
    "    \n",
    "    # Set y-axis to have a max of 30 (full marks) with Times font\n",
    "    plt.ylim(0, 32)  # Slight buffer for annotations\n",
    "    plt.yticks(range(0, 31, 5), fontsize=10, family='Times New Roman')\n",
    "    \n",
    "    # Add a horizontal line at maximum possible marks\n",
    "    plt.axhline(y=30, color='#CCCCCC', linestyle='-', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    # Add \"Full Marks (30)\" text with Times font\n",
    "    plt.text(len(subjects) - 0.2, 30.5, 'Full Marks (30)', \n",
    "           ha='right', va='bottom', fontsize=8, color='black', family='Times New Roman')\n",
    "    \n",
    "    # Add subtle grid for readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.2, zorder=0)\n",
    "    \n",
    "    # Create custom legend with more descriptive labels\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=student_color, edgecolor='white', label=f\"{student['Student Names']}\"),\n",
    "        Patch(facecolor=avg_color, edgecolor='white', label='Class Average'),\n",
    "        Patch(facecolor=high_color, edgecolor='white', label='Class Highest'),\n",
    "        Patch(facecolor=low_color, edgecolor='white', label='Class Lowest')\n",
    "    ]\n",
    "    \n",
    "    # Add \"Absent\" to legend if student has any absent marks\n",
    "    if absent_subjects:\n",
    "        legend_elements.append(\n",
    "            Patch(facecolor=absent_color, edgecolor='white', label='Absent')\n",
    "        )\n",
    "    \n",
    "    # Move legend outside the plot area with Times font\n",
    "    plt.legend(handles=legend_elements, \n",
    "             loc='upper center', \n",
    "             bbox_to_anchor=(0.5, -0.12),  # Position below the plot - adjusted for larger chart\n",
    "             fontsize=9, \n",
    "             framealpha=0.7, \n",
    "             edgecolor='#CCCCCC',\n",
    "             ncol=min(5, len(legend_elements)),\n",
    "             prop={'family': 'Times New Roman'})  # Set font family for legend\n",
    "    \n",
    "    # Remove top and right spines for cleaner look\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    \n",
    "    # Apply Times New Roman to tick labels\n",
    "    for label in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "        label.set_fontname('Times New Roman')\n",
    "    \n",
    "    # Clean background and tight layout with adjusted rect to make room for legend\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.97])  # Adjusted bottom margin for legend\n",
    "    \n",
    "    # Save with clean white background\n",
    "    fname = f\"temp_chart_{student['Student Names'].replace(' ','_')}.png\"\n",
    "    plt.savefig(fname, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    return fname\n",
    "# generate_individual_student_report('./4/student_data_final.csv', 'Anusha',f\"./14/reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51fc68",
   "metadata": {},
   "source": [
    "<h1>Convert worksheet html to pdf </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf415a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_latex_to_mathml(html_content):\n",
    "    \"\"\"\n",
    "    Convert LaTeX equations enclosed in $ signs to MathML format.\n",
    "    \n",
    "    Args:\n",
    "        html_content (str): HTML content with LaTeX equations\n",
    "        \n",
    "    Returns:\n",
    "        str: HTML content with LaTeX equations replaced by MathML\n",
    "    \"\"\"\n",
    "    # Regular expression to find LaTeX expressions enclosed in $ signs\n",
    "    # This handles both inline math ($...$) and display math ($$...$$)\n",
    "    pattern = r'\\$\\$(.*?)\\$\\$|\\$(.*?)\\$'\n",
    "    \n",
    "    def replace_math(match):\n",
    "        if match.group(1) is not None:  # Display math ($$...$$)\n",
    "            latex_expr = match.group(1)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='block')\n",
    "            return mathml\n",
    "        else:  # Inline math ($...$)\n",
    "            latex_expr = match.group(2)\n",
    "            mathml = latex2mathml.converter.convert(latex_expr, display='inline')\n",
    "            return mathml\n",
    "    \n",
    "    # Replace all matches with MathML\n",
    "    return re.sub(pattern, replace_math, html_content)\n",
    "\n",
    "def download_html_to_pdf(s3_url, output_pdf_path):\n",
    "    \"\"\"\n",
    "    Makes an API call to a local server that converts HTML from an S3 URL to PDF\n",
    "    \n",
    "    Args:\n",
    "        s3_url (str): The S3 URL of the HTML file to convert\n",
    "        output_pdf_path (str): Local file path where to save the PDF\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response containing success status and path if successful\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_pdf_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # First, fetch the HTML content to process LaTeX equations\n",
    "    try:\n",
    "        html_response = requests.get(s3_url)\n",
    "        html_response.raise_for_status()\n",
    "        \n",
    "        # Convert LaTeX to MathML\n",
    "        html_content = html_response.text\n",
    "        \n",
    "        # Now we can either:\n",
    "        # 1. Upload the modified HTML somewhere and pass that URL to the API\n",
    "        # 2. Or modify the API to accept HTML content directly\n",
    "        \n",
    "        # For now, we'll continue with the original approach using the S3 URL\n",
    "        # but in a real implementation, you might want to handle the modified HTML\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        err_box_red(\"Failed to fetch HTML from S3\",str(e))\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    # Prepare the API request data\n",
    "    api_url = DOWNLOAD_FROM_S3_LINK\n",
    "    payload = {\n",
    "        \"s3Link\": s3_url,  # Using original S3 URL\n",
    "        \"pathToSave\": output_pdf_path,\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        # Parse the response\n",
    "        result = response.json()\n",
    "        \n",
    "        if result.get('success', False):\n",
    "            print_single_value_in_table(\"PDF successfully saved to\",{result.get('savedPath', output_pdf_path)})\n",
    "        else:\n",
    "            err_box_red(\"PDF generation failed\",str(e))\n",
    "        return result['path']\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        err_box_red(\"PDF generation failed\",str(e))\n",
    "        return {\"success\": False, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f736e",
   "metadata": {},
   "source": [
    "<h1>Save Student Record in Database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16531eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_student_record(student_name, standard,worksheet_s3_link,cost,school_name='Surya International School'):\n",
    "    \"\"\"\n",
    "    Sends a POST to your Express endpoint to save a new student record.\n",
    "\n",
    "    Args:\n",
    "        student_name (str): Name of the student.\n",
    "        school_name (str): Name of the student's school.\n",
    "        standard (str): Grade or standard of the student.\n",
    "        worksheet_s3_link (str): URL to the student’s worksheet HTML in S3.\n",
    "        cost (int): Associated cost.\n",
    "        base_url (str): Base URL of your server (no trailing slash).\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed JSON response from the server, or None on error.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"studentName\": student_name,\n",
    "        \"schoolName\": school_name,\n",
    "        \"standard\": standard,\n",
    "        \"worksheet_s3_link\": worksheet_s3_link,\n",
    "        \"cost\": cost,\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(SAVE_STUDENT_COST_PER_WORKSHEET, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        err_box_red(\"[ERROR] Failed to save student record:\", err)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda05513",
   "metadata": {},
   "source": [
    "<h1>Generate worksheet and combine worksheet and report</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_worksheet_for_students_and_combine_report(data):\n",
    "    TOTAL_COST = 0\n",
    "    output_paths = []\n",
    "    for student in data:\n",
    "        print_single_value_in_table(\"Student Being Processed\",student['name'])\n",
    "        student_name = student['name']\n",
    "        [questions_and_insights_for_student,cost] = get_questions_and_insights_for_individual_student(student)\n",
    "        worksheet = requests.request(\n",
    "        method='POST',\n",
    "        url=GET_WORKSHEET_HTML,\n",
    "        json={'student_data':questions_and_insights_for_student}\n",
    "        )\n",
    "        worksheet.raise_for_status()\n",
    "        student_specific_questions_and_insights = worksheet.json()\n",
    "        student_worksheet_link = student_specific_questions_and_insights['worksheet_html']\n",
    "        \n",
    "        student_worksheet_pdf = download_html_to_pdf(student_worksheet_link,f\"../analysis_insights_copy/{STANDARD}/worksheets/{student_name}.pdf\")\n",
    "        print_single_value_in_table(\"student_worksheet_link\",student_worksheet_link)\n",
    "        print_single_value_in_table(\"student_worksheet_pdf_cost\",student_worksheet_pdf)\n",
    "        print_single_value_in_table(\"cost\",cost)\n",
    "        TOTAL_COST += float(cost)\n",
    "        student_comparison_report_pdf = generate_individual_student_report(FILE_DEST,student_name,f\"./{STANDARD}/reports/\")\n",
    "        full_output_path = combine_pdfs(student_comparison_report_pdf,student_worksheet_pdf,f\"./{STANDARD}/final_reports\",f\"{student_name}_insights.pdf\")\n",
    "        save_student_record(student_name,standard=STANDARD,cost=cost,worksheet_s3_link=student_worksheet_link)\n",
    "        output_paths.append(full_output_path)\n",
    "    print_single_value_in_table(\"Total Cost\",TOTAL_COST)\n",
    "    return output_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f97a17",
   "metadata": {},
   "source": [
    "<h1>Merge Pdfs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pdfs(pdf_path1, pdf_path2, output_folder, output_filename):\n",
    "    \"\"\"\n",
    "    Combine two PDFs into a single PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path1 (str): Path to the first PDF file\n",
    "        pdf_path2 (str): Path to the second PDF file\n",
    "        output_folder (str): Folder where the combined PDF will be saved\n",
    "        output_filename (str): Filename for the combined PDF\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the combined PDF file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a PDF merger object\n",
    "        merger = PdfMerger()\n",
    "        \n",
    "        # Append the PDFs to the merger\n",
    "        merger.append(pdf_path1)\n",
    "        merger.append(pdf_path2)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        full_output_path = os.path.join(output_folder, output_filename)        \n",
    "        # Write the combined PDF to the output path\n",
    "        merger.write(full_output_path)\n",
    "        merger.close()\n",
    "        print_single_value_in_table(\"Successfully combined PDFs and saved to\",full_output_path)\n",
    "        return full_output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        err_box_red(\"Error combining pdfs\",e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_topics_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = read_data(FILE_DESTINATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_validated = validate_data(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_students_data = classify_students_by_topic(student_data_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_topics_asked_in_examination = fetch_questions_for_topics(GET_QUESTIONS_FOR_TOPICS, AUTH_TOKEN,CHAPTERS)\n",
    "print_question_data(questions_for_topics_asked_in_examination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_worksheet_for_students_and_combine_report(classified_students_data)\n",
    "print_single_value_in_table(\"Total cost\",TOTAL_COST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
