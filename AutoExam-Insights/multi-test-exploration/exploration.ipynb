{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30294341",
   "metadata": {},
   "source": [
    "<h1>Import Libs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f591104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdb1bf",
   "metadata": {},
   "source": [
    "<h1>Constants</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_ORIGIN = \"./student_data.csv\"\n",
    "FILE_DESTINATION = \"./student_data_final.csv\"\n",
    "TESTS_AND_CHAPTERS_FOR_SUBJECTS =  [\n",
    "        (\"Test1\", [\"English\", \"Maths\"], [\"A,B\", \"C,D\"]),\n",
    "        (\"Test2\", [\"English\", \"Maths\"], [\"B,C\", \"D,F\"])\n",
    "    ]\n",
    "ATTENDANCE_DAYS_TOTAL = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee38fe",
   "metadata": {},
   "source": [
    "<h1> Read Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.csv':\n",
    "        student_data = pd.read_csv(file_path)\n",
    "        return student_data\n",
    "    elif ext in ('.xls', '.xlsx'):\n",
    "        student_data = pd.read_excel(file_path, sheet_name=None)\n",
    "        return student_data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052edb",
   "metadata": {},
   "source": [
    "<h1>Add topics to csv Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def add_topics_to_csv():\n",
    "    \"\"\"\n",
    "    - input_csv_path, output_csv_path: file paths.\n",
    "    - tests: a list of (test_name, subjects, topic_values), e.g.:\n",
    "        [\n",
    "          (\"Test1\", [\"English\",\"Maths\"], [\"A,B\",\"C,D\"]),\n",
    "          (\"Test2\", [\"English\",\"Maths\"], [\"B,C\",\"E,F\"])\n",
    "        ]\n",
    "    \n",
    "    This will add columns:\n",
    "      English Topics Test1, Maths Topics Test1,\n",
    "      English Topics Test2, Maths Topics Test2,\n",
    "      English All Topics,  Maths All Topics\n",
    "    \"\"\"\n",
    "    # 1) Validate\n",
    "    for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        if len(subjects) != len(chapters):\n",
    "            raise ValueError(f\"subjects vs topic_values length mismatch in {test_name}\")\n",
    "\n",
    "    # 2) Collect all unique subjects and append it to all_subjects\n",
    "    all_subjects: List[str] = []\n",
    "    for _, subjects, _ in TESTS_AND_CHAPTERS_FOR_SUBJECTS:\n",
    "        for subj in subjects:\n",
    "            if subj not in all_subjects:\n",
    "                all_subjects.append(subj)\n",
    "\n",
    "    # 3) Build per-test lookup maps\n",
    "    test_topic_maps: Dict[str, Dict[str, str]] = {\n",
    "        test_name: dict(zip(subjects, chapters))\n",
    "        for test_name, subjects, chapters in TESTS_AND_CHAPTERS_FOR_SUBJECTS\n",
    "    }\n",
    "\n",
    "    # 4) Open I/O\n",
    "    with open(FILE_ORIGIN, newline=\"\", encoding=\"utf-8\") as fin, \\\n",
    "         open(FILE_DESTINATION, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        # a) build the new header\n",
    "        extra_cols: List[str] = []\n",
    "        for test_name in test_topic_maps:\n",
    "            for subj in all_subjects:\n",
    "                if subj in test_topic_maps[test_name]:\n",
    "                    extra_cols.append(f\"{subj} Topics {test_name}\")\n",
    "        for subj in all_subjects:\n",
    "            extra_cols.append(f\"{subj} All Topics\")\n",
    "\n",
    "        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames + extra_cols)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 5) Process each row\n",
    "        for row in reader:\n",
    "            # per-test columns\n",
    "            for test_name, topics_map in test_topic_maps.items():\n",
    "                for subj, topics_str in topics_map.items():\n",
    "                    row[f\"{subj} Topics {test_name}\"] = topics_str\n",
    "\n",
    "            # aggregated union columns\n",
    "            for subj in all_subjects:\n",
    "                all_toks: List[str] = []\n",
    "                for topics_map in test_topic_maps.values():\n",
    "                    if subj in topics_map:\n",
    "                        # split on comma, strip whitespace\n",
    "                        all_toks.extend([tok.strip() for tok in topics_map[subj].split(\",\")])\n",
    "                # dedupe & sort (optional)\n",
    "                unique = sorted(set(tok for tok in all_toks if tok))\n",
    "                row[f\"{subj} All Topics\"] = \", \".join(unique)\n",
    "\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc8db",
   "metadata": {},
   "source": [
    "<h1>Validate Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data(df: pd.DataFrame, test_mark_cols=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and validates a student score DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    - Strips whitespace from all string columns\n",
    "    - Normalizes topic strings like \"A,B\" to \"A, B\"\n",
    "    - Detects missing names or marks\n",
    "    - Standardizes absent marks as 'AB'\n",
    "    - Converts valid marks to int/float\n",
    "    - Fills missing attendance with 0\n",
    "    - Prints a summary of absentees and preview of data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input student data.\n",
    "        test_mark_cols (list[str], optional): List of test score columns to validate. If None, inferred.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and validated dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "\n",
    "    # 0. Remove leading/trailing spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # 1. Normalize topic columns â€” ensure \"A, B, C\" format\n",
    "    topic_cols = [c for c in df.columns if re.search(r'topics', c, re.IGNORECASE)]\n",
    "    for col in topic_cols:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: ', '.join(p.strip() for p in x.split(',')) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    # 2. Check for missing student names and report\n",
    "    if df['Student Names'].isna().any():\n",
    "        missing = df[df['Student Names'].isna()].index.tolist()\n",
    "        print(f\"Missing Student Names in rows: {missing}\")\n",
    "\n",
    "    # 3. Identify test mark columns: use passed ones or detect those matching '<Subject>_Test<N>'\n",
    "    if test_mark_cols is None:\n",
    "        test_mark_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "\n",
    "    # Ensure the specified test mark columns exist in DataFrame\n",
    "    missing_marks = [c for c in test_mark_cols if c not in df.columns]\n",
    "    if missing_marks:\n",
    "        raise KeyError(f\"Expected mark columns not found: {missing_marks}\")\n",
    "\n",
    "    # 4. Validate each test mark column\n",
    "    for col in test_mark_cols:\n",
    "        # a) Treat empty or NaN cells as 'AB' (Absent)\n",
    "        empty_mask = df[col].isna() | (df[col] == '')\n",
    "        if empty_mask.any():\n",
    "            for idx in df[empty_mask].index:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Missing {col} for {name}; marking as absent ('AB')\")\n",
    "            df.loc[empty_mask, col] = 'AB'\n",
    "\n",
    "        # b) Standardize all 'ab', 'Ab', etc. to uppercase 'AB'\n",
    "        is_ab = df[col].astype(str).str.upper().str.strip() == 'AB'\n",
    "        df.loc[is_ab, col] = 'AB'\n",
    "\n",
    "        # c) Try to convert other values to numbers, else mark as 'AB'\n",
    "        for idx in df.index:\n",
    "            if df.at[idx, col] == 'AB':\n",
    "                continue  # Skip if already marked absent\n",
    "            val = df.at[idx, col]\n",
    "            try:\n",
    "                num = float(val)\n",
    "                df.at[idx, col] = int(num) if num.is_integer() else num\n",
    "            except Exception:\n",
    "                name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "                print(f\"Invalid {col} value '{val}' for {name}; marking as absent\")\n",
    "                df.at[idx, col] = 'AB'\n",
    "\n",
    "    # 5. Handle Attendance column\n",
    "    if 'Attendance' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'Attendance' not found\")\n",
    "\n",
    "    # Fill missing attendance with 0\n",
    "    if df['Attendance'].isna().any():\n",
    "        for idx in df[df['Attendance'].isna()].index:\n",
    "            name = df.at[idx, 'Student Names'] or '<Unknown>'\n",
    "            print(f\"Attendance missing for {name}; setting to 0\")\n",
    "        df['Attendance'] = df['Attendance'].fillna(0)\n",
    "\n",
    "    # Ensure attendance is numeric integers\n",
    "    df['Attendance'] = pd.to_numeric(df['Attendance'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 6. Summary statistics\n",
    "    print(f\"\\nNumber of students loaded: {len(df)}\")\n",
    "    absent_summary = {\n",
    "        col: (df[col] == 'AB').sum() for col in test_mark_cols if (df[col] == 'AB').any()\n",
    "    }\n",
    "    if absent_summary:\n",
    "        print(\"\\nStudents marked as absent:\")\n",
    "        for col, count in absent_summary.items():\n",
    "            print(f\"  {col}: {count}\")\n",
    "\n",
    "    # 7. Print first 5 rows for review\n",
    "    print(df.head(5).to_string(index=False))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca7c9",
   "metadata": {},
   "source": [
    "<h1>Classify Students Strong and Weak Topics </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b57e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_students_by_topic(\n",
    "    df: pd.DataFrame,\n",
    "    max_score: float = 100.0,\n",
    "    strong_thresh: float = 85.0,\n",
    "    weak_thresh: float = 70.0\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Classify students into strong/weak/practice *topics* based on multiple tests.\n",
    "\n",
    "    Logic & reasoning:\n",
    "      1. We may have multiple tests per subject, each covering overlapping topics.\n",
    "      2. For each student-topic pair, we collect all test percentages in which that topic appeared.\n",
    "      3. We compute the *average percentage* for that topic.\n",
    "      4. We apply *fixed thresholds* (85% for strong, 70% for weak) rather than class-level percentilesâ€”\n",
    "         because topic-level data can be sparse and unevenly distributed.\n",
    "      5. Topics â‰¥ strong_thresh â†’ strong; â‰¤ weak_thresh â†’ weak; otherwise â†’ practice.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame containing:\n",
    "            - \"Student Names\", one or more \"<Subject>_Test<N>\" columns,\n",
    "            - corresponding \"<Subject> Topics Test<N>\" columns,\n",
    "            - \"Attendance\" and \"Teacher's Remarks\".\n",
    "        max_score: Maximum possible raw score per test.\n",
    "        strong_thresh: Percentage threshold above which a topic is 'strong'.\n",
    "        weak_thresh: Percentage threshold below which a topic is 'weak'.\n",
    "\n",
    "    Returns:\n",
    "        A list of per-student dicts with keys:\n",
    "          - name, attendance, remarks\n",
    "          - strong_topics, weak_topics, practice_topics\n",
    "          - topic_details: list of { topic, avg_pct, count_of_tests }\n",
    "          - test_details: list of { test_col, subject, raw, pct, topics }\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1) Identify all test-score columns, e.g. 'English_Test1', 'Maths_Test2', etc.\n",
    "    test_cols = [c for c in df.columns if re.match(r'.+_Test\\d+', c)]\n",
    "    # 2) Identify all topic columns for tests: '<Subject> Topics Test<N>'\n",
    "    topic_cols = [c for c in df.columns if re.match(r'.+ Topics Test\\d+', c)]\n",
    "\n",
    "    # Build a mapping from each test column to its topic-column name\n",
    "    # e.g. { 'English_Test1': 'English Topics Test1', ... }\n",
    "    test_to_topics = {}\n",
    "    for tc in test_cols:\n",
    "        subj, num = tc.rsplit('_Test', 1)\n",
    "        tcol = f\"{subj} Topics Test{num}\"\n",
    "        if tcol in df.columns:\n",
    "            test_to_topics[tc] = tcol\n",
    "        else:\n",
    "            raise KeyError(f\"Missing topics column for {tc}: expected '{tcol}'\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        name       = row['Student Names']\n",
    "        attendance = row.get('Attendance')\n",
    "        remarks    = row.get(\"Teacher's Remarks\", \"\")\n",
    "\n",
    "        # Will collect raw details for debugging/reporting\n",
    "        test_details  = []\n",
    "        # topic_scores accumulates all pct values per topic\n",
    "        topic_scores  = {}\n",
    "\n",
    "        # 3) Loop through each test, parse marks and topics\n",
    "        for tc, tcol in test_to_topics.items():\n",
    "            raw = row[tc]\n",
    "            # a) Handle absent\n",
    "            if isinstance(raw, str) and raw.strip().upper() == 'AB':\n",
    "                pct = np.nan\n",
    "            else:\n",
    "                raw_num = pd.to_numeric(raw, errors='coerce')\n",
    "                pct     = (raw_num * 100.0 / max_score) if pd.notna(raw_num) else np.nan\n",
    "\n",
    "            # b) Parse topics list for this test\n",
    "            topics = []\n",
    "            tstr = row.get(tcol, \"\")\n",
    "            if isinstance(tstr, str) and tstr.strip():\n",
    "                topics = [t.strip() for t in tstr.split(',')]\n",
    "\n",
    "            # c) Record test detail\n",
    "            #    (helps trace exactly which tests contributed to each topic)\n",
    "            test_details.append({\n",
    "                'test_col': tc,\n",
    "                'subject':  tc.split('_Test')[0],\n",
    "                'raw':      raw,\n",
    "                'pct':      pct,\n",
    "                'topics':   topics\n",
    "            })\n",
    "\n",
    "            # d) Append pct to each topic's list\n",
    "            for topic in topics:\n",
    "                topic_scores.setdefault(topic, []).append(pct)\n",
    "\n",
    "        # 4) Compute average pct per topic & classify\n",
    "        strong_topics  = []\n",
    "        weak_topics    = []\n",
    "        practice_topics = []\n",
    "        topic_details   = []\n",
    "\n",
    "        for topic, pcts in topic_scores.items():\n",
    "            # ignore NaNs when averaging\n",
    "            valid = [p for p in pcts if pd.notna(p)]\n",
    "            avg_pct = float(np.nan) if not valid else sum(valid) / len(valid)\n",
    "\n",
    "            # classify based on fixed thresholds\n",
    "            if pd.notna(avg_pct):\n",
    "                if avg_pct >= strong_thresh:\n",
    "                    strong_topics.append(topic)\n",
    "                elif avg_pct <= weak_thresh:\n",
    "                    weak_topics.append(topic)\n",
    "                else:\n",
    "                    practice_topics.append(topic)\n",
    "\n",
    "            topic_details.append({\n",
    "                'topic':     topic,\n",
    "                'avg_pct':   avg_pct,\n",
    "                'num_tests': len(valid)\n",
    "            })\n",
    "\n",
    "        # 5) Assemble result for this student\n",
    "        results.append({\n",
    "            'name':             name,\n",
    "            'attendance':       attendance,\n",
    "            'remarks':          remarks,\n",
    "            'strong_topics':    strong_topics,\n",
    "            'weak_topics':      weak_topics,\n",
    "            'practice_topics':  practice_topics,\n",
    "            'topic_details':    topic_details,\n",
    "            'test_details':     test_details\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb92614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_topics_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e4e7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = read_data(FILE_DESTINATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc7c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of students loaded: 3\n",
      "Student Names English_Test1 English_Test2 Maths_Test1 Maths_Test2  Attendance English Topics Test1 Maths Topics Test1 English Topics Test2 Maths Topics Test2 English All Topics Maths All Topics\n",
      "        Alice            85            88          90          92          12                 A, B               C, D                 B, C               D, F            A, B, C          C, D, F\n",
      "          Bob            78            82          88          85          23                 A, B               C, D                 B, C               D, F            A, B, C          C, D, F\n",
      "      Charlie            92            94          76          78          24                 A, B               C, D                 B, C               D, F            A, B, C          C, D, F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/s_j8qb1j57j04085mgyyjx1h0000gn/T/ipykernel_32456/2057577662.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'AB' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[is_ab, col] = 'AB'\n",
      "/var/folders/sg/s_j8qb1j57j04085mgyyjx1h0000gn/T/ipykernel_32456/2057577662.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'AB' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[is_ab, col] = 'AB'\n",
      "/var/folders/sg/s_j8qb1j57j04085mgyyjx1h0000gn/T/ipykernel_32456/2057577662.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'AB' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[is_ab, col] = 'AB'\n",
      "/var/folders/sg/s_j8qb1j57j04085mgyyjx1h0000gn/T/ipykernel_32456/2057577662.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'AB' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[is_ab, col] = 'AB'\n"
     ]
    }
   ],
   "source": [
    "student_data_validated = validate_data(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'attendance': 12, 'remarks': '', 'strong_topics': ['A', 'B', 'C', 'D', 'F'], 'weak_topics': [], 'practice_topics': [], 'topic_details': [{'topic': 'A', 'avg_pct': 85.0, 'num_tests': 1}, {'topic': 'B', 'avg_pct': 86.5, 'num_tests': 2}, {'topic': 'C', 'avg_pct': 89.0, 'num_tests': 2}, {'topic': 'D', 'avg_pct': 91.0, 'num_tests': 2}, {'topic': 'F', 'avg_pct': 92.0, 'num_tests': 1}], 'test_details': [{'test_col': 'English_Test1', 'subject': 'English', 'raw': 85, 'pct': 85.0, 'topics': ['A', 'B']}, {'test_col': 'English_Test2', 'subject': 'English', 'raw': 88, 'pct': 88.0, 'topics': ['B', 'C']}, {'test_col': 'Maths_Test1', 'subject': 'Maths', 'raw': 90, 'pct': 90.0, 'topics': ['C', 'D']}, {'test_col': 'Maths_Test2', 'subject': 'Maths', 'raw': 92, 'pct': 92.0, 'topics': ['D', 'F']}]}, {'name': 'Bob', 'attendance': 23, 'remarks': '', 'strong_topics': ['C', 'D', 'F'], 'weak_topics': [], 'practice_topics': ['A', 'B'], 'topic_details': [{'topic': 'A', 'avg_pct': 78.0, 'num_tests': 1}, {'topic': 'B', 'avg_pct': 80.0, 'num_tests': 2}, {'topic': 'C', 'avg_pct': 85.0, 'num_tests': 2}, {'topic': 'D', 'avg_pct': 86.5, 'num_tests': 2}, {'topic': 'F', 'avg_pct': 85.0, 'num_tests': 1}], 'test_details': [{'test_col': 'English_Test1', 'subject': 'English', 'raw': 78, 'pct': 78.0, 'topics': ['A', 'B']}, {'test_col': 'English_Test2', 'subject': 'English', 'raw': 82, 'pct': 82.0, 'topics': ['B', 'C']}, {'test_col': 'Maths_Test1', 'subject': 'Maths', 'raw': 88, 'pct': 88.0, 'topics': ['C', 'D']}, {'test_col': 'Maths_Test2', 'subject': 'Maths', 'raw': 85, 'pct': 85.0, 'topics': ['D', 'F']}]}, {'name': 'Charlie', 'attendance': 24, 'remarks': '', 'strong_topics': ['A', 'B', 'C'], 'weak_topics': [], 'practice_topics': ['D', 'F'], 'topic_details': [{'topic': 'A', 'avg_pct': 92.0, 'num_tests': 1}, {'topic': 'B', 'avg_pct': 93.0, 'num_tests': 2}, {'topic': 'C', 'avg_pct': 85.0, 'num_tests': 2}, {'topic': 'D', 'avg_pct': 77.0, 'num_tests': 2}, {'topic': 'F', 'avg_pct': 78.0, 'num_tests': 1}], 'test_details': [{'test_col': 'English_Test1', 'subject': 'English', 'raw': 92, 'pct': 92.0, 'topics': ['A', 'B']}, {'test_col': 'English_Test2', 'subject': 'English', 'raw': 94, 'pct': 94.0, 'topics': ['B', 'C']}, {'test_col': 'Maths_Test1', 'subject': 'Maths', 'raw': 76, 'pct': 76.0, 'topics': ['C', 'D']}, {'test_col': 'Maths_Test2', 'subject': 'Maths', 'raw': 78, 'pct': 78.0, 'topics': ['D', 'F']}]}]\n"
     ]
    }
   ],
   "source": [
    "classified_students_data = classify_students_by_topic(student_data_validated)\n",
    "(classified_students_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460e25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
