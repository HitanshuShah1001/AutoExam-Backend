{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b567be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openai as client\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from fpdf import FPDF\n",
    "import seaborn as sns\n",
    "from xhtml2pdf import pisa\n",
    "from PyPDF2 import PdfMerger\n",
    "import re\n",
    "import csv\n",
    "from typing import List\n",
    "from utils import print_question_data\n",
    "from utils import print_first_5_students\n",
    "from utils import print_single_value_in_table\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from utils import print_single_value_in_table\n",
    "from utils import err_box_red\n",
    "from utils import pretty_print_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9fb30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_individual_student_report(csv_path, student_name, output_folder):\n",
    "    # 1. Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 2. Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 3. Identify subjects and their test columns\n",
    "    subjects_info = _identify_subjects_and_tests(df.columns)\n",
    "    subjects = list(subjects_info.keys())\n",
    "\n",
    "    # 4. Replace 'AB' with NaN for calculations but keep original data for display\n",
    "    df_calc = df.copy()\n",
    "    for subject_data in subjects_info.values():\n",
    "        for test_col in subject_data['test_columns']:\n",
    "            df_calc[test_col] = pd.to_numeric(df_calc[test_col], errors='coerce')\n",
    "\n",
    "    # 5. Compute aggregated scores and class stats\n",
    "    aggregated_scores = _compute_aggregated_scores(df_calc, subjects_info)\n",
    "    class_stats = _compute_class_stats(aggregated_scores, subjects)\n",
    "\n",
    "    # 6. Locate the student row\n",
    "    student_df = df[df['Student Names'] == student_name]\n",
    "    if student_df.empty:\n",
    "        raise ValueError(f\"Student '{student_name}' not found\")\n",
    "    student = student_df.iloc[0]\n",
    "    \n",
    "    # 7. Compute student's aggregated scores\n",
    "    student_calc = df_calc[df_calc['Student Names'] == student_name].iloc[0]\n",
    "    student_aggregated = _compute_student_aggregated_scores(student_calc, subjects_info)\n",
    "    \n",
    "    # 8. Generate the PDF\n",
    "    output_path = _generate_student_pdf(\n",
    "        student, student_calc, student_aggregated, subjects_info, subjects, \n",
    "        class_stats, output_folder, aggregated_scores\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def _identify_subjects_and_tests(columns):\n",
    "    \"\"\"\n",
    "    Identify subjects and their corresponding test columns from dataframe columns.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject_name: {'test_columns': [col1, col2, ...], 'topic_columns': [...]}}\n",
    "    \"\"\"\n",
    "    subjects_info = {}\n",
    "    \n",
    "    # Filter out non-subject columns\n",
    "    excluded_cols = {'Student Names', 'Attendance', \"Teacher's Remarks\"}\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in excluded_cols:\n",
    "            continue\n",
    "            \n",
    "        # Check if it's a topic column\n",
    "        if 'Topics' in col:\n",
    "            continue\n",
    "            \n",
    "        # Extract base subject name (remove _Test1, _Test2, etc.)\n",
    "        if '_Test' in col:\n",
    "            base_subject = col.split('_Test')[0]\n",
    "        else:\n",
    "            base_subject = col\n",
    "            \n",
    "        if base_subject not in subjects_info:\n",
    "            subjects_info[base_subject] = {\n",
    "                'test_columns': [],\n",
    "                'topic_columns': []\n",
    "            }\n",
    "        \n",
    "        # Add to test columns if it's a test column\n",
    "        if '_Test' in col or col == base_subject:\n",
    "            subjects_info[base_subject]['test_columns'].append(col)\n",
    "    \n",
    "    # Now find topic columns for each subject\n",
    "    for col in columns:\n",
    "        if 'Topics' in col:\n",
    "            # Try to match with subjects\n",
    "            for subject in subjects_info.keys():\n",
    "                if subject in col:\n",
    "                    subjects_info[subject]['topic_columns'].append(col)\n",
    "                    break\n",
    "    \n",
    "    return subjects_info\n",
    "\n",
    "\n",
    "def _compute_aggregated_scores(df_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for each student and subject.\n",
    "    Uses average of all tests for a subject, handling AB/NaN values properly.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: Student Names, Subject1_Avg, Subject2_Avg, etc.\n",
    "    \"\"\"\n",
    "    result_data = {'Student Names': df_calc['Student Names']}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            # Single test - just use that column\n",
    "            result_data[f\"{subject}_Avg\"] = df_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Multiple tests - compute average of available scores\n",
    "            test_data = df_calc[test_cols]\n",
    "            # Compute row-wise mean, ignoring NaN values\n",
    "            result_data[f\"{subject}_Avg\"] = test_data.mean(axis=1, skipna=True)\n",
    "    \n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "\n",
    "def _compute_student_aggregated_scores(student_calc, subjects_info):\n",
    "    \"\"\"\n",
    "    Compute aggregated scores for a single student.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject: aggregated_score}\n",
    "    \"\"\"\n",
    "    student_scores = {}\n",
    "    \n",
    "    for subject, info in subjects_info.items():\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        if len(test_cols) == 1:\n",
    "            student_scores[subject] = student_calc[test_cols[0]]\n",
    "        else:\n",
    "            # Compute average of available test scores\n",
    "            test_scores = [student_calc[col] for col in test_cols if pd.notna(student_calc[col])]\n",
    "            if test_scores:\n",
    "                student_scores[subject] = sum(test_scores) / len(test_scores)\n",
    "            else:\n",
    "                student_scores[subject] = float('nan')  # All tests were AB/NaN\n",
    "    \n",
    "    return student_scores\n",
    "\n",
    "\n",
    "def _compute_class_stats(aggregated_scores, subjects):\n",
    "    \"\"\"\n",
    "    Compute class statistics using aggregated scores.\n",
    "    \"\"\"\n",
    "    class_stats = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        col_name = f\"{subject}_Avg\"\n",
    "        if col_name in aggregated_scores.columns:\n",
    "            class_stats[subject] = {\n",
    "                'highest': aggregated_scores[col_name].max(),\n",
    "                'lowest': aggregated_scores[col_name].min(),\n",
    "                'average': aggregated_scores[col_name].mean()\n",
    "            }\n",
    "    \n",
    "    return class_stats\n",
    "\n",
    "\n",
    "def _generate_student_pdf(student, student_calc, student_aggregated, subjects_info, \n",
    "                         subjects, class_stats, output_folder, aggregated_scores):\n",
    "    \"\"\"\n",
    "    Internal helper to build the PDF for one student with compact layout.\n",
    "    Handles multiple tests per subject and improved strongest/weakest analysis.\n",
    "    \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Use Times as it's closer to the \"math\" font in the template\n",
    "    pdf.set_font('Times', 'B', 14)\n",
    "\n",
    "    # Header - more compact\n",
    "    name = student['Student Names']\n",
    "    pdf.cell(0, 8, \"Student Performance Report\", ln=1, align='C')\n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Attendance with less spacing (if available)\n",
    "    if 'Attendance' in student.index:\n",
    "        att = student['Attendance']\n",
    "        att_pct = (int(att) / ATTENDANCE_DAYS) * 100 if pd.notna(att) else 0\n",
    "        pdf.cell(0, 6, f\"Attendance: {att} / {ATTENDANCE_DAYS} ({att_pct:.1f}%)\", ln=1, align='C')\n",
    "    \n",
    "    # Minimal spacing before chart\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # Comparison chart - increased height\n",
    "    chart_path = create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info)\n",
    "    pdf.image(chart_path, x=20, w=170, h=75)\n",
    "    os.remove(chart_path)\n",
    "    \n",
    "    # Compact spacing\n",
    "    pdf.ln(2)\n",
    "\n",
    "    # SECTION: Subject Analysis with underlined header\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Subject Analysis\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Format subject analysis showing individual tests and average\n",
    "    pct_map = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        info = subjects_info[subject]\n",
    "        test_cols = info['test_columns']\n",
    "        \n",
    "        # Get subject average score\n",
    "        avg_score = student_aggregated.get(subject)\n",
    "        \n",
    "        if pd.isna(avg_score):\n",
    "            pdf.cell(0, 6, f\"{subject}: All tests absent\", ln=1)\n",
    "        else:\n",
    "            # Show individual test scores and average\n",
    "            test_details = []\n",
    "            for col in test_cols:\n",
    "                raw_score = student[col] if col in student.index else 'AB'\n",
    "                if raw_score == 'AB' or pd.isna(raw_score):\n",
    "                    test_details.append(\"AB\")\n",
    "                else:\n",
    "                    test_details.append(f\"{raw_score}\")\n",
    "            \n",
    "            # Assuming max score is 100 for percentage calculation\n",
    "            # You may need to adjust this based on your scoring system\n",
    "            max_score = 100\n",
    "            avg_pct = (avg_score / max_score) * 100\n",
    "            pct_map[subject] = avg_pct\n",
    "            \n",
    "            if len(test_cols) == 1:\n",
    "                pdf.cell(0, 6, f\"{subject}: {test_details[0]}/{max_score} ({avg_pct:.1f}%)\", ln=1)\n",
    "            else:\n",
    "                tests_str = \" | \".join([f\"T{i+1}: {score}\" for i, score in enumerate(test_details)])\n",
    "                pdf.cell(0, 6, f\"{subject}: {tests_str} | Avg: {avg_score:.1f}/{max_score} ({avg_pct:.1f}%)\", ln=1)\n",
    "\n",
    "    # SECTION: Performance Highlights with improved logic\n",
    "    pdf.ln(2)\n",
    "    pdf.set_font('Times', 'B', 12)\n",
    "    pdf.cell(0, 8, \"Performance Highlights\", ln=1)\n",
    "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "    pdf.ln(1)\n",
    "    \n",
    "    pdf.set_font('Times', '', 10)\n",
    "    \n",
    "    # Only show highlights if student has taken at least one test\n",
    "    if pct_map:\n",
    "        # Improved strongest/weakest subject logic\n",
    "        performance_analysis = _analyze_student_performance(pct_map, aggregated_scores, subjects, name)\n",
    "        \n",
    "        # Display strongest subjects (top 30% performance or above 80%)\n",
    "        if performance_analysis['strong_subjects']:\n",
    "            strong_subjects_str = \", \".join([f\"{subj} ({pct:.1f}%)\" \n",
    "                                           for subj, pct in performance_analysis['strong_subjects']])\n",
    "            pdf.cell(0, 6, f\"Strong Subjects: {strong_subjects_str}\", ln=1)\n",
    "        \n",
    "        # Display subjects needing improvement\n",
    "        if performance_analysis['improvement_subjects']:\n",
    "            pdf.cell(0, 6, \"Subjects Needing Improvement:\", ln=1)\n",
    "            for subj, pct, reason in performance_analysis['improvement_subjects']:\n",
    "                pdf.cell(0, 6, f\"- {subj} ({pct:.1f}%) - {reason}\", ln=1)\n",
    "        \n",
    "        # Overall performance summary\n",
    "        pdf.cell(0, 6, f\"Overall Average: {performance_analysis['overall_avg']:.1f}%\", ln=1)\n",
    "        \n",
    "        if performance_analysis['consistency_note']:\n",
    "            pdf.cell(0, 6, performance_analysis['consistency_note'], ln=1)\n",
    "    else:\n",
    "        pdf.cell(0, 6, \"No test scores available for performance analysis\", ln=1)\n",
    "\n",
    "    # SECTION: Teacher's Remarks (if available)\n",
    "    if \"Teacher's Remarks\" in student.index:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Teacher's Remarks\", ln=1)\n",
    "        \n",
    "        has_remarks = pd.notna(student[\"Teacher's Remarks\"]) and student[\"Teacher's Remarks\"].strip() != \"\"\n",
    "        \n",
    "        if has_remarks:\n",
    "            pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.multi_cell(0, 5, student[\"Teacher's Remarks\"])\n",
    "        else:\n",
    "            pdf.ln(1)\n",
    "            pdf.set_font('Times', '', 10)\n",
    "            pdf.cell(0, 5, \"No remarks from teacher\", ln=1)\n",
    "\n",
    "    # SECTION: Topics Covered - consolidate from all tests\n",
    "    remaining_height = 270 - pdf.get_y()\n",
    "    \n",
    "    if remaining_height > 20:\n",
    "        pdf.ln(2)\n",
    "        pdf.set_font('Times', 'B', 12)\n",
    "        pdf.cell(0, 8, \"Topics Covered\", ln=1)\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(1)\n",
    "        \n",
    "        pdf.set_font('Times', '', 10)\n",
    "        for subject in subjects:\n",
    "            info = subjects_info[subject]\n",
    "            topic_cols = info['topic_columns']\n",
    "            \n",
    "            if topic_cols:\n",
    "                all_topics = set()\n",
    "                for col in topic_cols:\n",
    "                    if col in student.index and pd.notna(student[col]):\n",
    "                        # Split topics by comma and add to set to avoid duplicates\n",
    "                        topics = [t.strip() for t in str(student[col]).split(',')]\n",
    "                        all_topics.update(topics)\n",
    "                \n",
    "                if all_topics:\n",
    "                    topics_text = f\"{subject}: {', '.join(sorted(all_topics))}\"\n",
    "                    if len(topics_text) > 100:\n",
    "                        topics_text = topics_text[:97] + \"...\"\n",
    "                    pdf.multi_cell(0, 5, topics_text)\n",
    "\n",
    "    # Save\n",
    "    safe_name = name.replace(' ', '_')\n",
    "    path = os.path.join(output_folder, f\"{safe_name}_report.pdf\")\n",
    "    pdf.output(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def _analyze_student_performance(pct_map, aggregated_scores, subjects, student_name):\n",
    "    \"\"\"\n",
    "    Improved performance analysis logic that considers:\n",
    "    1. Relative performance vs class\n",
    "    2. Absolute performance thresholds\n",
    "    3. Consistency across subjects\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        'strong_subjects': [],\n",
    "        'improvement_subjects': [],\n",
    "        'overall_avg': 0,\n",
    "        'consistency_note': ''\n",
    "    }\n",
    "    \n",
    "    if not pct_map:\n",
    "        return analysis\n",
    "    \n",
    "    # Calculate overall average\n",
    "    analysis['overall_avg'] = sum(pct_map.values()) / len(pct_map)\n",
    "    \n",
    "    # Calculate class percentiles for each subject\n",
    "    subject_percentiles = {}\n",
    "    for subject in subjects:\n",
    "        if subject in pct_map:\n",
    "            col_name = f\"{subject}_Avg\"\n",
    "            if col_name in aggregated_scores.columns:\n",
    "                all_scores = aggregated_scores[col_name].dropna()\n",
    "                if not all_scores.empty:\n",
    "                    student_score = pct_map[subject] * 100 / 100  # Convert back to raw score\n",
    "                    percentile = (all_scores < student_score).sum() / len(all_scores) * 100\n",
    "                    subject_percentiles[subject] = percentile\n",
    "    \n",
    "    # Identify strong subjects (above 80% OR top 25% of class)\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        if pct >= 80 or percentile >= 75:\n",
    "            analysis['strong_subjects'].append((subject, pct))\n",
    "    \n",
    "    # Sort strong subjects by percentage\n",
    "    analysis['strong_subjects'].sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Identify subjects needing improvement\n",
    "    for subject, pct in pct_map.items():\n",
    "        percentile = subject_percentiles.get(subject, 0)\n",
    "        reasons = []\n",
    "        \n",
    "        if pct < 60:\n",
    "            reasons.append(\"below 60%\")\n",
    "        elif pct < 75 and percentile < 50:\n",
    "            reasons.append(\"below class median\")\n",
    "        elif percentile < 25:\n",
    "            reasons.append(\"bottom 25% of class\")\n",
    "        \n",
    "        if reasons:\n",
    "            analysis['improvement_subjects'].append((subject, pct, \" & \".join(reasons)))\n",
    "    \n",
    "    # Sort improvement subjects by percentage (lowest first)\n",
    "    analysis['improvement_subjects'].sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Consistency analysis\n",
    "    if len(pct_map) > 1:\n",
    "        scores = list(pct_map.values())\n",
    "        score_range = max(scores) - min(scores)\n",
    "        if score_range < 10:\n",
    "            analysis['consistency_note'] = \"Performance is very consistent across subjects\"\n",
    "        elif score_range > 30:\n",
    "            analysis['consistency_note'] = \"Performance varies significantly across subjects\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def create_comparison_chart(student, student_aggregated, subjects, class_stats, subjects_info):\n",
    "    \"\"\"\n",
    "    Build and save a matplotlib chart comparing this student's aggregated scores\n",
    "    against class high/low/average in each subject, with percentages over all bars.\n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Set Times font family explicitly\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "    matplotlib.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif', 'serif']\n",
    "\n",
    "    # Prepare data arrays\n",
    "    marks = []\n",
    "    absent_subjects = []\n",
    "    for s in subjects:\n",
    "        agg = student_aggregated.get(s)\n",
    "        if pd.isna(agg):\n",
    "            marks.append(0)\n",
    "            absent_subjects.append(s)\n",
    "        else:\n",
    "            marks.append(agg)\n",
    "\n",
    "    average = [class_stats[s]['average'] for s in subjects]\n",
    "    highest = [class_stats[s]['highest'] for s in subjects]\n",
    "    lowest  = [class_stats[s]['lowest']  for s in subjects]\n",
    "\n",
    "    # Determine max_score for y-offset of labels\n",
    "    max_score = max(\n",
    "        max(average or [0]),\n",
    "        max(highest  or [0]),\n",
    "        max(lowest   or [0]),\n",
    "        max(marks    or [0]),\n",
    "        100\n",
    "    )\n",
    "\n",
    "    # Colors\n",
    "    student_color = '#4570B7'\n",
    "    avg_color     = '#9FA7B2'\n",
    "    high_color    = '#97D077'\n",
    "    low_color     = '#F08B7E'\n",
    "    absent_color  = '#E8E8E8'\n",
    "\n",
    "    # Figure setup\n",
    "    plt.figure(figsize=(7.5, 5.0))\n",
    "    x = np.arange(len(subjects))\n",
    "    width = 0.18\n",
    "\n",
    "    # Plot bars\n",
    "    avg_bars     = plt.bar(x,           average, width, color=avg_color,    edgecolor='white', linewidth=0.5, label='Class Average', zorder=1)\n",
    "    high_bars    = plt.bar(x + width,   highest, width,  color=high_color,   edgecolor='white', linewidth=0.5, label='Class Highest', zorder=1)\n",
    "    low_bars     = plt.bar(x - width,   lowest,  width,  color=low_color,    edgecolor='white', linewidth=0.5, label='Class Lowest', zorder=1)\n",
    "    student_bars = plt.bar(\n",
    "        x + 2*width,\n",
    "        marks,\n",
    "        width,\n",
    "        color=[absent_color if s in absent_subjects else student_color for s in subjects],\n",
    "        edgecolor='white',\n",
    "        linewidth=1.0,\n",
    "        label=student['Student Names'],\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "    # Annotate every bar with a percentage or \"Absent\"\n",
    "    bar_sets = [\n",
    "        (avg_bars,     average),\n",
    "        (high_bars,    highest),\n",
    "        (low_bars,     lowest),\n",
    "        (student_bars, marks),\n",
    "    ]\n",
    "    for bars, values in bar_sets:\n",
    "        for idx, rect in enumerate(bars):\n",
    "            height = rect.get_height()\n",
    "            # For student bars where the student was absent:\n",
    "            if bars is student_bars and subjects[idx] in absent_subjects:\n",
    "                label = \"Absent\"\n",
    "            else:\n",
    "                # value is out of 100, so it's directly percentage\n",
    "                label = f\"{values[idx]:.1f}%\"\n",
    "            plt.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height + max_score * 0.01,  # small offset above bar\n",
    "                label,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=8,\n",
    "                family='Times New Roman'\n",
    "            )\n",
    "\n",
    "    # Axes & titles\n",
    "    plt.xlabel('Subjects', fontsize=10, family='Times New Roman')\n",
    "    plt.ylabel('Average Score', fontsize=10, family='Times New Roman')\n",
    "    plt.suptitle(f\"{student['Student Names']}'s Performance\",\n",
    "                 fontsize=12, family='Times New Roman', y=0.98)\n",
    "    plt.title(\"Comparison with class statistics (test averages)\",\n",
    "              fontsize=9, family='Times New Roman', pad=10)\n",
    "\n",
    "    plt.xticks(x + width/2, subjects, fontsize=10, family='Times New Roman')\n",
    "    plt.ylim(0, max_score * 1.1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.2, zorder=0)\n",
    "\n",
    "    # Legend\n",
    "    legend_elems = [\n",
    "        Patch(facecolor=student_color, edgecolor='white', label=student['Student Names']),\n",
    "        Patch(facecolor=avg_color,     edgecolor='white', label='Class Average'),\n",
    "        Patch(facecolor=high_color,    edgecolor='white', label='Class Highest'),\n",
    "        Patch(facecolor=low_color,     edgecolor='white', label='Class Lowest'),\n",
    "    ]\n",
    "    if absent_subjects:\n",
    "        legend_elems.append(Patch(facecolor=absent_color, edgecolor='white', label='Absent'))\n",
    "    plt.legend(handles=legend_elems, loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "               fontsize=9, framealpha=0.7, edgecolor='#CCCCCC',\n",
    "               ncol=min(5, len(legend_elems)), prop={'family': 'Times New Roman'})\n",
    "\n",
    "    # Clean up\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for lbl in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        lbl.set_fontname('Times New Roman')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.97])\n",
    "\n",
    "    # Save and return\n",
    "    fname = f\"temp_chart_{student['Student Names'].replace(' ', '_')}.png\"\n",
    "    plt.savefig(fname, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    return fname\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e991da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./reports/Alice_report.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_individual_student_report('./student_data_out.csv','Alice','./reports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede10343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
